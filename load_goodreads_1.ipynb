{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for making dataframe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for crawling Goodreads\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for XML\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import for finding texts in HTML\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for seeing full text reviews\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodreads API Developer key\n",
    "key = 'e8m0Y7q3q9psBCGuwTDRUA'\n",
    "secret = 'sQzxhCY5eEGBUJLUwOrKnmPOGUIRUvSemqntp6ZSDJU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: FILL IN BEFORE RUNNING CODE\n",
    "# Goodreads login\n",
    "email = ''\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0062089099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0062089196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0062089234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0062089285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0062089374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>0062391739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>0062391755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2969</th>\n",
       "      <td>0062391763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>0062391771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>006239178X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2972 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin\n",
       "0     0062089099\n",
       "1     0062089196\n",
       "2     0062089234\n",
       "3     0062089285\n",
       "4     0062089374\n",
       "...          ...\n",
       "2967  0062391739\n",
       "2968  0062391755\n",
       "2969  0062391763\n",
       "2970  0062391771\n",
       "2971  006239178X\n",
       "\n",
       "[2972 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NOTE: FILL IN BEFORE RUNNING CODE\n",
    "# Load Amazon data to find reviews of same books from Goodreads\n",
    "amazon = pd.read_csv('asinOnly6.csv')\n",
    "amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2972\n"
     ]
    }
   ],
   "source": [
    "# Unique set of books to crawl from Goodreads\n",
    "books = set(amazon.asin)\n",
    "print(len(books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: COMMENT OUT FOR FULL SET\n",
    "## TEST SUBSET\n",
    "test = set()\n",
    "for i,val in enumerate(books):\n",
    "    if i == 3:\n",
    "        break\n",
    "    test.add(val)\n",
    "books = test\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [overall, reviewTime, asin, reviewText]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create empty dataframe to store Goodreads reviews & ratings\n",
    "column_names = ['overall', 'reviewTime', 'asin', 'reviewText']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in Goodreads\n",
    "driver = webdriver.Chrome(r\"C:\\\\Users\\\\Tien Nguyen\\\\Stats_170AB\\\\chromedriver.exe\")\n",
    "driver.get ('https://www.goodreads.com/user/sign_in?source=home')\n",
    "driver.find_element_by_name('user[email]').send_keys(email)\n",
    "driver.find_element_by_name('user[password]').send_keys(password)\n",
    "driver.find_element_by_name('next').click()                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "REVIEW_FOLDER = \"C:\\\\Users\\\\Tien Nguyen\\\\Stats_170AB\\\\goodreads_review_dataset\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6b40410b1dc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;31m#print('   NOT FOUND')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get most popular reviews for each book (10 if there are more than 10 reviews, or all reviews if less)\n",
    "for book in books:\n",
    "    # if the reviews for the book is downloaded, skip it\n",
    "    review_path = os.path.join(REVIEW_FOLDER, book + \".txt\")\n",
    "    if os.path.exists(review_path):\n",
    "        continue\n",
    "    \n",
    "    f = open(review_path, 'w')\n",
    "        \n",
    "    # Try to look up the book in Goodreads. If a book isn't found it will not be added to the dataset -> DATA CLEANING LATER\n",
    "    try:\n",
    "        #print('TRYING BOOK:', book)\n",
    "        \n",
    "        # Search up book on Goodreads\n",
    "        res = requests.get('https://www.goodreads.com/book/isbn', params={'format': 'xml', 'key': key, 'isbn': book})\n",
    "        \n",
    "        # Get XML from API\n",
    "        root = ElementTree.fromstring(res.text)    \n",
    "        \n",
    "        # Find iframe from XML\n",
    "        iframe = root.find('book').find('reviews_widget').text\n",
    "        \n",
    "        # Parse HTML of XML to find link to reviews\n",
    "        soup = BeautifulSoup(iframe, 'html.parser')\n",
    "        url = soup.find('iframe')['src']\n",
    "        \n",
    "        # Open link to reviews using Selenium\n",
    "        driver.get(str(url))\n",
    "\n",
    "        # PAGE 1: Expand each review to save full text & metadata\n",
    "        # If a book doesn't have reviews, it will not be added to the dataset -> DATA CLEANING LATER\n",
    "        links = driver.find_elements_by_link_text('...more') \n",
    "\n",
    "        for link in links:\n",
    "            # Open review in new tab\n",
    "            ActionChains(driver).move_to_element(link).perform()\n",
    "            link.click()\n",
    "            \n",
    "            # Switch to new tab\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            s = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Use BeautifulSoup to check & save reviewTime\n",
    "            time = s.find('span', itemprop='datePublished')\n",
    "            \n",
    "            # Use BeautifulSoup to save rating\n",
    "            rating = s.find('meta', itemprop='ratingValue')\n",
    "            \n",
    "            # Use BeautifulSoup to save text review\n",
    "            review = s.find('div', itemprop='reviewBody')\n",
    "            \n",
    "            # Add review to dataframe\n",
    "            #df = df.append({'overall':rating.get('content'), 'reviewTime':time.text.strip(), 'asin':book, \n",
    "            #                'reviewText':review.text.strip()}, ignore_index=True)\n",
    "            \n",
    "            print(\"{}\\n{}\\n{}\\n{}\\{}n\".format(rating.get('content'),\n",
    "                                                time.text.strip(),\n",
    "                                                book,\n",
    "                                                review.text.strip()))\n",
    "            f.write(\"{}\\n{}\\n{}\\n{}\\n\".format(rating.get('content'),\n",
    "                                                time.text.strip(),\n",
    "                                                book,\n",
    "                                                review.text.strip()))\n",
    "                \n",
    "            driver.close()\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            \n",
    "        # PAGE 2: Expand each review to save full text & metadata\n",
    "        # If a book doesn't have reviews, it will not be added to the dataset -> DATA CLEANING LATER\n",
    "        driver.find_element_by_link_text('2').click()\n",
    "        links = driver.find_elements_by_link_text('...more') \n",
    "\n",
    "        for link in links:\n",
    "            # Open review in new tab\n",
    "            ActionChains(driver).move_to_element(link).perform()\n",
    "            link.click()\n",
    "            \n",
    "            # Switch to new tab\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            s = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Use BeautifulSoup to check & save reviewTime\n",
    "            time = s.find('span', itemprop='datePublished')\n",
    "            \n",
    "            # Use BeautifulSoup to save rating\n",
    "            rating = s.find('meta', itemprop='ratingValue')\n",
    "            \n",
    "            # Use BeautifulSoup to save text review\n",
    "            review = s.find('div', itemprop='reviewBody')\n",
    "            \n",
    "            # Add review to dataframe\n",
    "            #df = df.append({'overall':rating.get('content'), 'reviewTime':time.text.strip(), 'asin':book, \n",
    "            #                'reviewText':review.text.strip()}, ignore_index=True)\n",
    "            f.write(\"{}\\n{}\\n{}\\n{}\\n\".format(rating.get('content'),\n",
    "                                                time.text.strip(),\n",
    "                                                book,\n",
    "                                                review.text.strip()))\n",
    "            \n",
    "                \n",
    "            driver.close()           \n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            \n",
    "        # PAGE 3: Expand each review to save full text & metadata\n",
    "        # If a book doesn't have reviews, it will not be added to the dataset -> DATA CLEANING LATER\n",
    "        driver.find_element_by_link_text('3').click()\n",
    "        links = driver.find_elements_by_link_text('...more') \n",
    "\n",
    "        for link in links:\n",
    "            # Open review in new tab\n",
    "            ActionChains(driver).move_to_element(link).perform()\n",
    "            link.click()\n",
    "            \n",
    "            # Switch to new tab\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "            s = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Use BeautifulSoup to check & save reviewTime\n",
    "            time = s.find('span', itemprop='datePublished')\n",
    "            \n",
    "            # Use BeautifulSoup to save rating\n",
    "            rating = s.find('meta', itemprop='ratingValue')\n",
    "            \n",
    "            # Use BeautifulSoup to save text review\n",
    "            review = s.find('div', itemprop='reviewBody')\n",
    "            \n",
    "            # Add review to dataframe\n",
    "            #df = df.append({'overall':rating.get('content'), 'reviewTime':time.text.strip(), 'asin':book, \n",
    "            #                'reviewText':review.text.strip()}, ignore_index=True)\n",
    "            \n",
    "            # Save a review to a file\n",
    "            f.write(\"{}\\n{}\\n{}\\n{}\\n\".format(rating.get('content'),\n",
    "                                                time.text.strip(),\n",
    "                                                book,\n",
    "                                                review.text.strip()))\n",
    "            \n",
    "            driver.close()           \n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "            \n",
    "        f.close()\n",
    "    except:\n",
    "        f.close()\n",
    "        pass\n",
    "    \n",
    "    sleep(2)\n",
    "        #print('   NOT FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: CHANGE FILE NAME BEFORE RUNNING CODE  \n",
    "df.to_csv('grData6.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
