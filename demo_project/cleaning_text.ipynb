{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#cell 3\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from textblob import TextBlob, Word\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller\n",
    "import multiprocessing as mp\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tien\n",
      "[nltk_data]     Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Tien\n",
      "[nltk_data]     Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Tien\n",
      "[nltk_data]     Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tien Nguyen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "STOPWORDS = stopwords.words(\"english\") #stopwords are the most common unnecessary words. eg is, he, that, etc.\n",
    "# adding more stopwords\n",
    "STOPWORDS.append('could')\n",
    "STOPWORDS.append('also')\n",
    "STOPWORDS.append('would')\n",
    "STOPWORDS.append('really')\n",
    "STOPWORDS.append('ought')\n",
    "STOPWORDS.append('might')\n",
    "STOPWORDS.append('may')\n",
    "STOPWORDS.append('must')\n",
    "STOPWORDS.append('need')\n",
    "STOPWORDS.append('shall')\n",
    "STOPWORDS.append('somebody')\n",
    "STOPWORDS.append('someone')\n",
    "STOPWORDS.append('something')\n",
    "STOPWORDS.append('somewhere')\n",
    "STOPWORDS.append('still')\n",
    "STOPWORDS.append('thing')\n",
    "STOPWORDS.append('up')\n",
    "STOPWORDS.append('whose')\n",
    "STOPWORDS.append('without')\n",
    "STOPWORDS.append('yet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii') # A function to remove emojis from the reviews\n",
    "\n",
    "#cell 6\n",
    "def lemmatize_with_postag(sentence, wnl):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    #lemmatized_list = [wnl.lemmatize(wd, tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = Speller(lang='en')\n",
    "contractions_dict = {     \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"iit will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "#cell 8\n",
    "# Remove 'not' for sentiment analysis\n",
    "#STOPWORDS.remove('not')\n",
    "#len(STOPWORDS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell 9\n",
    "def clean_text(text, wnl):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text=deEmojify(text) # remove emojis\n",
    "    text_cleaned=re.sub(' +', ' ', text) # remove extra white spaces\n",
    "    text_cleaned=text_cleaned.lower() # converting to lowercase\n",
    "    text_cleaned = ''.join(c for c in text_cleaned if not c.isdigit())# remove numbers\n",
    "    text_cleaned = expand_contractions(text_cleaned, contractions_dict) # contraction \n",
    "    text_cleaned=\"\".join([x for x in text_cleaned if x not in string.punctuation]) # remove punctuation\n",
    "    \n",
    "    text_cleaned = nltk.word_tokenize(text_cleaned)\n",
    "    text_cleaned = [x for x in text_cleaned if len(x) < 20]\n",
    "    #text_cleaned = ' '.join(spell(w) for w in (text_cleaned))\n",
    "    text_cleaned = [spell(w) for w in (text_cleaned)]   # correct spelling\n",
    "    #text_cleaned=text_cleaned.split(\" \")\n",
    "    text_cleaned=\" \".join([token for token in text_cleaned if token not in STOPWORDS]) # Taking only those words which are not stopwords\n",
    "    \n",
    "    #Converting to lemma\n",
    "    text_cleaned = lemmatize_with_postag(str(text_cleaned), wnl)\n",
    "\n",
    "    return text_cleaned\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "#cell 12\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending = []\n",
    "pending.append('overall' + '\\t' + 'reviewTime' + '\\t' + 'asin'+'\\t'+'reviewText' + '\\t' + 'cleaned_text' + '\\n')\n",
    "with open('reviews.tsv','r') as f:\n",
    "    next(f)\n",
    "    with open('reviews_cleaned.tsv', 'w') as g: \n",
    "        \n",
    "            #g.write('overall' + '\\t' + 'reviewTime' + '\\t' + 'asin'+'\\t'+'reviewText' + '\\t' + 'cleaned_text' + '\\n')\n",
    "        lines = f.readlines()\n",
    "        for i, line in enumerate(lines):\n",
    "            if i == 30:\n",
    "                break\n",
    "            line = line.strip().split('\\t')\n",
    "            overall = line[0]\n",
    "            reviewTime = line[1]\n",
    "            asin = line[2]\n",
    "            if len(line) > 3:\n",
    "                reviewText = line[3]\n",
    "                reviewText = remove_tags(reviewText)\n",
    "                cleaned_text = clean_text(reviewText, wnl)\n",
    "                pending.append(overall + '\\t' + reviewTime + '\\t' + asin +'\\t' + reviewText + '\\t' + cleaned_text + '\\n')\n",
    "                        #g.write(overall + '\\t' + reviewTime + '\\t' + asin +'\\t' + reviewText + '\\t' + cleaned_text + '\\n')\n",
    "            else:\n",
    "                pending.append(overall + '\\t' + reviewTime + '\\t' + asin +'\\t' + '' + '\\t' + '' + '\\n')\n",
    "                #g.write(overall + '\\t' + reviewTime + '\\t' + asin +'\\t' + '' + '\\t' + '' + '\\n')\n",
    "        g.write(\"\".join(pending))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>08 12  2005</td>\n",
       "      <td>1713353</td>\n",
       "      <td>This book is a winner with both of my boys.  T...</td>\n",
       "      <td>book winner boys enjoy picture story classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>03 30  2005</td>\n",
       "      <td>1713353</td>\n",
       "      <td>The King, the Mice and the Cheese by Nancy Gur...</td>\n",
       "      <td>king mouse cheese nancy gurney excellent child...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>04 4  2004</td>\n",
       "      <td>1713353</td>\n",
       "      <td>My daughter got her first copy from her great-...</td>\n",
       "      <td>daughter get first copy greatgrandmother fathe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 21  2004</td>\n",
       "      <td>1713353</td>\n",
       "      <td>I remember this book from when I was a child a...</td>\n",
       "      <td>remember book child year ago remember wonderfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 3  2016</td>\n",
       "      <td>1713353</td>\n",
       "      <td>Just as I remembered it, one of my favorites f...</td>\n",
       "      <td>remember one favorites childhood great conditi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 29  2016</td>\n",
       "      <td>1713353</td>\n",
       "      <td>It is a very cute book with great illustration...</td>\n",
       "      <td>cute book great illustrationswith enjoyable st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 20  2016</td>\n",
       "      <td>1713353</td>\n",
       "      <td>The kids loved it!</td>\n",
       "      <td>kid love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>04 24  2016</td>\n",
       "      <td>1713353</td>\n",
       "      <td>I was just so hapoy to have found it, thank yo...</td>\n",
       "      <td>happy find thank offering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 14  2016</td>\n",
       "      <td>1713353</td>\n",
       "      <td>good comdition</td>\n",
       "      <td>good condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 24  2016</td>\n",
       "      <td>1713353</td>\n",
       "      <td>My students (3 &amp; 4 year olds) loved this book!...</td>\n",
       "      <td>student year old love book definitely recommen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11 12  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>A thought-provoking fable about unintended con...</td>\n",
       "      <td>thoughtprovoking fable unintended consequence ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 21  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>My favorite book as a child. My daughter's fav...</td>\n",
       "      <td>favorite book child daughter favorite book gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 9  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>LOVE IT</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.0</td>\n",
       "      <td>06 23  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>Great story. I loved it as a kid and now can r...</td>\n",
       "      <td>great story love kid read grandkids little ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>05 21  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>This is a cute story my children used to love....</td>\n",
       "      <td>cute story child use love grandson get chance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 9  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>Perfect!</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 18  2015</td>\n",
       "      <td>1713353</td>\n",
       "      <td>Great!</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>09 22  2014</td>\n",
       "      <td>1713353</td>\n",
       "      <td>This was my 51 year old daughters book, got th...</td>\n",
       "      <td>year old daughter book get one part birthday t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.0</td>\n",
       "      <td>09 13  2014</td>\n",
       "      <td>1713353</td>\n",
       "      <td>Great vintage book</td>\n",
       "      <td>great vintage book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.0</td>\n",
       "      <td>07 2  2014</td>\n",
       "      <td>1713353</td>\n",
       "      <td>One of my favorite books ever! So glad I found...</td>\n",
       "      <td>one favorite book ever glad find grandson surp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>06 20  2014</td>\n",
       "      <td>1713353</td>\n",
       "      <td>This was a favourite of my children, and we no...</td>\n",
       "      <td>favourite child copy grandchild remember word ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.0</td>\n",
       "      <td>04 21  2014</td>\n",
       "      <td>1713353</td>\n",
       "      <td>I'm using this book in a course on sustainabil...</td>\n",
       "      <td>use book course sustainability college level m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.0</td>\n",
       "      <td>02 14  2014</td>\n",
       "      <td>1713353</td>\n",
       "      <td>It was hard to find this original book in such...</td>\n",
       "      <td>hard find original book good shape price pay h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "      <td>11 3  2013</td>\n",
       "      <td>1713353</td>\n",
       "      <td>Over and over the king has problems.  Fortunat...</td>\n",
       "      <td>king problem fortunately wise men help solve p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10 8  2013</td>\n",
       "      <td>1713353</td>\n",
       "      <td>I remember reading my parents' copy of this bo...</td>\n",
       "      <td>remember reading parent copy book fell apart s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 12  2013</td>\n",
       "      <td>1713353</td>\n",
       "      <td>I am very happy with the book!!!  It is one of...</td>\n",
       "      <td>happy book one child favorite book please order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 7  2013</td>\n",
       "      <td>1713353</td>\n",
       "      <td>I remember reading this when I was a kid.  Fav...</td>\n",
       "      <td>remember reading kid favorite book fun find re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.0</td>\n",
       "      <td>01 2  2013</td>\n",
       "      <td>1713353</td>\n",
       "      <td>My copy is so tattered, worn and so loved.  A ...</td>\n",
       "      <td>copy tattered worn love well do plot sometimes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "      <td>12 27  2012</td>\n",
       "      <td>1713353</td>\n",
       "      <td>This was one of my favorites when I was a smal...</td>\n",
       "      <td>one favorites small child buy copy nephew star...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>08 15  2011</td>\n",
       "      <td>1713353</td>\n",
       "      <td>So, you think you have problems? Things could ...</td>\n",
       "      <td>think problem thing bad clever book prove king...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    overall   reviewTime     asin  \\\n",
       "0       5.0  08 12  2005  1713353   \n",
       "1       5.0  03 30  2005  1713353   \n",
       "2       5.0   04 4  2004  1713353   \n",
       "3       5.0  02 21  2004  1713353   \n",
       "4       5.0   10 3  2016  1713353   \n",
       "5       5.0  07 29  2016  1713353   \n",
       "6       5.0  06 20  2016  1713353   \n",
       "7       5.0  04 24  2016  1713353   \n",
       "8       5.0  02 14  2016  1713353   \n",
       "9       5.0  01 24  2016  1713353   \n",
       "10      5.0  11 12  2015  1713353   \n",
       "11      5.0  07 21  2015  1713353   \n",
       "12      5.0   07 9  2015  1713353   \n",
       "13      4.0  06 23  2015  1713353   \n",
       "14      5.0  05 21  2015  1713353   \n",
       "15      5.0   02 9  2015  1713353   \n",
       "16      5.0  01 18  2015  1713353   \n",
       "17      5.0  09 22  2014  1713353   \n",
       "18      5.0  09 13  2014  1713353   \n",
       "19      5.0   07 2  2014  1713353   \n",
       "20      5.0  06 20  2014  1713353   \n",
       "21      5.0  04 21  2014  1713353   \n",
       "22      5.0  02 14  2014  1713353   \n",
       "23      5.0   11 3  2013  1713353   \n",
       "24      5.0   10 8  2013  1713353   \n",
       "25      5.0  01 12  2013  1713353   \n",
       "26      5.0   01 7  2013  1713353   \n",
       "27      5.0   01 2  2013  1713353   \n",
       "28      5.0  12 27  2012  1713353   \n",
       "29      5.0  08 15  2011  1713353   \n",
       "\n",
       "                                           reviewText  \\\n",
       "0   This book is a winner with both of my boys.  T...   \n",
       "1   The King, the Mice and the Cheese by Nancy Gur...   \n",
       "2   My daughter got her first copy from her great-...   \n",
       "3   I remember this book from when I was a child a...   \n",
       "4   Just as I remembered it, one of my favorites f...   \n",
       "5   It is a very cute book with great illustration...   \n",
       "6                                  The kids loved it!   \n",
       "7   I was just so hapoy to have found it, thank yo...   \n",
       "8                                      good comdition   \n",
       "9   My students (3 & 4 year olds) loved this book!...   \n",
       "10  A thought-provoking fable about unintended con...   \n",
       "11  My favorite book as a child. My daughter's fav...   \n",
       "12                                            LOVE IT   \n",
       "13  Great story. I loved it as a kid and now can r...   \n",
       "14  This is a cute story my children used to love....   \n",
       "15                                           Perfect!   \n",
       "16                                             Great!   \n",
       "17  This was my 51 year old daughters book, got th...   \n",
       "18                                 Great vintage book   \n",
       "19  One of my favorite books ever! So glad I found...   \n",
       "20  This was a favourite of my children, and we no...   \n",
       "21  I'm using this book in a course on sustainabil...   \n",
       "22  It was hard to find this original book in such...   \n",
       "23  Over and over the king has problems.  Fortunat...   \n",
       "24  I remember reading my parents' copy of this bo...   \n",
       "25  I am very happy with the book!!!  It is one of...   \n",
       "26  I remember reading this when I was a kid.  Fav...   \n",
       "27  My copy is so tattered, worn and so loved.  A ...   \n",
       "28  This was one of my favorites when I was a smal...   \n",
       "29  So, you think you have problems? Things could ...   \n",
       "\n",
       "                                         cleaned_text  \n",
       "0        book winner boys enjoy picture story classic  \n",
       "1   king mouse cheese nancy gurney excellent child...  \n",
       "2   daughter get first copy greatgrandmother fathe...  \n",
       "3   remember book child year ago remember wonderfu...  \n",
       "4   remember one favorites childhood great conditi...  \n",
       "5   cute book great illustrationswith enjoyable st...  \n",
       "6                                            kid love  \n",
       "7                           happy find thank offering  \n",
       "8                                      good condition  \n",
       "9   student year old love book definitely recommen...  \n",
       "10  thoughtprovoking fable unintended consequence ...  \n",
       "11  favorite book child daughter favorite book gre...  \n",
       "12                                               love  \n",
       "13  great story love kid read grandkids little ove...  \n",
       "14  cute story child use love grandson get chance ...  \n",
       "15                                            perfect  \n",
       "16                                              great  \n",
       "17  year old daughter book get one part birthday t...  \n",
       "18                                 great vintage book  \n",
       "19  one favorite book ever glad find grandson surp...  \n",
       "20  favourite child copy grandchild remember word ...  \n",
       "21  use book course sustainability college level m...  \n",
       "22  hard find original book good shape price pay h...  \n",
       "23  king problem fortunately wise men help solve p...  \n",
       "24  remember reading parent copy book fell apart s...  \n",
       "25    happy book one child favorite book please order  \n",
       "26  remember reading kid favorite book fun find re...  \n",
       "27  copy tattered worn love well do plot sometimes...  \n",
       "28  one favorites small child buy copy nephew star...  \n",
       "29  think problem thing bad clever book prove king...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('reviews_cleaned.tsv',sep = '\\t' )\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
