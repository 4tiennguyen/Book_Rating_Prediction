{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob, Word\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Tu\n",
      "[nltk_data]     Lam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Tu\n",
      "[nltk_data]     Lam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Tu\n",
      "[nltk_data]     Lam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Tu Lam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "STOPWORDS = stopwords.words(\"english\") #stopwords are the most common unnecessary words. eg is, he, that, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS.append('could')\n",
    "STOPWORDS.append('also')\n",
    "STOPWORDS.append('would')\n",
    "STOPWORDS.append('really')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deEmojify(inputString):\n",
    "    return inputString.encode('ascii', 'ignore').decode('ascii') # A function to remove emojis from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_with_postag(sentence):\n",
    "    sent = TextBlob(sentence)\n",
    "    tag_dict = {\"J\": 'a', \n",
    "                \"N\": 'n', \n",
    "                \"V\": 'v', \n",
    "                \"R\": 'r'}\n",
    "    words_and_tags = [(w, tag_dict.get(pos[0], 'n')) for w, pos in sent.tags]    \n",
    "    lemmatized_list = [wd.lemmatize(tag) for wd, tag in words_and_tags]\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contraction convert, spelling check\n",
    "spell = Speller(lang='en')\n",
    "contractions_dict = {     \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I had\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"iit will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they had\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def expand_contractions(text, contractions_dict):\n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contractions_dict.keys())),\n",
    "                                      flags=re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contractions_dict.get(match) \\\n",
    "            if contractions_dict.get(match) \\\n",
    "            else contractions_dict.get(match.lower())\n",
    "        expanded_contraction = expanded_contraction\n",
    "        return expanded_contraction\n",
    "\n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    text=deEmojify(text) # remove emojis\n",
    "    text_cleaned = re.sub(' +', ' ', text) # remove extra white spaces\n",
    "    text_cleaned = remove_tags(text_cleaned) # remove tags\n",
    "    text_cleaned = text_cleaned.lower() # converting to lowercase\n",
    "    text_cleaned = ''.join(c for c in text_cleaned if not c.isdigit())# remove numbers\n",
    "    text_cleaned = expand_contractions(text_cleaned, contractions_dict) # contraction & spelling check\n",
    "    text_cleaned=\"\".join([x for x in text_cleaned if x not in string.punctuation]) # remove punctuation\n",
    "\n",
    "    text_cleaned = nltk.word_tokenize(text_cleaned)\n",
    "    text_cleaned = [x for x in text_cleaned if len(x) < 20]\n",
    "    text_cleaned = [spell(w) for w in (text_cleaned)]   # correct spelling\n",
    "    \n",
    "    # Taking only those words which are not stopwords\n",
    "    text_cleaned=\" \".join([token for token in text_cleaned if token not in STOPWORDS])\n",
    "\n",
    "    #Converting to lemma\n",
    "    text_cleaned = lemmatize_with_postag(str(text_cleaned))\n",
    "    \n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:648: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "# Track progress\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>publisher</th>\n",
       "      <th>description</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>format</th>\n",
       "      <th>genres</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>780911</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Houghton Mifflin Harcourt</td>\n",
       "      <td>\"Michel Faber leads us back to 1870s London, w...</td>\n",
       "      <td>838.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>{'fiction': 2428, 'history, historical fiction...</td>\n",
       "      <td>015100692X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>926667</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Mariner Books</td>\n",
       "      <td>A modern verse play about the search for meani...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>{'fiction': 30, 'poetry': 29}</td>\n",
       "      <td>0156182890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18498572</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Broadside Books</td>\n",
       "      <td>The dramatic, first-hand account of the histor...</td>\n",
       "      <td>384.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>{'history, historical fiction, biography': 30,...</td>\n",
       "      <td>0062310194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>268464</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>William Morrow</td>\n",
       "      <td>Celebrity journalist Amelia Stone is the quint...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>{'fiction': 15, 'history, historical fiction, ...</td>\n",
       "      <td>0061198722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>598199</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Oxford University Press, USA</td>\n",
       "      <td>Throughout African-American history, religion ...</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>{'history, historical fiction, biography': 10,...</td>\n",
       "      <td>0195145852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37234</td>\n",
       "      <td>5582304</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Da Capo Press</td>\n",
       "      <td>Drawing on intimate recollections from friends...</td>\n",
       "      <td>440.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>{'history, historical fiction, biography': 22,...</td>\n",
       "      <td>0306815869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37235</td>\n",
       "      <td>3106983</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>The Story of a Childhood and The Story of a Re...</td>\n",
       "      <td>343.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>{'comics, graphic': 7696, 'non-fiction': 1811,...</td>\n",
       "      <td>009952399X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37236</td>\n",
       "      <td>11873</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Vintage Classics</td>\n",
       "      <td>WINNER OF THE PULITZER PRIZE\\nIn 1831 Nat Turn...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>{'fiction': 688, 'history, historical fiction,...</td>\n",
       "      <td>0099285568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37237</td>\n",
       "      <td>823091</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Harcourt Brace College Publishers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>{'non-fiction': 3}</td>\n",
       "      <td>0153117362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37238</td>\n",
       "      <td>20663470</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Zonderkidz</td>\n",
       "      <td>Chosen by God\\nMary was more than the mother o...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>{'children': 1, 'young-adult': 1}</td>\n",
       "      <td>0310744806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37239 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id  publication_year  publication_month  publication_day  \\\n",
       "0        780911            2002.0                9.0             16.0   \n",
       "1        926667            1964.0                3.0             18.0   \n",
       "2      18498572            2014.0                5.0              6.0   \n",
       "3        268464            2007.0                5.0             29.0   \n",
       "4        598199            2001.0                2.0             22.0   \n",
       "...         ...               ...                ...              ...   \n",
       "37234   5582304            2009.0                6.0              1.0   \n",
       "37235   3106983            2008.0                3.0              6.0   \n",
       "37236     11873            2004.0                7.0              1.0   \n",
       "37237    823091            1988.0                1.0              1.0   \n",
       "37238  20663470            2014.0                7.0              8.0   \n",
       "\n",
       "                               publisher  \\\n",
       "0              Houghton Mifflin Harcourt   \n",
       "1                          Mariner Books   \n",
       "2                        Broadside Books   \n",
       "3                         William Morrow   \n",
       "4           Oxford University Press, USA   \n",
       "...                                  ...   \n",
       "37234                      Da Capo Press   \n",
       "37235                            Vintage   \n",
       "37236                   Vintage Classics   \n",
       "37237  Harcourt Brace College Publishers   \n",
       "37238                         Zonderkidz   \n",
       "\n",
       "                                             description  num_pages  \\\n",
       "0      \"Michel Faber leads us back to 1870s London, w...      838.0   \n",
       "1      A modern verse play about the search for meani...      190.0   \n",
       "2      The dramatic, first-hand account of the histor...      384.0   \n",
       "3      Celebrity journalist Amelia Stone is the quint...      288.0   \n",
       "4      Throughout African-American history, religion ...      184.0   \n",
       "...                                                  ...        ...   \n",
       "37234  Drawing on intimate recollections from friends...      440.0   \n",
       "37235  The Story of a Childhood and The Story of a Re...      343.0   \n",
       "37236  WINNER OF THE PULITZER PRIZE\\nIn 1831 Nat Turn...      480.0   \n",
       "37237                                                NaN        NaN   \n",
       "37238  Chosen by God\\nMary was more than the mother o...      110.0   \n",
       "\n",
       "          format                                             genres  \\\n",
       "0      Hardcover  {'fiction': 2428, 'history, historical fiction...   \n",
       "1      Paperback                      {'fiction': 30, 'poetry': 29}   \n",
       "2      Hardcover  {'history, historical fiction, biography': 30,...   \n",
       "3      Hardcover  {'fiction': 15, 'history, historical fiction, ...   \n",
       "4      Paperback  {'history, historical fiction, biography': 10,...   \n",
       "...          ...                                                ...   \n",
       "37234  Hardcover  {'history, historical fiction, biography': 22,...   \n",
       "37235  Paperback  {'comics, graphic': 7696, 'non-fiction': 1811,...   \n",
       "37236  Paperback  {'fiction': 688, 'history, historical fiction,...   \n",
       "37237  Hardcover                                 {'non-fiction': 3}   \n",
       "37238  Paperback                  {'children': 1, 'young-adult': 1}   \n",
       "\n",
       "             asin  \n",
       "0      015100692X  \n",
       "1      0156182890  \n",
       "2      0062310194  \n",
       "3      0061198722  \n",
       "4      0195145852  \n",
       "...           ...  \n",
       "37234  0306815869  \n",
       "37235  009952399X  \n",
       "37236  0099285568  \n",
       "37237  0153117362  \n",
       "37238  0310744806  \n",
       "\n",
       "[37239 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load current dataframe\n",
    "metadata = pd.read_csv('book_metadata.csv')\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>780911</td>\n",
       "      <td>015100692X</td>\n",
       "      <td>\"Michel Faber leads us back to 1870s London, w...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>926667</td>\n",
       "      <td>0156182890</td>\n",
       "      <td>A modern verse play about the search for meani...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18498572</td>\n",
       "      <td>0062310194</td>\n",
       "      <td>The dramatic, first-hand account of the histor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>268464</td>\n",
       "      <td>0061198722</td>\n",
       "      <td>Celebrity journalist Amelia Stone is the quint...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>598199</td>\n",
       "      <td>0195145852</td>\n",
       "      <td>Throughout African-American history, religion ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37234</td>\n",
       "      <td>5582304</td>\n",
       "      <td>0306815869</td>\n",
       "      <td>Drawing on intimate recollections from friends...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37235</td>\n",
       "      <td>3106983</td>\n",
       "      <td>009952399X</td>\n",
       "      <td>The Story of a Childhood and The Story of a Re...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37236</td>\n",
       "      <td>11873</td>\n",
       "      <td>0099285568</td>\n",
       "      <td>WINNER OF THE PULITZER PRIZE\\nIn 1831 Nat Turn...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37237</td>\n",
       "      <td>823091</td>\n",
       "      <td>0153117362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37238</td>\n",
       "      <td>20663470</td>\n",
       "      <td>0310744806</td>\n",
       "      <td>Chosen by God\\nMary was more than the mother o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37239 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_id        asin  \\\n",
       "0        780911  015100692X   \n",
       "1        926667  0156182890   \n",
       "2      18498572  0062310194   \n",
       "3        268464  0061198722   \n",
       "4        598199  0195145852   \n",
       "...         ...         ...   \n",
       "37234   5582304  0306815869   \n",
       "37235   3106983  009952399X   \n",
       "37236     11873  0099285568   \n",
       "37237    823091  0153117362   \n",
       "37238  20663470  0310744806   \n",
       "\n",
       "                                             description  cleaned_description  \n",
       "0      \"Michel Faber leads us back to 1870s London, w...                  NaN  \n",
       "1      A modern verse play about the search for meani...                  NaN  \n",
       "2      The dramatic, first-hand account of the histor...                  NaN  \n",
       "3      Celebrity journalist Amelia Stone is the quint...                  NaN  \n",
       "4      Throughout African-American history, religion ...                  NaN  \n",
       "...                                                  ...                  ...  \n",
       "37234  Drawing on intimate recollections from friends...                  NaN  \n",
       "37235  The Story of a Childhood and The Story of a Re...                  NaN  \n",
       "37236  WINNER OF THE PULITZER PRIZE\\nIn 1831 Nat Turn...                  NaN  \n",
       "37237                                                NaN                  NaN  \n",
       "37238  Chosen by God\\nMary was more than the mother o...                  NaN  \n",
       "\n",
       "[37239 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe for cleaned text descriptions\n",
    "df = metadata[['book_id', 'asin', 'description']]\n",
    "df['cleaned_description'] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 37239/37239 [10:18:35<00:00,  1.00it/s]\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Clean text\n",
    "df['cleaned_description'] = df.progress_apply(lambda row: clean_text(row.description), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('goodreads_description.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
