{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_num_pages</th>\n",
       "      <th>gr_format</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_genres</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>poetry, fiction, non-fiction</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>history, historical fiction, biography, non-fi...</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover,  Audi...</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poetry, children</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>children, fiction, young-adult, history, histo...</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children, fiction, poetry, fantasy, paranormal</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.11</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>156.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>Kindle Edition,  Hardcover</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>mystery, thriller, crime, fiction</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>0.07</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>187.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>0.45</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>60.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>mystery, thriller, crime, fiction, history, hi...</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  gr_pub_yr  gr_pub_mo  gr_pub_day  gr_num_pages  gr_format  \\\n",
       "0      000100039X     2010.0        1.0         1.0         127.0  Paperback   \n",
       "1      0001053655     1997.0        NaN         NaN         268.0  Hardcover   \n",
       "2      0001061240     1959.0       12.0         1.0         324.0  Hardcover   \n",
       "3      000161102X        NaN        NaN         NaN         190.0        NaN   \n",
       "4      0001711296        NaN        NaN         NaN          63.0        NaN   \n",
       "...           ...        ...        ...         ...           ...        ...   \n",
       "37228  0312953240     1995.0        7.0        15.0         570.0  Paperback   \n",
       "37229  0312955138     1995.0        9.0        15.0         320.0  Paperback   \n",
       "37230  0312955154     1995.0       10.0        15.0           NaN  Paperback   \n",
       "37231  0312956878     1995.0       10.0        15.0         608.0  Paperback   \n",
       "37232  0312956959     1996.0        1.0        28.0         308.0  Paperback   \n",
       "\n",
       "       gr_countDes_before  gr_countDes_after  \\\n",
       "0                   106.0               66.0   \n",
       "1                     NaN                NaN   \n",
       "2                     NaN                NaN   \n",
       "3                    47.0               25.0   \n",
       "4                     NaN                NaN   \n",
       "...                   ...                ...   \n",
       "37228                41.0               20.0   \n",
       "37229               156.0               82.0   \n",
       "37230                48.0               33.0   \n",
       "37231               187.0              103.0   \n",
       "37232                60.0               39.0   \n",
       "\n",
       "                                               gr_genres  gr_countText_before  \\\n",
       "0                           poetry, fiction, non-fiction                42320   \n",
       "1      history, historical fiction, biography, non-fi...                  158   \n",
       "2                                       poetry, children                   49   \n",
       "3      children, fiction, young-adult, history, histo...                  130   \n",
       "4         children, fiction, poetry, fantasy, paranormal                  257   \n",
       "...                                                  ...                  ...   \n",
       "37228              mystery, thriller, crime, non-fiction                  219   \n",
       "37229              mystery, thriller, crime, non-fiction                  125   \n",
       "37230                  mystery, thriller, crime, fiction                  362   \n",
       "37231              mystery, thriller, crime, non-fiction                  152   \n",
       "37232  mystery, thriller, crime, fiction, history, hi...                  137   \n",
       "\n",
       "       gr_countText_after  am_rank  am_verifiedTrue_count  \\\n",
       "0                   17834  1810945                   1130   \n",
       "1                      75  9799161                     43   \n",
       "2                      18   321557                     30   \n",
       "3                      61  1542999                     13   \n",
       "4                     117  2884610                     69   \n",
       "...                   ...      ...                    ...   \n",
       "37228                  94   443719                      4   \n",
       "37229                  52  3470182                      6   \n",
       "37230                 184  3412599                      4   \n",
       "37231                  76  2606128                      9   \n",
       "37232                  72  2880300                     26   \n",
       "\n",
       "                                               am_format  am_countText_before  \\\n",
       "0                                                    NaN                69909   \n",
       "1       Kindle Edition,  Paperback,  Hardcover,  Audi...                 4888   \n",
       "2                                              Hardcover                 3085   \n",
       "3                                                    NaN                  788   \n",
       "4       Library Binding,  VHS Tape,  Paperback,  Hard...                 5667   \n",
       "...                                                  ...                  ...   \n",
       "37228                  Mass Market Paperback,  Hardcover                 2599   \n",
       "37229                         Kindle Edition,  Hardcover                 1489   \n",
       "37230                         Kindle Edition,  Paperback                 1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                  968   \n",
       "37232             Kindle Edition,  Paperback,  Hardcover                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  ratings_count  text_reviews_count  \n",
       "0                   31772        -0.41         221541               10300  \n",
       "1                    2240        -0.40            726                 135  \n",
       "2                    1326        -0.25            266                  81  \n",
       "3                     399        -0.49           2946                  92  \n",
       "4                    2574        -0.15            845                 172  \n",
       "...                   ...          ...            ...                 ...  \n",
       "37228                1216         0.11            100                  21  \n",
       "37229                 668        -0.20             41                  16  \n",
       "37230                 683         0.07             70                  19  \n",
       "37231                 450         0.45             74                  19  \n",
       "37232                2184        -0.56            422                 111  \n",
       "\n",
       "[37233 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = pd.read_csv('official_goodreads_metadata.csv')\n",
    "am = pd.read_csv('official_amazon_metadata.csv')\n",
    "am_gr = pd.merge(gr[['asin', 'average_rating', 'total_ratings_count', 'total_reviews_count', 'total_text_reviews_count',\n",
    "                    'publication_year', 'publication_month', 'publication_day', 'num_pages', 'format', 'gr_countDes_before',\n",
    "                    'gr_countDes_after', 'cleaned_genres', 'gr_countText_before', 'gr_countText_after']],\n",
    "                 am[['asin', 'average', 'rating_count', 'text_reviews_count', 'rank', 'verifiedTrue_count', 'Format',\n",
    "                    'am_countText_before', 'am_countText_after']], how='inner', on='asin')\n",
    "am_gr = am_gr.rename(columns={'average_rating':'gr_rating', 'total_ratings_count':'gr_ratings_count', \n",
    "                              'total_reviews_count':'gr_reviews_count', 'total_text_reviews_count':'gr_text_reviews_count',\n",
    "                              'publication_year':'gr_pub_yr', 'publication_month':'gr_pub_mo', 'publication_day':'gr_pub_day',\n",
    "                              'num_pages':'gr_num_pages', 'format':'gr_format', 'cleaned_genres':'gr_genres', \n",
    "                              'average':'am_rating', 'rating_count':'am_ratings_count', \n",
    "                              'text_reviews_count':'am_text_reviews_count', 'rank':'am_rank',\n",
    "                              'verifiedTrue_count':'am_verifiedTrue_count', 'Format':'am_format'})\n",
    "am_gr['rating_diff'] = am_gr['gr_rating'] - am_gr['am_rating']\n",
    "am_gr['ratings_count'] = am_gr['gr_ratings_count'] + am_gr['am_ratings_count']\n",
    "am_gr['text_reviews_count'] = am_gr['gr_text_reviews_count'] + am_gr['am_text_reviews_count']\n",
    "am_gr = am_gr.drop('gr_ratings_count', axis=1)\n",
    "am_gr = am_gr.drop('gr_reviews_count', axis=1)\n",
    "am_gr = am_gr.drop('gr_text_reviews_count', axis=1)\n",
    "am_gr = am_gr.drop('am_ratings_count', axis=1)\n",
    "am_gr = am_gr.drop('am_text_reviews_count', axis=1)\n",
    "am_gr = am_gr.drop('gr_rating', axis=1)\n",
    "am_gr = am_gr.drop('am_rating', axis=1)\n",
    "am_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_num_pages             1630\n",
       "gr_format                1535\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_genres                 199\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_format                  49\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "rating_diff                 0\n",
       "ratings_count               0\n",
       "text_reviews_count          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23786310198771948\n",
      "Mean Squared Error: 0.1045902287749011\n",
      "Root Mean Squared Error: 0.32340412609442865\n",
      "R2 Score: 0.06870658233604654\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.24009930378277686\n",
      "Mean Squared Error: 0.10611681199561204\n",
      "Root Mean Squared Error: 0.32575575512277916\n",
      "R2 Score: 0.05888039317085303\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr[['gr_countText_before', 'gr_countText_after', 'am_rank', 'am_verifiedTrue_count', 'am_countText_before',\n",
    "            'am_countText_after', 'ratings_count', 'text_reviews_count']]\n",
    "Y = am_gr['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All numeric features w/ null rows removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_all = am_gr[['asin', 'gr_pub_yr', 'gr_pub_mo', 'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                           'gr_countText_before', 'gr_countText_after', 'am_rank', 'am_verifiedTrue_count', \n",
    "                           'am_countText_before', 'am_countText_after', 'rating_diff', 'ratings_count', 'text_reviews_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_no_null = am_gr_numeric_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23645375430125162\n",
      "Mean Squared Error: 0.10254021322182508\n",
      "Root Mean Squared Error: 0.32021900821441734\n",
      "R2 Score: 0.0815204910077223\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.2374347419066162\n",
      "Mean Squared Error: 0.10499411636769387\n",
      "Root Mean Squared Error: 0.3240279561514621\n",
      "R2 Score: 0.07273423383488054\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr_numeric_no_null.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = am_gr_numeric_no_null['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Not much better than the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All numeric features w/ null values replaced by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_mean = am_gr_numeric_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "rating_diff                 0\n",
       "ratings_count               0\n",
       "text_reviews_count          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_numeric_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Fill null values with mean\n",
    "am_gr_numeric_mean['gr_pub_yr'].fillna(am_gr_numeric_mean['gr_pub_yr'].mean(), inplace=True)\n",
    "am_gr_numeric_mean['gr_pub_mo'].fillna(am_gr_numeric_mean['gr_pub_mo'].mean(), inplace=True)\n",
    "am_gr_numeric_mean['gr_pub_day'].fillna(am_gr_numeric_mean['gr_pub_day'].mean(), inplace=True)\n",
    "am_gr_numeric_mean['gr_countDes_before'].fillna(am_gr_numeric_mean['gr_countDes_before'].mean(), inplace=True)\n",
    "# If gr_countDes_after value is null, copy the value from gr_countDes_before\n",
    "am_gr_numeric_mean['gr_countDes_after'] = np.where(am_gr_numeric_mean['gr_countDes_after'].isnull(), am_gr_numeric_mean['gr_countDes_before'], am_gr_numeric_mean['gr_countDes_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "rating_diff              0\n",
       "ratings_count            0\n",
       "text_reviews_count       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_numeric_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23613797208911066\n",
      "Mean Squared Error: 0.10261757471601843\n",
      "Root Mean Squared Error: 0.3203397801023445\n",
      "R2 Score: 0.08627150940317596\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.23946998499136268\n",
      "Mean Squared Error: 0.1050815229979144\n",
      "Root Mean Squared Error: 0.3241628032299733\n",
      "R2 Score: 0.06806207471729864\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr_numeric_mean.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = am_gr_numeric_mean['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All numeric features w/ null values replaced by median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_median = am_gr_numeric_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Fill null values with mean\n",
    "am_gr_numeric_median['gr_pub_yr'].fillna(am_gr_numeric_median['gr_pub_yr'].median(), inplace=True)\n",
    "am_gr_numeric_median['gr_pub_mo'].fillna(am_gr_numeric_median['gr_pub_mo'].median(), inplace=True)\n",
    "am_gr_numeric_median['gr_pub_day'].fillna(am_gr_numeric_median['gr_pub_day'].median(), inplace=True)\n",
    "am_gr_numeric_median['gr_countDes_before'].fillna(am_gr_numeric_median['gr_countDes_before'].median(), inplace=True)\n",
    "# If gr_countDes_after value is null, copy the value from gr_countDes_before\n",
    "am_gr_numeric_median['gr_countDes_after'] = np.where(am_gr_numeric_median['gr_countDes_after'].isnull(), am_gr_numeric_median['gr_countDes_before'], am_gr_numeric_median['gr_countDes_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23757282787773895\n",
      "Mean Squared Error: 0.10329496598234364\n",
      "Root Mean Squared Error: 0.32139534219142574\n",
      "R2 Score: 0.08023987494839868\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.24081286042323347\n",
      "Mean Squared Error: 0.10595214944481854\n",
      "Root Mean Squared Error: 0.3255029177208993\n",
      "R2 Score: 0.06034073816377161\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr_numeric_median.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = am_gr_numeric_median['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Not as good as replacing it with the mean, about the same as removing null rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gr_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audible audio</th>\n",
       "      <th>audio</th>\n",
       "      <th>audio cassette</th>\n",
       "      <th>audio cd</th>\n",
       "      <th>audio cd (unabridged)</th>\n",
       "      <th>audiobook</th>\n",
       "      <th>b</th>\n",
       "      <th>big book</th>\n",
       "      <th>board book</th>\n",
       "      <th>boxed set - hardcover</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.11</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>0.07</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>0.45</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       audible audio  audio  audio cassette  audio cd  audio cd (unabridged)  \\\n",
       "0                  0      0               0         0                      0   \n",
       "1                  0      0               0         0                      0   \n",
       "2                  0      0               0         0                      0   \n",
       "3                  0      0               0         0                      0   \n",
       "4                  0      0               0         0                      0   \n",
       "...              ...    ...             ...       ...                    ...   \n",
       "37228              0      0               0         0                      0   \n",
       "37229              0      0               0         0                      0   \n",
       "37230              0      0               0         0                      0   \n",
       "37231              0      0               0         0                      0   \n",
       "37232              0      0               0         0                      0   \n",
       "\n",
       "       audiobook  b  big book  board book  boxed set - hardcover  ...  \\\n",
       "0              0  0         0           0                      0  ...   \n",
       "1              0  0         0           0                      0  ...   \n",
       "2              0  0         0           0                      0  ...   \n",
       "3              0  0         0           0                      0  ...   \n",
       "4              0  0         0           0                      0  ...   \n",
       "...          ... ..       ...         ...                    ...  ...   \n",
       "37228          0  0         0           0                      0  ...   \n",
       "37229          0  0         0           0                      0  ...   \n",
       "37230          0  0         0           0                      0  ...   \n",
       "37231          0  0         0           0                      0  ...   \n",
       "37232          0  0         0           0                      0  ...   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0              66.000000                42320               17834  1810945   \n",
       "1             160.689085                  158                  75  9799161   \n",
       "2             160.689085                   49                  18   321557   \n",
       "3              25.000000                  130                  61  1542999   \n",
       "4             160.689085                  257                 117  2884610   \n",
       "...                  ...                  ...                 ...      ...   \n",
       "37228          20.000000                  219                  94   443719   \n",
       "37229          82.000000                  125                  52  3470182   \n",
       "37230          33.000000                  362                 184  3412599   \n",
       "37231         103.000000                  152                  76  2606128   \n",
       "37232          39.000000                  137                  72  2880300   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before  am_countText_after  \\\n",
       "0                       1130                69909               31772   \n",
       "1                         43                 4888                2240   \n",
       "2                         30                 3085                1326   \n",
       "3                         13                  788                 399   \n",
       "4                         69                 5667                2574   \n",
       "...                      ...                  ...                 ...   \n",
       "37228                      4                 2599                1216   \n",
       "37229                      6                 1489                 668   \n",
       "37230                      4                 1456                 683   \n",
       "37231                      9                  968                 450   \n",
       "37232                     26                 4356                2184   \n",
       "\n",
       "       rating_diff  ratings_count  text_reviews_count  \n",
       "0            -0.41         221541               10300  \n",
       "1            -0.40            726                 135  \n",
       "2            -0.25            266                  81  \n",
       "3            -0.49           2946                  92  \n",
       "4            -0.15            845                 172  \n",
       "...            ...            ...                 ...  \n",
       "37228         0.11            100                  21  \n",
       "37229        -0.20             41                  16  \n",
       "37230         0.07             70                  19  \n",
       "37231         0.45             74                  19  \n",
       "37232        -0.56            422                 111  \n",
       "\n",
       "[37233 rows x 54 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['gr_format'].str.strip().str.lower())\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23774729390137228\n",
      "Mean Squared Error: 0.10318032542033881\n",
      "Root Mean Squared Error: 0.3212169444788659\n",
      "R2 Score: 0.08126065864916066\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.24165933919654553\n",
      "Mean Squared Error: 0.1059840972019457\n",
      "Root Mean Squared Error: 0.32555198847794753\n",
      "R2 Score: 0.0600574026577273\n"
     ]
    }
   ],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gr_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['gr_genres'] = am_gr['gr_genres'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historicalfiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.11</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>0.07</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>0.45</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       biography  children  comics  crime  fantasy  fiction  graphic  \\\n",
       "0              0         0       0      0        0        1        0   \n",
       "1              1         0       1      0        0        1        1   \n",
       "2              0         1       0      0        0        0        0   \n",
       "3              1         1       0      0        0        1        0   \n",
       "4              0         1       0      0        1        1        0   \n",
       "...          ...       ...     ...    ...      ...      ...      ...   \n",
       "37228          0         0       0      1        0        0        0   \n",
       "37229          0         0       0      1        0        0        0   \n",
       "37230          0         0       0      1        0        1        0   \n",
       "37231          0         0       0      1        0        0        0   \n",
       "37232          1         0       0      1        1        1        0   \n",
       "\n",
       "       historicalfiction  history  mystery  ...  gr_countDes_after  \\\n",
       "0                      0        0        0  ...          66.000000   \n",
       "1                      1        1        0  ...         160.689085   \n",
       "2                      0        0        0  ...         160.689085   \n",
       "3                      1        1        0  ...          25.000000   \n",
       "4                      0        0        0  ...         160.689085   \n",
       "...                  ...      ...      ...  ...                ...   \n",
       "37228                  0        0        1  ...          20.000000   \n",
       "37229                  0        0        1  ...          82.000000   \n",
       "37230                  0        0        1  ...          33.000000   \n",
       "37231                  0        0        1  ...         103.000000   \n",
       "37232                  1        1        1  ...          39.000000   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0                    42320               17834  1810945   \n",
       "1                      158                  75  9799161   \n",
       "2                       49                  18   321557   \n",
       "3                      130                  61  1542999   \n",
       "4                      257                 117  2884610   \n",
       "...                    ...                 ...      ...   \n",
       "37228                  219                  94   443719   \n",
       "37229                  125                  52  3470182   \n",
       "37230                  362                 184  3412599   \n",
       "37231                  152                  76  2606128   \n",
       "37232                  137                  72  2880300   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before am_countText_after  \\\n",
       "0                       1130                69909              31772   \n",
       "1                         43                 4888               2240   \n",
       "2                         30                 3085               1326   \n",
       "3                         13                  788                399   \n",
       "4                         69                 5667               2574   \n",
       "...                      ...                  ...                ...   \n",
       "37228                      4                 2599               1216   \n",
       "37229                      6                 1489                668   \n",
       "37230                      4                 1456                683   \n",
       "37231                      9                  968                450   \n",
       "37232                     26                 4356               2184   \n",
       "\n",
       "       rating_diff  ratings_count  text_reviews_count  \n",
       "0            -0.41         221541               10300  \n",
       "1            -0.40            726                 135  \n",
       "2            -0.25            266                  81  \n",
       "3            -0.49           2946                  92  \n",
       "4            -0.15            845                 172  \n",
       "...            ...            ...                 ...  \n",
       "37228         0.11            100                  21  \n",
       "37229        -0.20             41                  16  \n",
       "37230         0.07             70                  19  \n",
       "37231         0.45             74                  19  \n",
       "37232        -0.56            422                 111  \n",
       "\n",
       "[37233 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['gr_genres'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['biography', 'children', 'comics', 'crime', 'fantasy', 'fiction',\n",
       "       'graphic', 'historicalfiction', 'history', 'mystery', 'non-fiction',\n",
       "       'paranormal', 'poetry', 'romance', 'thriller', 'young-adult', 'asin',\n",
       "       'gr_pub_yr', 'gr_pub_mo', 'gr_pub_day', 'gr_countDes_before',\n",
       "       'gr_countDes_after', 'gr_countText_before', 'gr_countText_after',\n",
       "       'am_rank', 'am_verifiedTrue_count', 'am_countText_before',\n",
       "       'am_countText_after', 'rating_diff', 'ratings_count',\n",
       "       'text_reviews_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.22962216629932292\n",
      "Mean Squared Error: 0.0982336306814491\n",
      "Root Mean Squared Error: 0.31342244763489596\n",
      "R2 Score: 0.1253070700920088\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.23635039109720085\n",
      "Mean Squared Error: 0.10368137446814875\n",
      "Root Mean Squared Error: 0.3219959230613778\n",
      "R2 Score: 0.08047959093414425\n"
     ]
    }
   ],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best one so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding am_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['am_format'] = am_gr['am_format'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessory</th>\n",
       "      <th>AmazonVideo</th>\n",
       "      <th>AudibleAudiobook</th>\n",
       "      <th>AudioCD</th>\n",
       "      <th>AudioCDLibraryBinding</th>\n",
       "      <th>AudioCassette</th>\n",
       "      <th>BargainBook</th>\n",
       "      <th>BathBook</th>\n",
       "      <th>Blu-ray</th>\n",
       "      <th>Boardbook</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.11</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>0.07</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>0.45</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accessory  AmazonVideo  AudibleAudiobook  AudioCD  \\\n",
       "0              0            0                 0        0   \n",
       "1              0            0                 0        0   \n",
       "2              0            0                 0        0   \n",
       "3              0            0                 0        0   \n",
       "4              0            0                 0        0   \n",
       "...          ...          ...               ...      ...   \n",
       "37228          0            0                 0        0   \n",
       "37229          0            0                 0        0   \n",
       "37230          0            0                 0        0   \n",
       "37231          0            0                 0        0   \n",
       "37232          0            0                 0        0   \n",
       "\n",
       "       AudioCDLibraryBinding  AudioCassette  BargainBook  BathBook  Blu-ray  \\\n",
       "0                          0              0            0         0        0   \n",
       "1                          0              1            0         0        0   \n",
       "2                          0              0            0         0        0   \n",
       "3                          0              0            0         0        0   \n",
       "4                          0              0            0         0        0   \n",
       "...                      ...            ...          ...       ...      ...   \n",
       "37228                      0              0            0         0        0   \n",
       "37229                      0              0            0         0        0   \n",
       "37230                      0              0            0         0        0   \n",
       "37231                      0              0            0         0        0   \n",
       "37232                      0              0            0         0        0   \n",
       "\n",
       "       Boardbook  ...  gr_countDes_after  gr_countText_before  \\\n",
       "0              0  ...          66.000000                42320   \n",
       "1              0  ...         160.689085                  158   \n",
       "2              0  ...         160.689085                   49   \n",
       "3              0  ...          25.000000                  130   \n",
       "4              0  ...         160.689085                  257   \n",
       "...          ...  ...                ...                  ...   \n",
       "37228          0  ...          20.000000                  219   \n",
       "37229          0  ...          82.000000                  125   \n",
       "37230          0  ...          33.000000                  362   \n",
       "37231          0  ...         103.000000                  152   \n",
       "37232          0  ...          39.000000                  137   \n",
       "\n",
       "       gr_countText_after  am_rank  am_verifiedTrue_count  \\\n",
       "0                   17834  1810945                   1130   \n",
       "1                      75  9799161                     43   \n",
       "2                      18   321557                     30   \n",
       "3                      61  1542999                     13   \n",
       "4                     117  2884610                     69   \n",
       "...                   ...      ...                    ...   \n",
       "37228                  94   443719                      4   \n",
       "37229                  52  3470182                      6   \n",
       "37230                 184  3412599                      4   \n",
       "37231                  76  2606128                      9   \n",
       "37232                  72  2880300                     26   \n",
       "\n",
       "       am_countText_before  am_countText_after  rating_diff  ratings_count  \\\n",
       "0                    69909               31772        -0.41         221541   \n",
       "1                     4888                2240        -0.40            726   \n",
       "2                     3085                1326        -0.25            266   \n",
       "3                      788                 399        -0.49           2946   \n",
       "4                     5667                2574        -0.15            845   \n",
       "...                    ...                 ...          ...            ...   \n",
       "37228                 2599                1216         0.11            100   \n",
       "37229                 1489                 668        -0.20             41   \n",
       "37230                 1456                 683         0.07             70   \n",
       "37231                  968                 450         0.45             74   \n",
       "37232                 4356                2184        -0.56            422   \n",
       "\n",
       "       text_reviews_count  \n",
       "0                   10300  \n",
       "1                     135  \n",
       "2                      81  \n",
       "3                      92  \n",
       "4                     172  \n",
       "...                   ...  \n",
       "37228                  21  \n",
       "37229                  16  \n",
       "37230                  19  \n",
       "37231                  19  \n",
       "37232                 111  \n",
       "\n",
       "[37233 rows x 85 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['am_format'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23337744133590396\n",
      "Mean Squared Error: 0.10010175664045723\n",
      "Root Mean Squared Error: 0.3163886164836801\n",
      "R2 Score: 0.10867288323373381\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.2413723116327046\n",
      "Mean Squared Error: 0.10689032297862434\n",
      "Root Mean Squared Error: 0.3269408554748463\n",
      "R2 Score: 0.05202034584639459\n"
     ]
    }
   ],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['gr_genres'] = am_gr['gr_genres'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historicalfiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.11</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>0.07</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>0.45</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       biography  children  comics  crime  fantasy  fiction  graphic  \\\n",
       "0              0         0       0      0        0        1        0   \n",
       "1              1         0       1      0        0        1        1   \n",
       "2              0         1       0      0        0        0        0   \n",
       "3              1         1       0      0        0        1        0   \n",
       "4              0         1       0      0        1        1        0   \n",
       "...          ...       ...     ...    ...      ...      ...      ...   \n",
       "37228          0         0       0      1        0        0        0   \n",
       "37229          0         0       0      1        0        0        0   \n",
       "37230          0         0       0      1        0        1        0   \n",
       "37231          0         0       0      1        0        0        0   \n",
       "37232          1         0       0      1        1        1        0   \n",
       "\n",
       "       historicalfiction  history  mystery  ...  gr_countDes_after  \\\n",
       "0                      0        0        0  ...          66.000000   \n",
       "1                      1        1        0  ...         160.689085   \n",
       "2                      0        0        0  ...         160.689085   \n",
       "3                      1        1        0  ...          25.000000   \n",
       "4                      0        0        0  ...         160.689085   \n",
       "...                  ...      ...      ...  ...                ...   \n",
       "37228                  0        0        1  ...          20.000000   \n",
       "37229                  0        0        1  ...          82.000000   \n",
       "37230                  0        0        1  ...          33.000000   \n",
       "37231                  0        0        1  ...         103.000000   \n",
       "37232                  1        1        1  ...          39.000000   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0                    42320               17834  1810945   \n",
       "1                      158                  75  9799161   \n",
       "2                       49                  18   321557   \n",
       "3                      130                  61  1542999   \n",
       "4                      257                 117  2884610   \n",
       "...                    ...                 ...      ...   \n",
       "37228                  219                  94   443719   \n",
       "37229                  125                  52  3470182   \n",
       "37230                  362                 184  3412599   \n",
       "37231                  152                  76  2606128   \n",
       "37232                  137                  72  2880300   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before am_countText_after  \\\n",
       "0                       1130                69909              31772   \n",
       "1                         43                 4888               2240   \n",
       "2                         30                 3085               1326   \n",
       "3                         13                  788                399   \n",
       "4                         69                 5667               2574   \n",
       "...                      ...                  ...                ...   \n",
       "37228                      4                 2599               1216   \n",
       "37229                      6                 1489                668   \n",
       "37230                      4                 1456                683   \n",
       "37231                      9                  968                450   \n",
       "37232                     26                 4356               2184   \n",
       "\n",
       "       rating_diff  ratings_count  text_reviews_count  \n",
       "0            -0.41         221541               10300  \n",
       "1            -0.40            726                 135  \n",
       "2            -0.25            266                  81  \n",
       "3            -0.49           2946                  92  \n",
       "4            -0.15            845                 172  \n",
       "...            ...            ...                 ...  \n",
       "37228         0.11            100                  21  \n",
       "37229        -0.20             41                  16  \n",
       "37230         0.07             70                  19  \n",
       "37231         0.45             74                  19  \n",
       "37232        -0.56            422                 111  \n",
       "\n",
       "[37233 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['gr_genres'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Keep it at 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: activation = 'relu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23015568819080812\n",
      "Mean Squared Error: 0.09830625360992003\n",
      "Root Mean Squared Error: 0.3135382809322014\n",
      "R2 Score: 0.12466042024671575\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.23440243835680682\n",
      "Mean Squared Error: 0.1021820982113065\n",
      "Root Mean Squared Error: 0.3196593471358322\n",
      "R2 Score: 0.09377624256580075\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,), solver='lbfgs', max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Verdict: solver='lbfgs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.23001336115322873\n",
      "Mean Squared Error: 0.09826593813590476\n",
      "Root Mean Squared Error: 0.31347398318824604\n",
      "R2 Score: 0.12501939771545445\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.233364356318945\n",
      "Mean Squared Error: 0.10167990231034822\n",
      "Root Mean Squared Error: 0.318872862298359\n",
      "R2 Score: 0.098230074149816\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,), solver='lbfgs', alpha=0.001, max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.002, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14,), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.22774252705173897\n",
      "Mean Squared Error: 0.09618239250606889\n",
      "Root Mean Squared Error: 0.31013286266706547\n",
      "R2 Score: 0.14357172667770146\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.2316190806863135\n",
      "Mean Squared Error: 0.09987613935056316\n",
      "Root Mean Squared Error: 0.3160318644544616\n",
      "R2 Score: 0.11422713112506788\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,), solver='lbfgs', alpha=0.002, max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: alpha=0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: learning_rate = 'constant'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: keep it at 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MLPRegressor(activation='relu', alpha=0.002, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=(14,), learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='lbfgs', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "TRAIN DATA:\n",
    "Mean Absolute Error: 0.22774252705173897\n",
    "Mean Squared Error: 0.09618239250606889\n",
    "Root Mean Squared Error: 0.31013286266706547\n",
    "R2 Score: 0.14357172667770146\n",
    "TEST DATA:\n",
    "Mean Absolute Error: 0.2316190806863135\n",
    "Mean Squared Error: 0.09987613935056316\n",
    "Root Mean Squared Error: 0.3160318644544616\n",
    "R2 Score: 0.11422713112506788\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
