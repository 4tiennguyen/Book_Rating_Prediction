{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL OUT: For faster processing\n",
    "num_cpu = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_reviews_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>format</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>cleaned_genres</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>4.23</td>\n",
       "      <td>186297</td>\n",
       "      <td>163625</td>\n",
       "      <td>5535</td>\n",
       "      <td>220088</td>\n",
       "      <td>196528</td>\n",
       "      <td>8847</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Rupa &amp; Co</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Kahlil Gibran's masterpiece, The Prophet, is o...</td>\n",
       "      <td>tahsil vibrants masterpiece prophet one belove...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>poetry, fiction, non-fiction</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>4.08</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>6</td>\n",
       "      <td>676</td>\n",
       "      <td>1552</td>\n",
       "      <td>85</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>history, historical fiction, biography, non-fi...</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>4.62</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>221</td>\n",
       "      <td>603</td>\n",
       "      <td>36</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Western Publishing Company</td>\n",
       "      <td>324.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poetry, children</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>3.86</td>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "      <td>2929</td>\n",
       "      <td>5786</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The snobby girls at the fashionable boarding s...</td>\n",
       "      <td>snobby girl fashionable board school ridicule ...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>children, fiction, young-adult, history, histo...</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>4.29</td>\n",
       "      <td>604</td>\n",
       "      <td>1319</td>\n",
       "      <td>48</td>\n",
       "      <td>738</td>\n",
       "      <td>1564</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Random House</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children, fiction, poetry, fantasy, paranormal</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>3.80</td>\n",
       "      <td>75</td>\n",
       "      <td>178</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>201</td>\n",
       "      <td>8</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>St. Martin's Paperbacks</td>\n",
       "      <td>570.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Recounts the search for and trial of a serial ...</td>\n",
       "      <td>recount search trial serial killer target offr...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>3.38</td>\n",
       "      <td>27</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>St. Martin's Paperbacks</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Jill Coit was a voluptuous, dark-skinned beaut...</td>\n",
       "      <td>jill coit voluptuous darkskinned beauty sultry...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>3.36</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>St. Martin's Press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Paleontologist Cameron Malone has discovered a...</td>\n",
       "      <td>paleontologist cameron alone discover yearly m...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>mystery, thriller, crime, fiction</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>3.78</td>\n",
       "      <td>57</td>\n",
       "      <td>189</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>193</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>St. Martin's Paperbacks</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>A KILLER WITHOUT REDEMPTION...\\nIn broad dayli...</td>\n",
       "      <td>killer without redemption broad daylight backw...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>3.27</td>\n",
       "      <td>29</td>\n",
       "      <td>81</td>\n",
       "      <td>6</td>\n",
       "      <td>381</td>\n",
       "      <td>976</td>\n",
       "      <td>70</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>St Martins Mass Market Paper</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>Though vaudeville is dying, Houdini still dazz...</td>\n",
       "      <td>though vaudeville die hold still dazzle audien...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>mystery, thriller, crime, fiction, history, hi...</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  average_rating  ratings_count  reviews_count  \\\n",
       "0      000100039X            4.23         186297         163625   \n",
       "1      0001053655            4.08             16             33   \n",
       "2      0001061240            4.62             10             22   \n",
       "3      000161102X            3.86             33             74   \n",
       "4      0001711296            4.29            604           1319   \n",
       "...           ...             ...            ...            ...   \n",
       "37228  0312953240            3.80             75            178   \n",
       "37229  0312955138            3.38             27             75   \n",
       "37230  0312955154            3.36             52             94   \n",
       "37231  0312956878            3.78             57            189   \n",
       "37232  0312956959            3.27             29             81   \n",
       "\n",
       "       text_reviews_count  total_ratings_count  total_reviews_count  \\\n",
       "0                    5535               220088               196528   \n",
       "1                       6                  676                 1552   \n",
       "2                       2                  221                  603   \n",
       "3                       4                 2929                 5786   \n",
       "4                      48                  738                 1564   \n",
       "...                   ...                  ...                  ...   \n",
       "37228                   8                   87                  201   \n",
       "37229                   3                   29                   81   \n",
       "37230                   5                   56                  101   \n",
       "37231                   3                   59                  193   \n",
       "37232                   6                  381                  976   \n",
       "\n",
       "       total_text_reviews_count  publication_year  publication_month  ...  \\\n",
       "0                          8847            2010.0                1.0  ...   \n",
       "1                            85            1997.0                NaN  ...   \n",
       "2                            36            1959.0               12.0  ...   \n",
       "3                            75               NaN                NaN  ...   \n",
       "4                            65               NaN                NaN  ...   \n",
       "...                         ...               ...                ...  ...   \n",
       "37228                         8            1995.0                7.0  ...   \n",
       "37229                         4            1995.0                9.0  ...   \n",
       "37230                         5            1995.0               10.0  ...   \n",
       "37231                         4            1995.0               10.0  ...   \n",
       "37232                        70            1996.0                1.0  ...   \n",
       "\n",
       "                          publisher num_pages     format  \\\n",
       "0                         Rupa & Co     127.0  Paperback   \n",
       "1                     HarperCollins     268.0  Hardcover   \n",
       "2        Western Publishing Company     324.0  Hardcover   \n",
       "3                               NaN     190.0        NaN   \n",
       "4                      Random House      63.0        NaN   \n",
       "...                             ...       ...        ...   \n",
       "37228       St. Martin's Paperbacks     570.0  Paperback   \n",
       "37229       St. Martin's Paperbacks     320.0  Paperback   \n",
       "37230            St. Martin's Press       NaN  Paperback   \n",
       "37231       St. Martin's Paperbacks     608.0  Paperback   \n",
       "37232  St Martins Mass Market Paper     308.0  Paperback   \n",
       "\n",
       "                                             description  \\\n",
       "0      Kahlil Gibran's masterpiece, The Prophet, is o...   \n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3      The snobby girls at the fashionable boarding s...   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "37228  Recounts the search for and trial of a serial ...   \n",
       "37229  Jill Coit was a voluptuous, dark-skinned beaut...   \n",
       "37230  Paleontologist Cameron Malone has discovered a...   \n",
       "37231  A KILLER WITHOUT REDEMPTION...\\nIn broad dayli...   \n",
       "37232  Though vaudeville is dying, Houdini still dazz...   \n",
       "\n",
       "                                     cleaned_description gr_countDes_before  \\\n",
       "0      tahsil vibrants masterpiece prophet one belove...              106.0   \n",
       "1                                                    NaN                NaN   \n",
       "2                                                    NaN                NaN   \n",
       "3      snobby girl fashionable board school ridicule ...               47.0   \n",
       "4                                                    NaN                NaN   \n",
       "...                                                  ...                ...   \n",
       "37228  recount search trial serial killer target offr...               41.0   \n",
       "37229  jill coit voluptuous darkskinned beauty sultry...              156.0   \n",
       "37230  paleontologist cameron alone discover yearly m...               48.0   \n",
       "37231  killer without redemption broad daylight backw...              187.0   \n",
       "37232  though vaudeville die hold still dazzle audien...               60.0   \n",
       "\n",
       "       gr_countDes_after                                     cleaned_genres  \\\n",
       "0                   66.0                       poetry, fiction, non-fiction   \n",
       "1                    NaN  history, historical fiction, biography, non-fi...   \n",
       "2                    NaN                                   poetry, children   \n",
       "3                   25.0  children, fiction, young-adult, history, histo...   \n",
       "4                    NaN     children, fiction, poetry, fantasy, paranormal   \n",
       "...                  ...                                                ...   \n",
       "37228               20.0              mystery, thriller, crime, non-fiction   \n",
       "37229               82.0              mystery, thriller, crime, non-fiction   \n",
       "37230               33.0                  mystery, thriller, crime, fiction   \n",
       "37231              103.0              mystery, thriller, crime, non-fiction   \n",
       "37232               39.0  mystery, thriller, crime, fiction, history, hi...   \n",
       "\n",
       "      gr_countText_before  gr_countText_after  \n",
       "0                   42320               17834  \n",
       "1                     158                  75  \n",
       "2                      49                  18  \n",
       "3                     130                  61  \n",
       "4                     257                 117  \n",
       "...                   ...                 ...  \n",
       "37228                 219                  94  \n",
       "37229                 125                  52  \n",
       "37230                 362                 184  \n",
       "37231                 152                  76  \n",
       "37232                 137                  72  \n",
       "\n",
       "[37233 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_metadata = pd.read_csv('official_goodreads_metadata.csv')\n",
    "gr_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>average</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>genres</th>\n",
       "      <th>rank</th>\n",
       "      <th>verifiedTrue_count</th>\n",
       "      <th>Format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>4.83</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>Childrens Books, Literature &amp; Fiction</td>\n",
       "      <td>1461315</td>\n",
       "      <td>36</td>\n",
       "      <td>Paperback,  Hardcover</td>\n",
       "      <td>2362</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>4.87</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>Childrens Books, Literature &amp; Fiction</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>4.44</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>3.37</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Science &amp; Math, Chemistry</td>\n",
       "      <td>9799524</td>\n",
       "      <td>3</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>5668</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>4.61</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>Literature &amp; Fiction, Poetry</td>\n",
       "      <td>3841172</td>\n",
       "      <td>44</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>3081</td>\n",
       "      <td>1457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>4.17</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>Literature &amp; Fiction, Fiction</td>\n",
       "      <td>2583900</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition</td>\n",
       "      <td>5228</td>\n",
       "      <td>2508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>4.00</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>Romance, Historical</td>\n",
       "      <td>553268</td>\n",
       "      <td>12</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition,  Pape...</td>\n",
       "      <td>3184</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>3.29</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Literature &amp; Fiction, Fiction</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>2.30</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>3083783</td>\n",
       "      <td>13</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition,  Pape...</td>\n",
       "      <td>3811</td>\n",
       "      <td>1804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  average  rating_count  text_reviews_count  \\\n",
       "0      0001713353     4.83            54                  54   \n",
       "1      0001061240     4.87            45                  45   \n",
       "2      0001711296     4.44           107                 107   \n",
       "3      0002007649     3.37            19                  19   \n",
       "4      0001716069     4.61            59                  59   \n",
       "...           ...      ...           ...                 ...   \n",
       "37228  0312943636     4.17            24                  24   \n",
       "37229  0312953038     4.00            27                  27   \n",
       "37230  0312955154     3.29            14                  14   \n",
       "37231  0312956878     3.33            15                  15   \n",
       "37232  0312947763     2.30            33                  33   \n",
       "\n",
       "                                       genres     rank  verifiedTrue_count  \\\n",
       "0       Childrens Books, Literature & Fiction  1461315                  36   \n",
       "1       Childrens Books, Literature & Fiction   321557                  30   \n",
       "2                        Literature & Fiction  2884610                  69   \n",
       "3                   Science & Math, Chemistry  9799524                   3   \n",
       "4                Literature & Fiction, Poetry  3841172                  44   \n",
       "...                                       ...      ...                 ...   \n",
       "37228           Literature & Fiction, Fiction  2583900                   9   \n",
       "37229                     Romance, Historical   553268                  12   \n",
       "37230           Literature & Fiction, Fiction  3412599                   4   \n",
       "37231       Biographies & Memoirs, True Crime  2606128                   9   \n",
       "37232       Biographies & Memoirs, True Crime  3083783                  13   \n",
       "\n",
       "                                                  Format  am_countText_before  \\\n",
       "0                                  Paperback,  Hardcover                 2362   \n",
       "1                                              Hardcover                 3085   \n",
       "2       Library Binding,  VHS Tape,  Paperback,  Hard...                 5667   \n",
       "3                 Kindle Edition,  Paperback,  Hardcover                 5668   \n",
       "4                 Kindle Edition,  Paperback,  Hardcover                 3081   \n",
       "...                                                  ...                  ...   \n",
       "37228             Mass Market Paperback,  Kindle Edition                 5228   \n",
       "37229   Mass Market Paperback,  Kindle Edition,  Pape...                 3184   \n",
       "37230                         Kindle Edition,  Paperback                 1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                  968   \n",
       "37232   Mass Market Paperback,  Kindle Edition,  Pape...                 3811   \n",
       "\n",
       "       am_countText_after  \n",
       "0                    1037  \n",
       "1                    1326  \n",
       "2                    2574  \n",
       "3                    2810  \n",
       "4                    1457  \n",
       "...                   ...  \n",
       "37228                2508  \n",
       "37229                1420  \n",
       "37230                 683  \n",
       "37231                 450  \n",
       "37232                1804  \n",
       "\n",
       "[37233 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_metadata = pd.read_csv('official_amazon_metadata.csv')\n",
    "am_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find outliers & anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                           0\n",
       "average_rating                 0\n",
       "ratings_count                  0\n",
       "reviews_count                  0\n",
       "text_reviews_count             0\n",
       "total_ratings_count            0\n",
       "total_reviews_count            0\n",
       "total_text_reviews_count       0\n",
       "publication_year            1445\n",
       "publication_month           2012\n",
       "publication_day             2212\n",
       "publisher                   1488\n",
       "num_pages                   1630\n",
       "format                      1535\n",
       "description                 1027\n",
       "cleaned_description         1748\n",
       "gr_countDes_before          1027\n",
       "gr_countDes_after           1748\n",
       "cleaned_genres               199\n",
       "gr_countText_before            0\n",
       "gr_countText_after             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_metadata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                    0\n",
       "average                 0\n",
       "rating_count            0\n",
       "text_reviews_count      0\n",
       "genres                  0\n",
       "rank                    0\n",
       "verifiedTrue_count      0\n",
       "Format                 49\n",
       "am_countText_before     0\n",
       "am_countText_after      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_metadata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_reviews_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>35788.000000</td>\n",
       "      <td>35221.000000</td>\n",
       "      <td>35021.000000</td>\n",
       "      <td>35603.000000</td>\n",
       "      <td>36206.000000</td>\n",
       "      <td>35485.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.873311</td>\n",
       "      <td>2.141833e+03</td>\n",
       "      <td>4.211693e+03</td>\n",
       "      <td>145.747267</td>\n",
       "      <td>1.147746e+04</td>\n",
       "      <td>1.963290e+04</td>\n",
       "      <td>614.953992</td>\n",
       "      <td>2005.668772</td>\n",
       "      <td>6.367764</td>\n",
       "      <td>13.958339</td>\n",
       "      <td>322.277757</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>89.978442</td>\n",
       "      <td>3.233221e+03</td>\n",
       "      <td>1429.169957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>2.213376e+04</td>\n",
       "      <td>2.996176e+04</td>\n",
       "      <td>974.148611</td>\n",
       "      <td>8.537788e+04</td>\n",
       "      <td>1.153654e+05</td>\n",
       "      <td>3121.161743</td>\n",
       "      <td>8.987800</td>\n",
       "      <td>3.339121</td>\n",
       "      <td>10.365574</td>\n",
       "      <td>201.544695</td>\n",
       "      <td>92.759441</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>1.502964e+04</td>\n",
       "      <td>6492.465045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>6.300000e+02</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>1.860000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>8.210000e+02</td>\n",
       "      <td>2.103000e+03</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.740000e+02</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>6.900000e+02</td>\n",
       "      <td>1.797000e+03</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.416000e+03</td>\n",
       "      <td>7.850000e+03</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2.058000e+03</td>\n",
       "      <td>928.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.056193e+06</td>\n",
       "      <td>2.238009e+06</td>\n",
       "      <td>68752.000000</td>\n",
       "      <td>4.718437e+06</td>\n",
       "      <td>5.684376e+06</td>\n",
       "      <td>152766.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9998.000000</td>\n",
       "      <td>2124.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1.001655e+06</td>\n",
       "      <td>443150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       average_rating  ratings_count  reviews_count  text_reviews_count  \\\n",
       "count    37233.000000   3.723300e+04   3.723300e+04        37233.000000   \n",
       "mean         3.873311   2.141833e+03   4.211693e+03          145.747267   \n",
       "std          0.306148   2.213376e+04   2.996176e+04          974.148611   \n",
       "min          2.320000   0.000000e+00   0.000000e+00            0.000000   \n",
       "25%          3.690000   5.900000e+01   1.500000e+02            9.000000   \n",
       "50%          3.890000   1.860000e+02   5.060000e+02           24.000000   \n",
       "75%          4.080000   6.900000e+02   1.797000e+03           75.000000   \n",
       "max          5.000000   2.056193e+06   2.238009e+06        68752.000000   \n",
       "\n",
       "       total_ratings_count  total_reviews_count  total_text_reviews_count  \\\n",
       "count         3.723300e+04         3.723300e+04              37233.000000   \n",
       "mean          1.147746e+04         1.963290e+04                614.953992   \n",
       "std           8.537788e+04         1.153654e+05               3121.161743   \n",
       "min           1.000000e+00         3.000000e+00                  0.000000   \n",
       "25%           2.270000e+02         6.300000e+02                 27.000000   \n",
       "50%           8.210000e+02         2.103000e+03                 83.000000   \n",
       "75%           3.416000e+03         7.850000e+03                292.000000   \n",
       "max           4.718437e+06         5.684376e+06             152766.000000   \n",
       "\n",
       "       publication_year  publication_month  publication_day     num_pages  \\\n",
       "count      35788.000000       35221.000000     35021.000000  35603.000000   \n",
       "mean        2005.668772           6.367764        13.958339    322.277757   \n",
       "std            8.987800           3.339121        10.365574    201.544695   \n",
       "min         1900.000000           1.000000         1.000000      0.000000   \n",
       "25%         2002.000000           4.000000         4.000000    227.000000   \n",
       "50%         2008.000000           6.000000        13.000000    307.000000   \n",
       "75%         2012.000000           9.000000        24.000000    384.000000   \n",
       "max         2019.000000          12.000000        31.000000   9998.000000   \n",
       "\n",
       "       gr_countDes_before  gr_countDes_after  gr_countText_before  \\\n",
       "count        36206.000000       35485.000000         3.723300e+04   \n",
       "mean           160.689085          89.978442         3.233221e+03   \n",
       "std             92.759441          52.634720         1.502964e+04   \n",
       "min              1.000000           1.000000         1.000000e+00   \n",
       "25%             99.000000          55.000000         1.480000e+02   \n",
       "50%            147.000000          81.000000         5.740000e+02   \n",
       "75%            205.000000         115.000000         2.058000e+03   \n",
       "max           2124.000000        1250.000000         1.001655e+06   \n",
       "\n",
       "       gr_countText_after  \n",
       "count        37233.000000  \n",
       "mean          1429.169957  \n",
       "std           6492.465045  \n",
       "min              0.000000  \n",
       "25%             68.000000  \n",
       "50%            260.000000  \n",
       "75%            928.000000  \n",
       "max         443150.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_metadata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.261219</td>\n",
       "      <td>152.651680</td>\n",
       "      <td>152.615798</td>\n",
       "      <td>1.563020e+06</td>\n",
       "      <td>104.396879</td>\n",
       "      <td>1.371004e+04</td>\n",
       "      <td>6.490044e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.422799</td>\n",
       "      <td>702.459338</td>\n",
       "      <td>702.255076</td>\n",
       "      <td>2.092905e+06</td>\n",
       "      <td>569.410575</td>\n",
       "      <td>4.245893e+04</td>\n",
       "      <td>1.970582e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.022940e+05</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.395000e+03</td>\n",
       "      <td>1.152000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.232760e+05</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.956000e+03</td>\n",
       "      <td>2.387000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.986080e+06</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.170400e+04</td>\n",
       "      <td>5.585000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>44956.000000</td>\n",
       "      <td>44947.000000</td>\n",
       "      <td>2.154444e+07</td>\n",
       "      <td>39851.000000</td>\n",
       "      <td>2.384912e+06</td>\n",
       "      <td>1.082212e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            average  rating_count  text_reviews_count          rank  \\\n",
       "count  37233.000000  37233.000000        37233.000000  3.723300e+04   \n",
       "mean       4.261219    152.651680          152.615798  1.563020e+06   \n",
       "std        0.422799    702.459338          702.255076  2.092905e+06   \n",
       "min        1.080000      6.000000            6.000000  2.300000e+01   \n",
       "25%        4.040000     22.000000           22.000000  3.022940e+05   \n",
       "50%        4.330000     43.000000           43.000000  9.232760e+05   \n",
       "75%        4.570000    107.000000          107.000000  1.986080e+06   \n",
       "max        5.000000  44956.000000        44947.000000  2.154444e+07   \n",
       "\n",
       "       verifiedTrue_count  am_countText_before  am_countText_after  \n",
       "count        37233.000000         3.723300e+04        3.723300e+04  \n",
       "mean           104.396879         1.371004e+04        6.490044e+03  \n",
       "std            569.410575         4.245893e+04        1.970582e+04  \n",
       "min              0.000000         7.900000e+01        4.900000e+01  \n",
       "25%             11.000000         2.395000e+03        1.152000e+03  \n",
       "50%             24.000000         4.956000e+03        2.387000e+03  \n",
       "75%             66.000000         1.170400e+04        5.585000e+03  \n",
       "max          39851.000000         2.384912e+06        1.082212e+06  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_metadata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from EDA, outliers are: <br/>\n",
    "1. min from am_metadata.average <br/>\n",
    "2. max from gr_metadata.num_pages <br/>\n",
    "3. 2 min from am_metadata.average_rating - gr_metadata.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_reviews_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>format</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>cleaned_genres</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24788</td>\n",
       "      <td>0205739415</td>\n",
       "      <td>2.92</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Longman Publishing Group</td>\n",
       "      <td>544.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>\"Technical Communication Strategies for Today ...</td>\n",
       "      <td>technical communication strategy today offer s...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>96</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26677</td>\n",
       "      <td>0300084323</td>\n",
       "      <td>4.35</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Yale University Press</td>\n",
       "      <td>816.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>The Holocaust has been the subject of countles...</td>\n",
       "      <td>holocaust subject countless book work art memo...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>history, historical fiction, biography, fictio...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  average_rating  ratings_count  reviews_count  \\\n",
       "24788  0205739415            2.92              8             32   \n",
       "26677  0300084323            4.35             23             86   \n",
       "\n",
       "       text_reviews_count  total_ratings_count  total_reviews_count  \\\n",
       "24788                   0                   12                   46   \n",
       "26677                   0                   23                   86   \n",
       "\n",
       "       total_text_reviews_count  publication_year  publication_month  ...  \\\n",
       "24788                         0            2010.0                9.0  ...   \n",
       "26677                         0            2001.0                3.0  ...   \n",
       "\n",
       "                      publisher num_pages     format  \\\n",
       "24788  Longman Publishing Group     544.0  Paperback   \n",
       "26677     Yale University Press     816.0  Hardcover   \n",
       "\n",
       "                                             description  \\\n",
       "24788  \"Technical Communication Strategies for Today ...   \n",
       "26677  The Holocaust has been the subject of countles...   \n",
       "\n",
       "                                     cleaned_description gr_countDes_before  \\\n",
       "24788  technical communication strategy today offer s...              147.0   \n",
       "26677  holocaust subject countless book work art memo...              214.0   \n",
       "\n",
       "       gr_countDes_after                                     cleaned_genres  \\\n",
       "24788               92.0                                        non-fiction   \n",
       "26677              134.0  history, historical fiction, biography, fictio...   \n",
       "\n",
       "      gr_countText_before  gr_countText_after  \n",
       "24788                  96                  40  \n",
       "26677                   2                   2  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually check data points w/ 0 total_text_reviews_count\n",
    "gr_metadata[gr_metadata['total_text_reviews_count'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change those values to 1 (inconsistent values by GR)\n",
    "gr_metadata.loc[gr_metadata['asin'] == '0205739415', 'total_text_reviews_count'] = 1\n",
    "gr_metadata.loc[gr_metadata['asin'] == '0300084323', 'total_text_reviews_count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_reviews_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>35788.000000</td>\n",
       "      <td>35221.000000</td>\n",
       "      <td>35021.000000</td>\n",
       "      <td>35603.000000</td>\n",
       "      <td>36206.000000</td>\n",
       "      <td>35485.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.873311</td>\n",
       "      <td>2.141833e+03</td>\n",
       "      <td>4.211693e+03</td>\n",
       "      <td>145.747267</td>\n",
       "      <td>1.147746e+04</td>\n",
       "      <td>1.963290e+04</td>\n",
       "      <td>614.954046</td>\n",
       "      <td>2005.668772</td>\n",
       "      <td>6.367764</td>\n",
       "      <td>13.958339</td>\n",
       "      <td>322.277757</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>89.978442</td>\n",
       "      <td>3.233221e+03</td>\n",
       "      <td>1429.169957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>2.213376e+04</td>\n",
       "      <td>2.996176e+04</td>\n",
       "      <td>974.148611</td>\n",
       "      <td>8.537788e+04</td>\n",
       "      <td>1.153654e+05</td>\n",
       "      <td>3121.161732</td>\n",
       "      <td>8.987800</td>\n",
       "      <td>3.339121</td>\n",
       "      <td>10.365574</td>\n",
       "      <td>201.544695</td>\n",
       "      <td>92.759441</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>1.502964e+04</td>\n",
       "      <td>6492.465045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>5.900000e+01</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>6.300000e+02</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>1.860000e+02</td>\n",
       "      <td>5.060000e+02</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>8.210000e+02</td>\n",
       "      <td>2.103000e+03</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.740000e+02</td>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>6.900000e+02</td>\n",
       "      <td>1.797000e+03</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.416000e+03</td>\n",
       "      <td>7.850000e+03</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2.058000e+03</td>\n",
       "      <td>928.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.056193e+06</td>\n",
       "      <td>2.238009e+06</td>\n",
       "      <td>68752.000000</td>\n",
       "      <td>4.718437e+06</td>\n",
       "      <td>5.684376e+06</td>\n",
       "      <td>152766.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9998.000000</td>\n",
       "      <td>2124.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1.001655e+06</td>\n",
       "      <td>443150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       average_rating  ratings_count  reviews_count  text_reviews_count  \\\n",
       "count    37233.000000   3.723300e+04   3.723300e+04        37233.000000   \n",
       "mean         3.873311   2.141833e+03   4.211693e+03          145.747267   \n",
       "std          0.306148   2.213376e+04   2.996176e+04          974.148611   \n",
       "min          2.320000   0.000000e+00   0.000000e+00            0.000000   \n",
       "25%          3.690000   5.900000e+01   1.500000e+02            9.000000   \n",
       "50%          3.890000   1.860000e+02   5.060000e+02           24.000000   \n",
       "75%          4.080000   6.900000e+02   1.797000e+03           75.000000   \n",
       "max          5.000000   2.056193e+06   2.238009e+06        68752.000000   \n",
       "\n",
       "       total_ratings_count  total_reviews_count  total_text_reviews_count  \\\n",
       "count         3.723300e+04         3.723300e+04              37233.000000   \n",
       "mean          1.147746e+04         1.963290e+04                614.954046   \n",
       "std           8.537788e+04         1.153654e+05               3121.161732   \n",
       "min           1.000000e+00         3.000000e+00                  1.000000   \n",
       "25%           2.270000e+02         6.300000e+02                 27.000000   \n",
       "50%           8.210000e+02         2.103000e+03                 83.000000   \n",
       "75%           3.416000e+03         7.850000e+03                292.000000   \n",
       "max           4.718437e+06         5.684376e+06             152766.000000   \n",
       "\n",
       "       publication_year  publication_month  publication_day     num_pages  \\\n",
       "count      35788.000000       35221.000000     35021.000000  35603.000000   \n",
       "mean        2005.668772           6.367764        13.958339    322.277757   \n",
       "std            8.987800           3.339121        10.365574    201.544695   \n",
       "min         1900.000000           1.000000         1.000000      0.000000   \n",
       "25%         2002.000000           4.000000         4.000000    227.000000   \n",
       "50%         2008.000000           6.000000        13.000000    307.000000   \n",
       "75%         2012.000000           9.000000        24.000000    384.000000   \n",
       "max         2019.000000          12.000000        31.000000   9998.000000   \n",
       "\n",
       "       gr_countDes_before  gr_countDes_after  gr_countText_before  \\\n",
       "count        36206.000000       35485.000000         3.723300e+04   \n",
       "mean           160.689085          89.978442         3.233221e+03   \n",
       "std             92.759441          52.634720         1.502964e+04   \n",
       "min              1.000000           1.000000         1.000000e+00   \n",
       "25%             99.000000          55.000000         1.480000e+02   \n",
       "50%            147.000000          81.000000         5.740000e+02   \n",
       "75%            205.000000         115.000000         2.058000e+03   \n",
       "max           2124.000000        1250.000000         1.001655e+06   \n",
       "\n",
       "       gr_countText_after  \n",
       "count        37233.000000  \n",
       "mean          1429.169957  \n",
       "std           6492.465045  \n",
       "min              0.000000  \n",
       "25%             68.000000  \n",
       "50%            260.000000  \n",
       "75%            928.000000  \n",
       "max         443150.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr_metadata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select numerical features w/o null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>format</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>average</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>genres</th>\n",
       "      <th>rank</th>\n",
       "      <th>verifiedTrue_count</th>\n",
       "      <th>Format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>4.23</td>\n",
       "      <td>220088</td>\n",
       "      <td>8847</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>tahsil vibrants masterpiece prophet one belove...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17834</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>Literature &amp; Fiction, Poetry</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>4.08</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>4.48</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover,  Audi...</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>4.62</td>\n",
       "      <td>221</td>\n",
       "      <td>36</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4.87</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>Childrens Books, Literature &amp; Fiction</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2929</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snobby girl fashionable board school ridicule ...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>4.35</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>4.29</td>\n",
       "      <td>738</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>4.44</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>3.80</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>recount search trial serial killer target offr...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>3.69</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>3.38</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>jill coit voluptuous darkskinned beauty sultry...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>Kindle Edition,  Hardcover</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>3.36</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>paleontologist cameron alone discover yearly m...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>3.29</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Literature &amp; Fiction, Fiction</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>3.78</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>killer without redemption broad daylight backw...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>3.27</td>\n",
       "      <td>381</td>\n",
       "      <td>70</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>though vaudeville die hold still dazzle audien...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>3.83</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>Mystery, Thriller &amp; Suspense, Mystery</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  average_rating  total_ratings_count  \\\n",
       "0      000100039X            4.23               220088   \n",
       "1      0001053655            4.08                  676   \n",
       "2      0001061240            4.62                  221   \n",
       "3      000161102X            3.86                 2929   \n",
       "4      0001711296            4.29                  738   \n",
       "...           ...             ...                  ...   \n",
       "37228  0312953240            3.80                   87   \n",
       "37229  0312955138            3.38                   29   \n",
       "37230  0312955154            3.36                   56   \n",
       "37231  0312956878            3.78                   59   \n",
       "37232  0312956959            3.27                  381   \n",
       "\n",
       "       total_text_reviews_count  publication_year  publication_month  \\\n",
       "0                          8847            2010.0                1.0   \n",
       "1                            85            1997.0                NaN   \n",
       "2                            36            1959.0               12.0   \n",
       "3                            75               NaN                NaN   \n",
       "4                            65               NaN                NaN   \n",
       "...                         ...               ...                ...   \n",
       "37228                         8            1995.0                7.0   \n",
       "37229                         4            1995.0                9.0   \n",
       "37230                         5            1995.0               10.0   \n",
       "37231                         4            1995.0               10.0   \n",
       "37232                        70            1996.0                1.0   \n",
       "\n",
       "       publication_day     format  \\\n",
       "0                  1.0  Paperback   \n",
       "1                  NaN  Hardcover   \n",
       "2                  1.0  Hardcover   \n",
       "3                  NaN        NaN   \n",
       "4                  NaN        NaN   \n",
       "...                ...        ...   \n",
       "37228             15.0  Paperback   \n",
       "37229             15.0  Paperback   \n",
       "37230             15.0  Paperback   \n",
       "37231             15.0  Paperback   \n",
       "37232             28.0  Paperback   \n",
       "\n",
       "                                     cleaned_description  gr_countDes_before  \\\n",
       "0      tahsil vibrants masterpiece prophet one belove...               106.0   \n",
       "1                                                    NaN                 NaN   \n",
       "2                                                    NaN                 NaN   \n",
       "3      snobby girl fashionable board school ridicule ...                47.0   \n",
       "4                                                    NaN                 NaN   \n",
       "...                                                  ...                 ...   \n",
       "37228  recount search trial serial killer target offr...                41.0   \n",
       "37229  jill coit voluptuous darkskinned beauty sultry...               156.0   \n",
       "37230  paleontologist cameron alone discover yearly m...                48.0   \n",
       "37231  killer without redemption broad daylight backw...               187.0   \n",
       "37232  though vaudeville die hold still dazzle audien...                60.0   \n",
       "\n",
       "       ...  gr_countText_after average  rating_count  text_reviews_count  \\\n",
       "0      ...               17834    4.64          1453                1453   \n",
       "1      ...                  75    4.48            50                  50   \n",
       "2      ...                  18    4.87            45                  45   \n",
       "3      ...                  61    4.35            17                  17   \n",
       "4      ...                 117    4.44           107                 107   \n",
       "...    ...                 ...     ...           ...                 ...   \n",
       "37228  ...                  94    3.69            13                  13   \n",
       "37229  ...                  52    3.58            12                  12   \n",
       "37230  ...                 184    3.29            14                  14   \n",
       "37231  ...                  76    3.33            15                  15   \n",
       "37232  ...                  72    3.83            41                  41   \n",
       "\n",
       "                                       genres     rank  verifiedTrue_count  \\\n",
       "0                Literature & Fiction, Poetry  1810945                1130   \n",
       "1                       Humor & Entertainment  9799161                  43   \n",
       "2       Childrens Books, Literature & Fiction   321557                  30   \n",
       "3                        Literature & Fiction  1542999                  13   \n",
       "4                        Literature & Fiction  2884610                  69   \n",
       "...                                       ...      ...                 ...   \n",
       "37228       Biographies & Memoirs, True Crime   443719                   4   \n",
       "37229       Biographies & Memoirs, True Crime  3470182                   6   \n",
       "37230           Literature & Fiction, Fiction  3412599                   4   \n",
       "37231       Biographies & Memoirs, True Crime  2606128                   9   \n",
       "37232   Mystery, Thriller & Suspense, Mystery  2880300                  26   \n",
       "\n",
       "                                                  Format  am_countText_before  \\\n",
       "0                                                    NaN                69909   \n",
       "1       Kindle Edition,  Paperback,  Hardcover,  Audi...                 4888   \n",
       "2                                              Hardcover                 3085   \n",
       "3                                                    NaN                  788   \n",
       "4       Library Binding,  VHS Tape,  Paperback,  Hard...                 5667   \n",
       "...                                                  ...                  ...   \n",
       "37228                  Mass Market Paperback,  Hardcover                 2599   \n",
       "37229                         Kindle Edition,  Hardcover                 1489   \n",
       "37230                         Kindle Edition,  Paperback                 1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                  968   \n",
       "37232             Kindle Edition,  Paperback,  Hardcover                 4356   \n",
       "\n",
       "       am_countText_after  \n",
       "0                   31772  \n",
       "1                    2240  \n",
       "2                    1326  \n",
       "3                     399  \n",
       "4                    2574  \n",
       "...                   ...  \n",
       "37228                1216  \n",
       "37229                 668  \n",
       "37230                 683  \n",
       "37231                 450  \n",
       "37232                2184  \n",
       "\n",
       "[37233 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata = pd.merge(gr_metadata[['asin', 'average_rating', 'total_ratings_count', 'total_text_reviews_count', \n",
    "                                       'publication_year', 'publication_month', 'publication_day', 'format', \n",
    "                                       'cleaned_description', 'gr_countDes_before', 'gr_countDes_after', 'cleaned_genres',\n",
    "                                       'gr_countText_before', 'gr_countText_after']], \n",
    "                          am_metadata, how='inner', on='asin')\n",
    "am_gr_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata = am_gr_metadata.rename(columns={'average_rating':'gr_average', 'total_ratings_count':'gr_ratings_count',\n",
    "                                                'total_text_reviews_count':'gr_reviews_count', \n",
    "                                                'publication_year':'gr_pub_yr', 'publication_month':'gr_pub_mo', \n",
    "                                                'publication_day':'gr_pub_day', 'format':'gr_format',\n",
    "                                                'cleaned_description':'gr_description', 'cleaned_genres':'gr_genres',\n",
    "                                                'average':'am_average', 'rating_count':'am_ratings_count', \n",
    "                                                'text_reviews_count':'am_reviews_count', 'genres':'am_genres', \n",
    "                                                'rank':'am_rank', 'verifiedTrue_count':'am_verifiedTrue_count', \n",
    "                                                'Format':'am_format'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>gr_average</th>\n",
       "      <th>gr_ratings_count</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_format</th>\n",
       "      <th>gr_description</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_average</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_genres</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>4.23</td>\n",
       "      <td>220088</td>\n",
       "      <td>8847</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>tahsil vibrants masterpiece prophet one belove...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17834</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>Literature &amp; Fiction, Poetry</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>4.08</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>4.48</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover,  Audi...</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>4.62</td>\n",
       "      <td>221</td>\n",
       "      <td>36</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>4.87</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>Childrens Books, Literature &amp; Fiction</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2929</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snobby girl fashionable board school ridicule ...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>4.35</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>4.29</td>\n",
       "      <td>738</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>4.44</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>3.80</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>recount search trial serial killer target offr...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94</td>\n",
       "      <td>3.69</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>3.38</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>jill coit voluptuous darkskinned beauty sultry...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>Kindle Edition,  Hardcover</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>3.36</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>paleontologist cameron alone discover yearly m...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>184</td>\n",
       "      <td>3.29</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Literature &amp; Fiction, Fiction</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>3.78</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>killer without redemption broad daylight backw...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>3.27</td>\n",
       "      <td>381</td>\n",
       "      <td>70</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>though vaudeville die hold still dazzle audien...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>3.83</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>Mystery, Thriller &amp; Suspense, Mystery</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  gr_average  gr_ratings_count  gr_reviews_count  gr_pub_yr  \\\n",
       "0      000100039X        4.23            220088              8847     2010.0   \n",
       "1      0001053655        4.08               676                85     1997.0   \n",
       "2      0001061240        4.62               221                36     1959.0   \n",
       "3      000161102X        3.86              2929                75        NaN   \n",
       "4      0001711296        4.29               738                65        NaN   \n",
       "...           ...         ...               ...               ...        ...   \n",
       "37228  0312953240        3.80                87                 8     1995.0   \n",
       "37229  0312955138        3.38                29                 4     1995.0   \n",
       "37230  0312955154        3.36                56                 5     1995.0   \n",
       "37231  0312956878        3.78                59                 4     1995.0   \n",
       "37232  0312956959        3.27               381                70     1996.0   \n",
       "\n",
       "       gr_pub_mo  gr_pub_day  gr_format  \\\n",
       "0            1.0         1.0  Paperback   \n",
       "1            NaN         NaN  Hardcover   \n",
       "2           12.0         1.0  Hardcover   \n",
       "3            NaN         NaN        NaN   \n",
       "4            NaN         NaN        NaN   \n",
       "...          ...         ...        ...   \n",
       "37228        7.0        15.0  Paperback   \n",
       "37229        9.0        15.0  Paperback   \n",
       "37230       10.0        15.0  Paperback   \n",
       "37231       10.0        15.0  Paperback   \n",
       "37232        1.0        28.0  Paperback   \n",
       "\n",
       "                                          gr_description  gr_countDes_before  \\\n",
       "0      tahsil vibrants masterpiece prophet one belove...               106.0   \n",
       "1                                                    NaN                 NaN   \n",
       "2                                                    NaN                 NaN   \n",
       "3      snobby girl fashionable board school ridicule ...                47.0   \n",
       "4                                                    NaN                 NaN   \n",
       "...                                                  ...                 ...   \n",
       "37228  recount search trial serial killer target offr...                41.0   \n",
       "37229  jill coit voluptuous darkskinned beauty sultry...               156.0   \n",
       "37230  paleontologist cameron alone discover yearly m...                48.0   \n",
       "37231  killer without redemption broad daylight backw...               187.0   \n",
       "37232  though vaudeville die hold still dazzle audien...                60.0   \n",
       "\n",
       "       ...  gr_countText_after am_average  am_ratings_count  am_reviews_count  \\\n",
       "0      ...               17834       4.64              1453              1453   \n",
       "1      ...                  75       4.48                50                50   \n",
       "2      ...                  18       4.87                45                45   \n",
       "3      ...                  61       4.35                17                17   \n",
       "4      ...                 117       4.44               107               107   \n",
       "...    ...                 ...        ...               ...               ...   \n",
       "37228  ...                  94       3.69                13                13   \n",
       "37229  ...                  52       3.58                12                12   \n",
       "37230  ...                 184       3.29                14                14   \n",
       "37231  ...                  76       3.33                15                15   \n",
       "37232  ...                  72       3.83                41                41   \n",
       "\n",
       "                                    am_genres  am_rank  am_verifiedTrue_count  \\\n",
       "0                Literature & Fiction, Poetry  1810945                   1130   \n",
       "1                       Humor & Entertainment  9799161                     43   \n",
       "2       Childrens Books, Literature & Fiction   321557                     30   \n",
       "3                        Literature & Fiction  1542999                     13   \n",
       "4                        Literature & Fiction  2884610                     69   \n",
       "...                                       ...      ...                    ...   \n",
       "37228       Biographies & Memoirs, True Crime   443719                      4   \n",
       "37229       Biographies & Memoirs, True Crime  3470182                      6   \n",
       "37230           Literature & Fiction, Fiction  3412599                      4   \n",
       "37231       Biographies & Memoirs, True Crime  2606128                      9   \n",
       "37232   Mystery, Thriller & Suspense, Mystery  2880300                     26   \n",
       "\n",
       "                                               am_format  am_countText_before  \\\n",
       "0                                                    NaN                69909   \n",
       "1       Kindle Edition,  Paperback,  Hardcover,  Audi...                 4888   \n",
       "2                                              Hardcover                 3085   \n",
       "3                                                    NaN                  788   \n",
       "4       Library Binding,  VHS Tape,  Paperback,  Hard...                 5667   \n",
       "...                                                  ...                  ...   \n",
       "37228                  Mass Market Paperback,  Hardcover                 2599   \n",
       "37229                         Kindle Edition,  Hardcover                 1489   \n",
       "37230                         Kindle Edition,  Paperback                 1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                  968   \n",
       "37232             Kindle Edition,  Paperback,  Hardcover                 4356   \n",
       "\n",
       "       am_countText_after  \n",
       "0                   31772  \n",
       "1                    2240  \n",
       "2                    1326  \n",
       "3                     399  \n",
       "4                    2574  \n",
       "...                   ...  \n",
       "37228                1216  \n",
       "37229                 668  \n",
       "37230                 683  \n",
       "37231                 450  \n",
       "37232                2184  \n",
       "\n",
       "[37233 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata['rating_diff'] = am_gr_metadata['am_average']- am_gr_metadata['gr_average']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>gr_average</th>\n",
       "      <th>gr_ratings_count</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_format</th>\n",
       "      <th>gr_description</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>...</th>\n",
       "      <th>am_average</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_genres</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>4.23</td>\n",
       "      <td>220088</td>\n",
       "      <td>8847</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>tahsil vibrants masterpiece prophet one belove...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>Literature &amp; Fiction, Poetry</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>4.08</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>Humor &amp; Entertainment</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover,  Audi...</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>4.62</td>\n",
       "      <td>221</td>\n",
       "      <td>36</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.87</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>Childrens Books, Literature &amp; Fiction</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2929</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snobby girl fashionable board school ridicule ...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.35</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>4.29</td>\n",
       "      <td>738</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.44</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>3.80</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>recount search trial serial killer target offr...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.69</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>3.38</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>jill coit voluptuous darkskinned beauty sultry...</td>\n",
       "      <td>156.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>Kindle Edition,  Hardcover</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>3.36</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>paleontologist cameron alone discover yearly m...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.29</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Literature &amp; Fiction, Fiction</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>3.78</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>killer without redemption broad daylight backw...</td>\n",
       "      <td>187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>Biographies &amp; Memoirs, True Crime</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>3.27</td>\n",
       "      <td>381</td>\n",
       "      <td>70</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>though vaudeville die hold still dazzle audien...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.83</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>Mystery, Thriller &amp; Suspense, Mystery</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  gr_average  gr_ratings_count  gr_reviews_count  gr_pub_yr  \\\n",
       "0      000100039X        4.23            220088              8847     2010.0   \n",
       "1      0001053655        4.08               676                85     1997.0   \n",
       "2      0001061240        4.62               221                36     1959.0   \n",
       "3      000161102X        3.86              2929                75        NaN   \n",
       "4      0001711296        4.29               738                65        NaN   \n",
       "...           ...         ...               ...               ...        ...   \n",
       "37228  0312953240        3.80                87                 8     1995.0   \n",
       "37229  0312955138        3.38                29                 4     1995.0   \n",
       "37230  0312955154        3.36                56                 5     1995.0   \n",
       "37231  0312956878        3.78                59                 4     1995.0   \n",
       "37232  0312956959        3.27               381                70     1996.0   \n",
       "\n",
       "       gr_pub_mo  gr_pub_day  gr_format  \\\n",
       "0            1.0         1.0  Paperback   \n",
       "1            NaN         NaN  Hardcover   \n",
       "2           12.0         1.0  Hardcover   \n",
       "3            NaN         NaN        NaN   \n",
       "4            NaN         NaN        NaN   \n",
       "...          ...         ...        ...   \n",
       "37228        7.0        15.0  Paperback   \n",
       "37229        9.0        15.0  Paperback   \n",
       "37230       10.0        15.0  Paperback   \n",
       "37231       10.0        15.0  Paperback   \n",
       "37232        1.0        28.0  Paperback   \n",
       "\n",
       "                                          gr_description  gr_countDes_before  \\\n",
       "0      tahsil vibrants masterpiece prophet one belove...               106.0   \n",
       "1                                                    NaN                 NaN   \n",
       "2                                                    NaN                 NaN   \n",
       "3      snobby girl fashionable board school ridicule ...                47.0   \n",
       "4                                                    NaN                 NaN   \n",
       "...                                                  ...                 ...   \n",
       "37228  recount search trial serial killer target offr...                41.0   \n",
       "37229  jill coit voluptuous darkskinned beauty sultry...               156.0   \n",
       "37230  paleontologist cameron alone discover yearly m...                48.0   \n",
       "37231  killer without redemption broad daylight backw...               187.0   \n",
       "37232  though vaudeville die hold still dazzle audien...                60.0   \n",
       "\n",
       "       ...  am_average am_ratings_count  am_reviews_count  \\\n",
       "0      ...        4.64             1453              1453   \n",
       "1      ...        4.48               50                50   \n",
       "2      ...        4.87               45                45   \n",
       "3      ...        4.35               17                17   \n",
       "4      ...        4.44              107               107   \n",
       "...    ...         ...              ...               ...   \n",
       "37228  ...        3.69               13                13   \n",
       "37229  ...        3.58               12                12   \n",
       "37230  ...        3.29               14                14   \n",
       "37231  ...        3.33               15                15   \n",
       "37232  ...        3.83               41                41   \n",
       "\n",
       "                                    am_genres  am_rank  am_verifiedTrue_count  \\\n",
       "0                Literature & Fiction, Poetry  1810945                   1130   \n",
       "1                       Humor & Entertainment  9799161                     43   \n",
       "2       Childrens Books, Literature & Fiction   321557                     30   \n",
       "3                        Literature & Fiction  1542999                     13   \n",
       "4                        Literature & Fiction  2884610                     69   \n",
       "...                                       ...      ...                    ...   \n",
       "37228       Biographies & Memoirs, True Crime   443719                      4   \n",
       "37229       Biographies & Memoirs, True Crime  3470182                      6   \n",
       "37230           Literature & Fiction, Fiction  3412599                      4   \n",
       "37231       Biographies & Memoirs, True Crime  2606128                      9   \n",
       "37232   Mystery, Thriller & Suspense, Mystery  2880300                     26   \n",
       "\n",
       "                                               am_format am_countText_before  \\\n",
       "0                                                    NaN               69909   \n",
       "1       Kindle Edition,  Paperback,  Hardcover,  Audi...                4888   \n",
       "2                                              Hardcover                3085   \n",
       "3                                                    NaN                 788   \n",
       "4       Library Binding,  VHS Tape,  Paperback,  Hard...                5667   \n",
       "...                                                  ...                 ...   \n",
       "37228                  Mass Market Paperback,  Hardcover                2599   \n",
       "37229                         Kindle Edition,  Hardcover                1489   \n",
       "37230                         Kindle Edition,  Paperback                1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                 968   \n",
       "37232             Kindle Edition,  Paperback,  Hardcover                4356   \n",
       "\n",
       "       am_countText_after  rating_diff  \n",
       "0                   31772         0.41  \n",
       "1                    2240         0.40  \n",
       "2                    1326         0.25  \n",
       "3                     399         0.49  \n",
       "4                    2574         0.15  \n",
       "...                   ...          ...  \n",
       "37228                1216        -0.11  \n",
       "37229                 668         0.20  \n",
       "37230                 683        -0.07  \n",
       "37231                 450        -0.45  \n",
       "37232                2184         0.56  \n",
       "\n",
       "[37233 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['asin', 'gr_average', 'gr_ratings_count', 'gr_reviews_count',\n",
       "       'gr_pub_yr', 'gr_pub_mo', 'gr_pub_day', 'gr_format', 'gr_description',\n",
       "       'gr_countDes_before', 'gr_countDes_after', 'gr_genres',\n",
       "       'gr_countText_before', 'gr_countText_after', 'am_average',\n",
       "       'am_ratings_count', 'am_reviews_count', 'am_genres', 'am_rank',\n",
       "       'am_verifiedTrue_count', 'am_format', 'am_countText_before',\n",
       "       'am_countText_after', 'rating_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata_numeric = am_gr_metadata[['asin', 'gr_ratings_count', 'gr_reviews_count', 'gr_countText_before', \n",
    "                                         'gr_countText_after', 'am_ratings_count', 'am_reviews_count', 'am_rank', \n",
    "                                         'am_verifiedTrue_count', 'am_countText_before', 'am_countText_after', \n",
    "                                         'rating_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(am_gr_metadata_numeric['rating_diff'])\n",
    "x = am_gr_metadata_numeric.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, n_jobs=num_cpu, oob_score=True)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08635801282051275\n",
      "Mean Squared Error: 0.013708338621612224\n",
      "Root Mean Squared Error: 0.11708261451476143\n",
      "R2 Score: 0.87793806673\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2344059705661188\n",
      "Mean Squared Error: 0.1015427998725964\n",
      "Root Mean Squared Error: 0.31865780999780374\n",
      "R2 Score: 0.0994459963951776\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: gr_ratings_count          Importance: 0.15\n",
      "Variable: am_rank                   Importance: 0.136\n",
      "Variable: am_countText_before       Importance: 0.133\n",
      "Variable: gr_reviews_count          Importance: 0.124\n",
      "Variable: am_countText_after        Importance: 0.1\n",
      "Variable: am_verifiedTrue_count     Importance: 0.096\n",
      "Variable: gr_countText_before       Importance: 0.08\n",
      "Variable: gr_countText_after        Importance: 0.075\n",
      "Variable: am_ratings_count          Importance: 0.053\n",
      "Variable: am_reviews_count          Importance: 0.052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 3)) for feature, importance in zip(features, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:25} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, features, rotation='vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Variable')\n",
    "plt.title('Variable Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model w/ Important Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 4 most important variables from the model above (> 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = am_gr_metadata_numeric[['gr_ratings_count', 'am_rank', 'am_countText_before', 'gr_reviews_count']]\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08911723750179051\n",
      "Mean Squared Error: 0.0145448929128778\n",
      "Root Mean Squared Error: 0.1206022094029699\n",
      "R2 Score: 0.8704892111906274\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2454043828553013\n",
      "Mean Squared Error: 0.10997076278214633\n",
      "Root Mean Squared Error: 0.3316183993419942\n",
      "R2 Score: 0.024700807667360825\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much improvements in MAE, MSE, or RMSE, but much worse R2. We'll stick to the first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Numerical Features w/ Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing rows w/ null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata_numeric_all = am_gr_metadata[['asin', 'gr_ratings_count', 'gr_reviews_count', 'gr_pub_yr', 'gr_pub_mo', \n",
    "                                             'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                                             'gr_countText_before', 'gr_countText_after', 'am_ratings_count', \n",
    "                                             'am_reviews_count', 'am_rank', 'am_verifiedTrue_count',\n",
    "                                             'am_countText_before', 'am_countText_after', 'rating_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata_numeric_no_null = am_gr_metadata[['asin', 'gr_ratings_count', 'gr_reviews_count', 'gr_pub_yr', 'gr_pub_mo', \n",
    "                                                 'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                                                 'gr_countText_before', 'gr_countText_after', 'am_ratings_count', \n",
    "                                                 'am_reviews_count', 'am_rank', 'am_verifiedTrue_count',\n",
    "                                                 'am_countText_before', 'am_countText_after', 'rating_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata_numeric_no_null = am_gr_metadata_numeric_no_null.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(am_gr_metadata_numeric_no_null['rating_diff'])\n",
    "x = am_gr_metadata_numeric_no_null.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0846611545433052\n",
      "Mean Squared Error: 0.013272025219906997\n",
      "Root Mean Squared Error: 0.11520427604870835\n",
      "R2 Score: 0.8811189988366562\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2292194574468085\n",
      "Mean Squared Error: 0.09760325171022459\n",
      "Root Mean Squared Error: 0.31241519122831496\n",
      "R2 Score: 0.13800737500052862\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better results than the first model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing null values w/ mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata_numeric_mean = am_gr_metadata[['asin', 'gr_ratings_count', 'gr_reviews_count', 'gr_pub_yr', 'gr_pub_mo', \n",
    "                                              'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                                              'gr_countText_before', 'gr_countText_after', 'am_ratings_count', \n",
    "                                              'am_reviews_count', 'am_rank', 'am_verifiedTrue_count',\n",
    "                                              'am_countText_before', 'am_countText_after', 'rating_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gr_ratings_count            0\n",
       "gr_reviews_count            0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_ratings_count            0\n",
       "am_reviews_count            0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "rating_diff                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata_numeric_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Fill null values with mean\n",
    "am_gr_metadata_numeric_mean['gr_pub_yr'].fillna(am_gr_metadata_numeric_mean['gr_pub_yr'].mean(), inplace=True)\n",
    "am_gr_metadata_numeric_mean['gr_pub_mo'].fillna(am_gr_metadata_numeric_mean['gr_pub_mo'].mean(), inplace=True)\n",
    "am_gr_metadata_numeric_mean['gr_pub_day'].fillna(am_gr_metadata_numeric_mean['gr_pub_day'].mean(), inplace=True)\n",
    "am_gr_metadata_numeric_mean['gr_countDes_before'].fillna(am_gr_metadata_numeric_mean['gr_countDes_before'].mean(), inplace=True)\n",
    "# If gr_countDes_after value is null, copy the value from gr_countDes_before\n",
    "am_gr_metadata_numeric_mean['gr_countDes_after'] = np.where(am_gr_metadata_numeric_mean['gr_countDes_after'].isnull(), am_gr_metadata_numeric_mean['gr_countDes_before'], am_gr_metadata_numeric_mean['gr_countDes_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gr_ratings_count         0\n",
       "gr_reviews_count         0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_ratings_count         0\n",
       "am_reviews_count         0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "rating_diff              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata_numeric_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(am_gr_metadata_numeric_mean['rating_diff'])\n",
    "x = am_gr_metadata_numeric_mean.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.085033401733276\n",
      "Mean Squared Error: 0.01336475290201618\n",
      "Root Mean Squared Error: 0.11560602450571587\n",
      "R2 Score: 0.8809974263165612\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2316496207970781\n",
      "Mean Squared Error: 0.09935238727925662\n",
      "Root Mean Squared Error: 0.3152021371743165\n",
      "R2 Score: 0.11887213820881204\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not better than deleting null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing null values w/ median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_metadata_numeric_median = am_gr_metadata[['asin', 'gr_ratings_count', 'gr_reviews_count', 'gr_pub_yr', 'gr_pub_mo', \n",
    "                                              'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                                              'gr_countText_before', 'gr_countText_after', 'am_ratings_count', \n",
    "                                              'am_reviews_count', 'am_rank', 'am_verifiedTrue_count',\n",
    "                                              'am_countText_before', 'am_countText_after', 'rating_diff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Fill null values with mean\n",
    "am_gr_metadata_numeric_median['gr_pub_yr'].fillna(am_gr_metadata_numeric_median['gr_pub_yr'].median(), inplace=True)\n",
    "am_gr_metadata_numeric_median['gr_pub_mo'].fillna(am_gr_metadata_numeric_median['gr_pub_mo'].median(), inplace=True)\n",
    "am_gr_metadata_numeric_median['gr_pub_day'].fillna(am_gr_metadata_numeric_median['gr_pub_day'].median(), inplace=True)\n",
    "am_gr_metadata_numeric_median['gr_countDes_before'].fillna(am_gr_metadata_numeric_median['gr_countDes_before'].median(), inplace=True)\n",
    "# If gr_countDes_after value is null, copy the value from gr_countDes_before\n",
    "am_gr_metadata_numeric_median['gr_countDes_after'] = np.where(am_gr_metadata_numeric_median['gr_countDes_after'].isnull(), am_gr_metadata_numeric_median['gr_countDes_before'], am_gr_metadata_numeric_median['gr_countDes_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(am_gr_metadata_numeric_median['rating_diff'])\n",
    "x = am_gr_metadata_numeric_median.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0848938977223893\n",
      "Mean Squared Error: 0.013327483756474707\n",
      "Root Mean Squared Error: 0.11544472164839199\n",
      "R2 Score: 0.8813292786351887\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.23173690729401655\n",
      "Mean Squared Error: 0.0993881135429262\n",
      "Root Mean Squared Error: 0.31525880406885737\n",
      "R2 Score: 0.11855529221065308\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same result as mean so nope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        paperback\n",
       "1        hardcover\n",
       "2        hardcover\n",
       "3              NaN\n",
       "4              NaN\n",
       "           ...    \n",
       "37228    paperback\n",
       "37229    paperback\n",
       "37230    paperback\n",
       "37231    paperback\n",
       "37232    paperback\n",
       "Name: gr_format, Length: 37233, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_metadata.gr_format.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gr_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audible audio</th>\n",
       "      <th>audio</th>\n",
       "      <th>audio cassette</th>\n",
       "      <th>audio cd</th>\n",
       "      <th>audio cd (unabridged)</th>\n",
       "      <th>audiobook</th>\n",
       "      <th>b</th>\n",
       "      <th>big book</th>\n",
       "      <th>board book</th>\n",
       "      <th>boxed set - hardcover</th>\n",
       "      <th>...</th>\n",
       "      <th>paperback + 2 cds</th>\n",
       "      <th>paperback boxed set</th>\n",
       "      <th>softback</th>\n",
       "      <th>softcover</th>\n",
       "      <th>spiral binding in hardcover</th>\n",
       "      <th>spiral-bound</th>\n",
       "      <th>trade paperback</th>\n",
       "      <th>unbound</th>\n",
       "      <th>unknown binding</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001053655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001061240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000161102X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001711296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312953240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312955138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312955154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312956878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312956959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       audible audio  audio  audio cassette  audio cd  audio cd (unabridged)  \\\n",
       "0                  0      0               0         0                      0   \n",
       "1                  0      0               0         0                      0   \n",
       "2                  0      0               0         0                      0   \n",
       "3                  0      0               0         0                      0   \n",
       "4                  0      0               0         0                      0   \n",
       "...              ...    ...             ...       ...                    ...   \n",
       "37228              0      0               0         0                      0   \n",
       "37229              0      0               0         0                      0   \n",
       "37230              0      0               0         0                      0   \n",
       "37231              0      0               0         0                      0   \n",
       "37232              0      0               0         0                      0   \n",
       "\n",
       "       audiobook  b  big book  board book  boxed set - hardcover  ...  \\\n",
       "0              0  0         0           0                      0  ...   \n",
       "1              0  0         0           0                      0  ...   \n",
       "2              0  0         0           0                      0  ...   \n",
       "3              0  0         0           0                      0  ...   \n",
       "4              0  0         0           0                      0  ...   \n",
       "...          ... ..       ...         ...                    ...  ...   \n",
       "37228          0  0         0           0                      0  ...   \n",
       "37229          0  0         0           0                      0  ...   \n",
       "37230          0  0         0           0                      0  ...   \n",
       "37231          0  0         0           0                      0  ...   \n",
       "37232          0  0         0           0                      0  ...   \n",
       "\n",
       "       paperback + 2 cds  paperback boxed set  softback  softcover  \\\n",
       "0                      0                    0         0          0   \n",
       "1                      0                    0         0          0   \n",
       "2                      0                    0         0          0   \n",
       "3                      0                    0         0          0   \n",
       "4                      0                    0         0          0   \n",
       "...                  ...                  ...       ...        ...   \n",
       "37228                  0                    0         0          0   \n",
       "37229                  0                    0         0          0   \n",
       "37230                  0                    0         0          0   \n",
       "37231                  0                    0         0          0   \n",
       "37232                  0                    0         0          0   \n",
       "\n",
       "       spiral binding in hardcover  spiral-bound  trade paperback  unbound  \\\n",
       "0                                0             0                0        0   \n",
       "1                                0             0                0        0   \n",
       "2                                0             0                0        0   \n",
       "3                                0             0                0        0   \n",
       "4                                0             0                0        0   \n",
       "...                            ...           ...              ...      ...   \n",
       "37228                            0             0                0        0   \n",
       "37229                            0             0                0        0   \n",
       "37230                            0             0                0        0   \n",
       "37231                            0             0                0        0   \n",
       "37232                            0             0                0        0   \n",
       "\n",
       "       unknown binding        asin  \n",
       "0                    0  000100039X  \n",
       "1                    0  0001053655  \n",
       "2                    0  0001061240  \n",
       "3                    0  000161102X  \n",
       "4                    0  0001711296  \n",
       "...                ...         ...  \n",
       "37228                0  0312953240  \n",
       "37229                0  0312955138  \n",
       "37230                0  0312955154  \n",
       "37231                0  0312956878  \n",
       "37232                0  0312956959  \n",
       "\n",
       "[37233 rows x 40 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['gr_format'].str.strip().str.lower())\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audible audio</th>\n",
       "      <th>audio</th>\n",
       "      <th>audio cassette</th>\n",
       "      <th>audio cd</th>\n",
       "      <th>audio cd (unabridged)</th>\n",
       "      <th>audiobook</th>\n",
       "      <th>b</th>\n",
       "      <th>big book</th>\n",
       "      <th>board book</th>\n",
       "      <th>boxed set - hardcover</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1910783</td>\n",
       "      <td>33</td>\n",
       "      <td>2003</td>\n",
       "      <td>887</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>1231410</td>\n",
       "      <td>110</td>\n",
       "      <td>5934</td>\n",
       "      <td>2615</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>1525356</td>\n",
       "      <td>66</td>\n",
       "      <td>3397</td>\n",
       "      <td>1565</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>328</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>2360259</td>\n",
       "      <td>78</td>\n",
       "      <td>4368</td>\n",
       "      <td>1957</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33838 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       audible audio  audio  audio cassette  audio cd  audio cd (unabridged)  \\\n",
       "0                  0      0               0         0                      0   \n",
       "1                  0      0               0         0                      0   \n",
       "2                  0      0               0         0                      0   \n",
       "3                  0      0               0         0                      0   \n",
       "4                  0      0               0         0                      0   \n",
       "...              ...    ...             ...       ...                    ...   \n",
       "33833              0      0               0         0                      0   \n",
       "33834              0      0               0         0                      0   \n",
       "33835              0      0               0         0                      0   \n",
       "33836              0      0               0         0                      0   \n",
       "33837              0      0               0         0                      0   \n",
       "\n",
       "       audiobook  b  big book  board book  boxed set - hardcover  ...  \\\n",
       "0              0  0         0           0                      0  ...   \n",
       "1              0  0         0           0                      0  ...   \n",
       "2              0  0         0           0                      0  ...   \n",
       "3              0  0         0           0                      0  ...   \n",
       "4              0  0         0           0                      0  ...   \n",
       "...          ... ..       ...         ...                    ...  ...   \n",
       "33833          0  0         0           0                      0  ...   \n",
       "33834          0  0         0           0                      0  ...   \n",
       "33835          0  0         0           0                      0  ...   \n",
       "33836          0  0         0           0                      0  ...   \n",
       "33837          0  0         0           0                      0  ...   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  \\\n",
       "0                   66.0                42320               17834   \n",
       "1                   19.0                   83                  36   \n",
       "2                   18.0                   47                  28   \n",
       "3                    8.0                   49                  22   \n",
       "4                   59.0                  328                 140   \n",
       "...                  ...                  ...                 ...   \n",
       "33833               20.0                  219                  94   \n",
       "33834               82.0                  125                  52   \n",
       "33835               33.0                  362                 184   \n",
       "33836              103.0                  152                  76   \n",
       "33837               39.0                  137                  72   \n",
       "\n",
       "       am_ratings_count  am_reviews_count  am_rank  am_verifiedTrue_count  \\\n",
       "0                  1453              1453  1810945                   1130   \n",
       "1                    42                42  1910783                     33   \n",
       "2                   146               146  1231410                    110   \n",
       "3                    84                84  1525356                     66   \n",
       "4                   110               110  2360259                     78   \n",
       "...                 ...               ...      ...                    ...   \n",
       "33833                13                13   443719                      4   \n",
       "33834                12                12  3470182                      6   \n",
       "33835                14                14  3412599                      4   \n",
       "33836                15                15  2606128                      9   \n",
       "33837                41                41  2880300                     26   \n",
       "\n",
       "       am_countText_before  am_countText_after  rating_diff  \n",
       "0                    69909               31772         0.41  \n",
       "1                     2003                 887         0.28  \n",
       "2                     5934                2615         0.51  \n",
       "3                     3397                1565         0.64  \n",
       "4                     4368                1957         0.50  \n",
       "...                    ...                 ...          ...  \n",
       "33833                 2599                1216        -0.11  \n",
       "33834                 1489                 668         0.20  \n",
       "33835                 1456                 683        -0.07  \n",
       "33836                  968                 450        -0.45  \n",
       "33837                 4356                2184         0.56  \n",
       "\n",
       "[33838 rows x 56 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(df, am_gr_metadata_numeric_no_null, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08458485893293399\n",
      "Mean Squared Error: 0.013243224957660168\n",
      "Root Mean Squared Error: 0.11507921166596584\n",
      "R2 Score: 0.8813769703182455\n",
      "Mean Absolute Error: 0.22907987588652484\n",
      "Mean Squared Error: 0.09748982778485817\n",
      "Root Mean Squared Error: 0.3122336109147415\n",
      "R2 Score: 0.13900908944601265\n"
     ]
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good as the other 2 models :( Let's try it with dummy_na=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audible audio</th>\n",
       "      <th>audio</th>\n",
       "      <th>audio cassette</th>\n",
       "      <th>audio cd</th>\n",
       "      <th>audio cd (unabridged)</th>\n",
       "      <th>audiobook</th>\n",
       "      <th>b</th>\n",
       "      <th>big book</th>\n",
       "      <th>board book</th>\n",
       "      <th>boxed set - hardcover</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1910783</td>\n",
       "      <td>33</td>\n",
       "      <td>2003</td>\n",
       "      <td>887</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>1231410</td>\n",
       "      <td>110</td>\n",
       "      <td>5934</td>\n",
       "      <td>2615</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>1525356</td>\n",
       "      <td>66</td>\n",
       "      <td>3397</td>\n",
       "      <td>1565</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>328</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>2360259</td>\n",
       "      <td>78</td>\n",
       "      <td>4368</td>\n",
       "      <td>1957</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33838 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       audible audio  audio  audio cassette  audio cd  audio cd (unabridged)  \\\n",
       "0                  0      0               0         0                      0   \n",
       "1                  0      0               0         0                      0   \n",
       "2                  0      0               0         0                      0   \n",
       "3                  0      0               0         0                      0   \n",
       "4                  0      0               0         0                      0   \n",
       "...              ...    ...             ...       ...                    ...   \n",
       "33833              0      0               0         0                      0   \n",
       "33834              0      0               0         0                      0   \n",
       "33835              0      0               0         0                      0   \n",
       "33836              0      0               0         0                      0   \n",
       "33837              0      0               0         0                      0   \n",
       "\n",
       "       audiobook  b  big book  board book  boxed set - hardcover  ...  \\\n",
       "0              0  0         0           0                      0  ...   \n",
       "1              0  0         0           0                      0  ...   \n",
       "2              0  0         0           0                      0  ...   \n",
       "3              0  0         0           0                      0  ...   \n",
       "4              0  0         0           0                      0  ...   \n",
       "...          ... ..       ...         ...                    ...  ...   \n",
       "33833          0  0         0           0                      0  ...   \n",
       "33834          0  0         0           0                      0  ...   \n",
       "33835          0  0         0           0                      0  ...   \n",
       "33836          0  0         0           0                      0  ...   \n",
       "33837          0  0         0           0                      0  ...   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  \\\n",
       "0                   66.0                42320               17834   \n",
       "1                   19.0                   83                  36   \n",
       "2                   18.0                   47                  28   \n",
       "3                    8.0                   49                  22   \n",
       "4                   59.0                  328                 140   \n",
       "...                  ...                  ...                 ...   \n",
       "33833               20.0                  219                  94   \n",
       "33834               82.0                  125                  52   \n",
       "33835               33.0                  362                 184   \n",
       "33836              103.0                  152                  76   \n",
       "33837               39.0                  137                  72   \n",
       "\n",
       "       am_ratings_count  am_reviews_count  am_rank  am_verifiedTrue_count  \\\n",
       "0                  1453              1453  1810945                   1130   \n",
       "1                    42                42  1910783                     33   \n",
       "2                   146               146  1231410                    110   \n",
       "3                    84                84  1525356                     66   \n",
       "4                   110               110  2360259                     78   \n",
       "...                 ...               ...      ...                    ...   \n",
       "33833                13                13   443719                      4   \n",
       "33834                12                12  3470182                      6   \n",
       "33835                14                14  3412599                      4   \n",
       "33836                15                15  2606128                      9   \n",
       "33837                41                41  2880300                     26   \n",
       "\n",
       "       am_countText_before  am_countText_after  rating_diff  \n",
       "0                    69909               31772         0.41  \n",
       "1                     2003                 887         0.28  \n",
       "2                     5934                2615         0.51  \n",
       "3                     3397                1565         0.64  \n",
       "4                     4368                1957         0.50  \n",
       "...                    ...                 ...          ...  \n",
       "33833                 2599                1216        -0.11  \n",
       "33834                 1489                 668         0.20  \n",
       "33835                 1456                 683        -0.07  \n",
       "33836                  968                 450        -0.45  \n",
       "33837                 4356                2184         0.56  \n",
       "\n",
       "[33838 rows x 57 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['gr_format'].str.strip().str.lower(), dummy_na=True)\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_metadata_numeric_no_null, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08457446331468196\n",
      "Mean Squared Error: 0.013243460686748355\n",
      "Root Mean Squared Error: 0.11508023586501878\n",
      "R2 Score: 0.8813748588311482\n",
      "Mean Absolute Error: 0.2290636631205674\n",
      "Mean Squared Error: 0.09744965813653665\n",
      "Root Mean Squared Error: 0.31216927801520866\n",
      "R2 Score: 0.1393638516080845\n"
     ]
    }
   ],
   "source": [
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, still not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gr_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historical fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>comics</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>non-fiction</th>\n",
       "      <th>poetry</th>\n",
       "      <th>romance</th>\n",
       "      <th>young-adult</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001053655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001061240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>000161102X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0001711296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312953240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312955138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312955154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312956878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0312956959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        biography   children   comics   crime   fantasy   fiction   graphic  \\\n",
       "0               0          0        0       0         0         1         0   \n",
       "1               1          0        1       0         0         1         1   \n",
       "2               0          1        0       0         0         0         0   \n",
       "3               1          0        0       0         0         1         0   \n",
       "4               0          0        0       0         1         1         0   \n",
       "...           ...        ...      ...     ...       ...       ...       ...   \n",
       "37228           0          0        0       1         0         0         0   \n",
       "37229           0          0        0       1         0         0         0   \n",
       "37230           0          0        0       1         0         1         0   \n",
       "37231           0          0        0       1         0         0         0   \n",
       "37232           1          0        0       1         1         1         0   \n",
       "\n",
       "        historical fiction   history   mystery  ...  comics  fantasy  fiction  \\\n",
       "0                        0         0         0  ...       0        0        0   \n",
       "1                        1         0         0  ...       0        0        0   \n",
       "2                        0         0         0  ...       0        0        0   \n",
       "3                        1         1         0  ...       0        0        0   \n",
       "4                        0         0         0  ...       0        0        0   \n",
       "...                    ...       ...       ...  ...     ...      ...      ...   \n",
       "37228                    0         0         0  ...       0        0        0   \n",
       "37229                    0         0         0  ...       0        0        0   \n",
       "37230                    0         0         0  ...       0        0        0   \n",
       "37231                    0         0         0  ...       0        0        0   \n",
       "37232                    1         1         0  ...       0        0        0   \n",
       "\n",
       "       history  mystery  non-fiction  poetry  romance  young-adult        asin  \n",
       "0            0        0            0       1        0            0  000100039X  \n",
       "1            1        0            0       0        0            0  0001053655  \n",
       "2            0        0            0       1        0            0  0001061240  \n",
       "3            0        0            0       0        0            0  000161102X  \n",
       "4            0        0            0       0        0            0  0001711296  \n",
       "...        ...      ...          ...     ...      ...          ...         ...  \n",
       "37228        0        1            0       0        0            0  0312953240  \n",
       "37229        0        1            0       0        0            0  0312955138  \n",
       "37230        0        1            0       0        0            0  0312955154  \n",
       "37231        0        1            0       0        0            0  0312956878  \n",
       "37232        0        1            0       0        0            0  0312956959  \n",
       "\n",
       "[37233 rows x 27 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['gr_genres'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_metadata_numeric_no_null, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08457446331468196\n",
      "Mean Squared Error: 0.013243460686748355\n",
      "Root Mean Squared Error: 0.11508023586501878\n",
      "R2 Score: 0.8813748588311482\n",
      "Mean Absolute Error: 0.2290636631205674\n",
      "Mean Squared Error: 0.09744965813653665\n",
      "Root Mean Squared Error: 0.31216927801520866\n",
      "R2 Score: 0.1393638516080845\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very smol improvements. Worth the time trade-off?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### am_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Amazon Video</th>\n",
       "      <th>Audible Audiobook</th>\n",
       "      <th>Audio CD</th>\n",
       "      <th>Audio CD Library Binding</th>\n",
       "      <th>Audio Cassette</th>\n",
       "      <th>Bargain Book</th>\n",
       "      <th>Bath Book</th>\n",
       "      <th>Blu-ray</th>\n",
       "      <th>Board book</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>83</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1910783</td>\n",
       "      <td>33</td>\n",
       "      <td>2003</td>\n",
       "      <td>887</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>1231410</td>\n",
       "      <td>110</td>\n",
       "      <td>5934</td>\n",
       "      <td>2615</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49</td>\n",
       "      <td>22</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>1525356</td>\n",
       "      <td>66</td>\n",
       "      <td>3397</td>\n",
       "      <td>1565</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>328</td>\n",
       "      <td>140</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>2360259</td>\n",
       "      <td>78</td>\n",
       "      <td>4368</td>\n",
       "      <td>1957</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33835</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33836</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33838 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accessory    Amazon Video    Audible Audiobook    Audio CD  \\\n",
       "0                0               0                    0           0   \n",
       "1                0               0                    0           0   \n",
       "2                0               0                    0           0   \n",
       "3                0               0                    0           0   \n",
       "4                0               0                    0           0   \n",
       "...            ...             ...                  ...         ...   \n",
       "33833            0               0                    0           0   \n",
       "33834            0               0                    0           0   \n",
       "33835            0               0                    0           0   \n",
       "33836            0               0                    0           0   \n",
       "33837            0               0                    0           0   \n",
       "\n",
       "         Audio CD Library Binding    Audio Cassette    Bargain Book  \\\n",
       "0                               0                 0               0   \n",
       "1                               0                 0               0   \n",
       "2                               0                 0               0   \n",
       "3                               0                 0               0   \n",
       "4                               0                 0               0   \n",
       "...                           ...               ...             ...   \n",
       "33833                           0                 0               0   \n",
       "33834                           0                 0               0   \n",
       "33835                           0                 0               0   \n",
       "33836                           0                 0               0   \n",
       "33837                           0                 0               0   \n",
       "\n",
       "         Bath Book    Blu-ray    Board book  ...  gr_countDes_after  \\\n",
       "0                0          0             0  ...               66.0   \n",
       "1                0          0             0  ...               19.0   \n",
       "2                0          0             0  ...               18.0   \n",
       "3                0          0             0  ...                8.0   \n",
       "4                0          0             0  ...               59.0   \n",
       "...            ...        ...           ...  ...                ...   \n",
       "33833            0          0             0  ...               20.0   \n",
       "33834            0          0             0  ...               82.0   \n",
       "33835            0          0             0  ...               33.0   \n",
       "33836            0          0             0  ...              103.0   \n",
       "33837            0          0             0  ...               39.0   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_ratings_count  \\\n",
       "0                    42320               17834              1453   \n",
       "1                       83                  36                42   \n",
       "2                       47                  28               146   \n",
       "3                       49                  22                84   \n",
       "4                      328                 140               110   \n",
       "...                    ...                 ...               ...   \n",
       "33833                  219                  94                13   \n",
       "33834                  125                  52                12   \n",
       "33835                  362                 184                14   \n",
       "33836                  152                  76                15   \n",
       "33837                  137                  72                41   \n",
       "\n",
       "       am_reviews_count  am_rank  am_verifiedTrue_count  am_countText_before  \\\n",
       "0                  1453  1810945                   1130                69909   \n",
       "1                    42  1910783                     33                 2003   \n",
       "2                   146  1231410                    110                 5934   \n",
       "3                    84  1525356                     66                 3397   \n",
       "4                   110  2360259                     78                 4368   \n",
       "...                 ...      ...                    ...                  ...   \n",
       "33833                13   443719                      4                 2599   \n",
       "33834                12  3470182                      6                 1489   \n",
       "33835                14  3412599                      4                 1456   \n",
       "33836                15  2606128                      9                  968   \n",
       "33837                41  2880300                     26                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  \n",
       "0                   31772         0.41  \n",
       "1                     887         0.28  \n",
       "2                    2615         0.51  \n",
       "3                    1565         0.64  \n",
       "4                    1957         0.50  \n",
       "...                   ...          ...  \n",
       "33833                1216        -0.11  \n",
       "33834                 668         0.20  \n",
       "33835                 683        -0.07  \n",
       "33836                 450        -0.45  \n",
       "33837                2184         0.56  \n",
       "\n",
       "[33838 rows x 132 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['am_format'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_metadata_numeric_no_null, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08427455000394038\n",
      "Mean Squared Error: 0.013171285496709737\n",
      "Root Mean Squared Error: 0.11476622106138085\n",
      "R2 Score: 0.8820213508855843\n",
      "Mean Absolute Error: 0.22784879905437352\n",
      "Mean Squared Error: 0.09681365522851063\n",
      "Root Mean Squared Error: 0.3111489277315778\n",
      "R2 Score: 0.14498077324328051\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, smol improvements. Is it worth it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gr_genres again but only w/ numeric variables w/o null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historical fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8847</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        biography   children   comics   crime   fantasy   fiction   graphic  \\\n",
       "0               0          0        0       0         0         1         0   \n",
       "1               1          0        1       0         0         1         1   \n",
       "2               0          1        0       0         0         0         0   \n",
       "3               1          0        0       0         0         1         0   \n",
       "4               0          0        0       0         1         1         0   \n",
       "...           ...        ...      ...     ...       ...       ...       ...   \n",
       "37228           0          0        0       1         0         0         0   \n",
       "37229           0          0        0       1         0         0         0   \n",
       "37230           0          0        0       1         0         1         0   \n",
       "37231           0          0        0       1         0         0         0   \n",
       "37232           1          0        0       1         1         1         0   \n",
       "\n",
       "        historical fiction   history   mystery  ...  gr_reviews_count  \\\n",
       "0                        0         0         0  ...              8847   \n",
       "1                        1         0         0  ...                85   \n",
       "2                        0         0         0  ...                36   \n",
       "3                        1         1         0  ...                75   \n",
       "4                        0         0         0  ...                65   \n",
       "...                    ...       ...       ...  ...               ...   \n",
       "37228                    0         0         0  ...                 8   \n",
       "37229                    0         0         0  ...                 4   \n",
       "37230                    0         0         0  ...                 5   \n",
       "37231                    0         0         0  ...                 4   \n",
       "37232                    1         1         0  ...                70   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_ratings_count  \\\n",
       "0                    42320               17834              1453   \n",
       "1                      158                  75                50   \n",
       "2                       49                  18                45   \n",
       "3                      130                  61                17   \n",
       "4                      257                 117               107   \n",
       "...                    ...                 ...               ...   \n",
       "37228                  219                  94                13   \n",
       "37229                  125                  52                12   \n",
       "37230                  362                 184                14   \n",
       "37231                  152                  76                15   \n",
       "37232                  137                  72                41   \n",
       "\n",
       "       am_reviews_count  am_rank  am_verifiedTrue_count  am_countText_before  \\\n",
       "0                  1453  1810945                   1130                69909   \n",
       "1                    50  9799161                     43                 4888   \n",
       "2                    45   321557                     30                 3085   \n",
       "3                    17  1542999                     13                  788   \n",
       "4                   107  2884610                     69                 5667   \n",
       "...                 ...      ...                    ...                  ...   \n",
       "37228                13   443719                      4                 2599   \n",
       "37229                12  3470182                      6                 1489   \n",
       "37230                14  3412599                      4                 1456   \n",
       "37231                15  2606128                      9                  968   \n",
       "37232                41  2880300                     26                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  \n",
       "0                   31772         0.41  \n",
       "1                    2240         0.40  \n",
       "2                    1326         0.25  \n",
       "3                     399         0.49  \n",
       "4                    2574         0.15  \n",
       "...                   ...          ...  \n",
       "37228                1216        -0.11  \n",
       "37229                 668         0.20  \n",
       "37230                 683        -0.07  \n",
       "37231                 450        -0.45  \n",
       "37232                2184         0.56  \n",
       "\n",
       "[37233 rows x 38 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['gr_genres'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_metadata_numeric, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08335464045265716\n",
      "Mean Squared Error: 0.012957724555450498\n",
      "Root Mean Squared Error: 0.11383200145587574\n",
      "R2 Score: 0.8846216924110075\n",
      "Mean Absolute Error: 0.22749687399291008\n",
      "Mean Squared Error: 0.0969760749481362\n",
      "Root Mean Squared Error: 0.3114098183232767\n",
      "R2 Score: 0.1399469715430416\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than on the model w/ all numeric variables and deleting null rows! What about for am_format?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### am_format again but on the model w/ only numeric variables w/o null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Amazon Video</th>\n",
       "      <th>Audible Audiobook</th>\n",
       "      <th>Audio CD</th>\n",
       "      <th>Audio CD Library Binding</th>\n",
       "      <th>Audio Cassette</th>\n",
       "      <th>Bargain Book</th>\n",
       "      <th>Bath Book</th>\n",
       "      <th>Blu-ray</th>\n",
       "      <th>Board book</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8847</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accessory    Amazon Video    Audible Audiobook    Audio CD  \\\n",
       "0                0               0                    0           0   \n",
       "1                0               0                    0           0   \n",
       "2                0               0                    0           0   \n",
       "3                0               0                    0           0   \n",
       "4                0               0                    0           0   \n",
       "...            ...             ...                  ...         ...   \n",
       "37228            0               0                    0           0   \n",
       "37229            0               0                    0           0   \n",
       "37230            0               0                    0           0   \n",
       "37231            0               0                    0           0   \n",
       "37232            0               0                    0           0   \n",
       "\n",
       "         Audio CD Library Binding    Audio Cassette    Bargain Book  \\\n",
       "0                               0                 0               0   \n",
       "1                               0                 1               0   \n",
       "2                               0                 0               0   \n",
       "3                               0                 0               0   \n",
       "4                               0                 0               0   \n",
       "...                           ...               ...             ...   \n",
       "37228                           0                 0               0   \n",
       "37229                           0                 0               0   \n",
       "37230                           0                 0               0   \n",
       "37231                           0                 0               0   \n",
       "37232                           0                 0               0   \n",
       "\n",
       "         Bath Book    Blu-ray    Board book  ...  gr_reviews_count  \\\n",
       "0                0          0             0  ...              8847   \n",
       "1                0          0             0  ...                85   \n",
       "2                0          0             0  ...                36   \n",
       "3                0          0             0  ...                75   \n",
       "4                0          0             0  ...                65   \n",
       "...            ...        ...           ...  ...               ...   \n",
       "37228            0          0             0  ...                 8   \n",
       "37229            0          0             0  ...                 4   \n",
       "37230            0          0             0  ...                 5   \n",
       "37231            0          0             0  ...                 4   \n",
       "37232            0          0             0  ...                70   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_ratings_count  \\\n",
       "0                    42320               17834              1453   \n",
       "1                      158                  75                50   \n",
       "2                       49                  18                45   \n",
       "3                      130                  61                17   \n",
       "4                      257                 117               107   \n",
       "...                    ...                 ...               ...   \n",
       "37228                  219                  94                13   \n",
       "37229                  125                  52                12   \n",
       "37230                  362                 184                14   \n",
       "37231                  152                  76                15   \n",
       "37232                  137                  72                41   \n",
       "\n",
       "       am_reviews_count  am_rank  am_verifiedTrue_count  am_countText_before  \\\n",
       "0                  1453  1810945                   1130                69909   \n",
       "1                    50  9799161                     43                 4888   \n",
       "2                    45   321557                     30                 3085   \n",
       "3                    17  1542999                     13                  788   \n",
       "4                   107  2884610                     69                 5667   \n",
       "...                 ...      ...                    ...                  ...   \n",
       "37228                13   443719                      4                 2599   \n",
       "37229                12  3470182                      6                 1489   \n",
       "37230                14  3412599                      4                 1456   \n",
       "37231                15  2606128                      9                  968   \n",
       "37232                41  2880300                     26                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  \n",
       "0                   31772         0.41  \n",
       "1                    2240         0.40  \n",
       "2                    1326         0.25  \n",
       "3                     399         0.49  \n",
       "4                    2574         0.15  \n",
       "...                   ...          ...  \n",
       "37228                1216        -0.11  \n",
       "37229                 668         0.20  \n",
       "37230                 683        -0.07  \n",
       "37231                 450        -0.45  \n",
       "37232                2184         0.56  \n",
       "\n",
       "[37233 rows x 127 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['am_format'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_metadata_numeric, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08552603889127627\n",
      "Mean Squared Error: 0.013476360132112149\n",
      "Root Mean Squared Error: 0.11608772601835282\n",
      "R2 Score: 0.8800036520417599\n",
      "Mean Absolute Error: 0.2330514663229133\n",
      "Mean Squared Error: 0.10055743831094638\n",
      "Root Mean Squared Error: 0.3171079284895702\n",
      "R2 Score: 0.10818488581378316\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No bueno!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model w/ only numeric variables w/o null & gr_genres dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model again for base stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historical fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8847</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        biography   children   comics   crime   fantasy   fiction   graphic  \\\n",
       "0               0          0        0       0         0         1         0   \n",
       "1               1          0        1       0         0         1         1   \n",
       "2               0          1        0       0         0         0         0   \n",
       "3               1          0        0       0         0         1         0   \n",
       "4               0          0        0       0         1         1         0   \n",
       "...           ...        ...      ...     ...       ...       ...       ...   \n",
       "37228           0          0        0       1         0         0         0   \n",
       "37229           0          0        0       1         0         0         0   \n",
       "37230           0          0        0       1         0         1         0   \n",
       "37231           0          0        0       1         0         0         0   \n",
       "37232           1          0        0       1         1         1         0   \n",
       "\n",
       "        historical fiction   history   mystery  ...  gr_reviews_count  \\\n",
       "0                        0         0         0  ...              8847   \n",
       "1                        1         0         0  ...                85   \n",
       "2                        0         0         0  ...                36   \n",
       "3                        1         1         0  ...                75   \n",
       "4                        0         0         0  ...                65   \n",
       "...                    ...       ...       ...  ...               ...   \n",
       "37228                    0         0         0  ...                 8   \n",
       "37229                    0         0         0  ...                 4   \n",
       "37230                    0         0         0  ...                 5   \n",
       "37231                    0         0         0  ...                 4   \n",
       "37232                    1         1         0  ...                70   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_ratings_count  \\\n",
       "0                    42320               17834              1453   \n",
       "1                      158                  75                50   \n",
       "2                       49                  18                45   \n",
       "3                      130                  61                17   \n",
       "4                      257                 117               107   \n",
       "...                    ...                 ...               ...   \n",
       "37228                  219                  94                13   \n",
       "37229                  125                  52                12   \n",
       "37230                  362                 184                14   \n",
       "37231                  152                  76                15   \n",
       "37232                  137                  72                41   \n",
       "\n",
       "       am_reviews_count  am_rank  am_verifiedTrue_count  am_countText_before  \\\n",
       "0                  1453  1810945                   1130                69909   \n",
       "1                    50  9799161                     43                 4888   \n",
       "2                    45   321557                     30                 3085   \n",
       "3                    17  1542999                     13                  788   \n",
       "4                   107  2884610                     69                 5667   \n",
       "...                 ...      ...                    ...                  ...   \n",
       "37228                13   443719                      4                 2599   \n",
       "37229                12  3470182                      6                 1489   \n",
       "37230                14  3412599                      4                 1456   \n",
       "37231                15  2606128                      9                  968   \n",
       "37232                41  2880300                     26                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  \n",
       "0                   31772         0.41  \n",
       "1                    2240         0.40  \n",
       "2                    1326         0.25  \n",
       "3                     399         0.49  \n",
       "4                    2574         0.15  \n",
       "...                   ...          ...  \n",
       "37228                1216        -0.11  \n",
       "37229                 668         0.20  \n",
       "37230                 683        -0.07  \n",
       "37231                 450        -0.45  \n",
       "37232                2184         0.56  \n",
       "\n",
       "[37233 rows x 38 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr_metadata['gr_genres'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr_metadata['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_metadata_numeric, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08335464045265716\n",
      "Mean Squared Error: 0.012957724555450498\n",
      "Root Mean Squared Error: 0.11383200145587574\n",
      "R2 Score: 0.8846216924110075\n",
      "Mean Absolute Error: 0.22749687399291013\n",
      "Mean Squared Error: 0.0969760749481362\n",
      "Root Mean Squared Error: 0.3114098183232767\n",
      "R2 Score: 0.1399469715430416\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing train & test size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train .7, test .30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08330018493649997\n",
      "Mean Squared Error: 0.012921206826819619\n",
      "Root Mean Squared Error: 0.11367148642830188\n",
      "R2 Score: 0.8848984287339166\n",
      "Mean Absolute Error: 0.2283257188898836\n",
      "Mean Squared Error: 0.09752724166044763\n",
      "Root Mean Squared Error: 0.31229351844130165\n",
      "R2 Score: 0.1352933546714019\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse than before. Try again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train .80, test .20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08309846236486937\n",
      "Mean Squared Error: 0.012860304250480082\n",
      "Root Mean Squared Error: 0.1134032814802115\n",
      "R2 Score: 0.8853289746951091\n",
      "Mean Absolute Error: 0.22819772391567075\n",
      "Mean Squared Error: 0.09891119479192964\n",
      "Root Mean Squared Error: 0.3145015020503553\n",
      "R2 Score: 0.1284869039974328\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller train error but higher test error... overfitting! But just to make sure we'll try again w/ test size = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train .85, test .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08301732810920115\n",
      "Mean Squared Error: 0.012841480941923649\n",
      "Root Mean Squared Error: 0.11332025830328683\n",
      "R2 Score: 0.8857275050740608\n",
      "Mean Absolute Error: 0.2291078334825425\n",
      "Mean Squared Error: 0.09944342592621308\n",
      "Root Mean Squared Error: 0.3153465172254374\n",
      "R2 Score: 0.11703387213434824\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: Keep test size at 0.25!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 36\n",
      "Max: 55\n",
      "Mean: 42.695\n"
     ]
    }
   ],
   "source": [
    "depths = [estimator.tree_.max_depth for estimator in rf.estimators_]\n",
    "print('Min:', np.min(depths))\n",
    "print('Max:', np.max(depths))\n",
    "print('Mean:', np.mean(depths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0927756507491824\n",
      "Mean Squared Error: 0.01550854068846598\n",
      "Root Mean Squared Error: 0.12453329148651769\n",
      "R2 Score: 0.8619086885083103\n",
      "Mean Absolute Error: 0.22733716564685724\n",
      "Mean Squared Error: 0.09687572656451082\n",
      "Root Mean Squared Error: 0.3112486571288474\n",
      "R2 Score: 0.1408369326111084\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=25)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly worse. Try again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08507587159761228\n",
      "Mean Squared Error: 0.013374986031751052\n",
      "Root Mean Squared Error: 0.11565027467218161\n",
      "R2 Score: 0.8809063083748967\n",
      "Mean Absolute Error: 0.2275414662114504\n",
      "Mean Squared Error: 0.09704414796172946\n",
      "Root Mean Squared Error: 0.31151909726649096\n",
      "R2 Score: 0.13934325148602356\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=30)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconclusive. Try again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08358551411005011\n",
      "Mean Squared Error: 0.013008577235702251\n",
      "Root Mean Squared Error: 0.11405514997448493\n",
      "R2 Score: 0.8841688894394131\n",
      "Mean Absolute Error: 0.22746297576128638\n",
      "Mean Squared Error: 0.09698642907438298\n",
      "Root Mean Squared Error: 0.31142644247780726\n",
      "R2 Score: 0.13985514376345454\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=35)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better! Keep going?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08338428501379277\n",
      "Mean Squared Error: 0.012961609764729277\n",
      "Root Mean Squared Error: 0.11384906571741939\n",
      "R2 Score: 0.8845870976895889\n",
      "Mean Absolute Error: 0.22742039717412388\n",
      "Mean Squared Error: 0.09696634692124641\n",
      "Root Mean Squared Error: 0.31139419859921347\n",
      "R2 Score: 0.1400332466267873\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better! Keep going!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08336664197778339\n",
      "Mean Squared Error: 0.012959129388535022\n",
      "Root Mean Squared Error: 0.1138381719307501\n",
      "R2 Score: 0.8846091834814462\n",
      "Mean Absolute Error: 0.22747792309271986\n",
      "Mean Squared Error: 0.09697623203510561\n",
      "Root Mean Squared Error: 0.31141007054221226\n",
      "R2 Score: 0.1399455783837099\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=45)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the same as max_depth = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08335699822949572\n",
      "Mean Squared Error: 0.012958181146893184\n",
      "Root Mean Squared Error: 0.11383400698777665\n",
      "R2 Score: 0.8846176268246703\n",
      "Mean Absolute Error: 0.2275043061186733\n",
      "Mean Squared Error: 0.09698280829695557\n",
      "Root Mean Squared Error: 0.3114206292090419\n",
      "R2 Score: 0.13988725540123192\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=50)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: max_depth = 40-45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.09617078677839849\n",
      "Mean Squared Error: 0.01920765589483956\n",
      "Root Mean Squared Error: 0.13859168768306257\n",
      "R2 Score: 0.82897098789107\n",
      "Mean Absolute Error: 0.24079418304866262\n",
      "Mean Squared Error: 0.10671091158636803\n",
      "Root Mean Squared Error: 0.326666361271509\n",
      "R2 Score: 0.053611494089218836\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 10, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08346776431181384\n",
      "Mean Squared Error: 0.012996581994064971\n",
      "Root Mean Squared Error: 0.11400255257697071\n",
      "R2 Score: 0.8842756975964554\n",
      "Mean Absolute Error: 0.227461009086007\n",
      "Mean Squared Error: 0.09700052373706364\n",
      "Root Mean Squared Error: 0.31144907085599666\n",
      "R2 Score: 0.13973014223776814\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 500, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconclusive findings, let's continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08464867709219694\n",
      "Mean Squared Error: 0.01356433886978204\n",
      "Root Mean Squared Error: 0.11646604170221482\n",
      "R2 Score: 0.8792202708383141\n",
      "Mean Absolute Error: 0.2289132596301863\n",
      "Mean Squared Error: 0.09808164408755199\n",
      "Root Mean Squared Error: 0.3131798909373844\n",
      "R2 Score: 0.1301419955525035\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 100, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good as n_estimators = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0839231435483672\n",
      "Mean Squared Error: 0.013209455778335035\n",
      "Root Mean Squared Error: 0.11493239655699795\n",
      "R2 Score: 0.8823802246024093\n",
      "Mean Absolute Error: 0.22772712523816185\n",
      "Mean Squared Error: 0.09713102715712099\n",
      "Root Mean Squared Error: 0.3116585104840248\n",
      "R2 Score: 0.13857274478995085\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 200, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08346776431181384\n",
      "Mean Squared Error: 0.012996581994064971\n",
      "Root Mean Squared Error: 0.11400255257697071\n",
      "R2 Score: 0.8842756975964554\n",
      "Mean Absolute Error: 0.227461009086007\n",
      "Mean Squared Error: 0.09700052373706364\n",
      "Root Mean Squared Error: 0.31144907085599666\n",
      "R2 Score: 0.13973014223776814\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 500, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08330671159320875\n",
      "Mean Squared Error: 0.012916231255544934\n",
      "Root Mean Squared Error: 0.11364959857186005\n",
      "R2 Score: 0.8849911574894556\n",
      "Mean Absolute Error: 0.22742261318963328\n",
      "Mean Squared Error: 0.0970342525423747\n",
      "Root Mean Squared Error: 0.3115032143371472\n",
      "R2 Score: 0.13943101112558876\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 2000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better train error but worse test error = overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.08333371910261458\n",
      "Mean Squared Error: 0.012927504885941847\n",
      "Root Mean Squared Error: 0.11369918595109574\n",
      "R2 Score: 0.884890774710827\n",
      "Mean Absolute Error: 0.22744898998377627\n",
      "Mean Squared Error: 0.09702377426498793\n",
      "Root Mean Squared Error: 0.3114863949918005\n",
      "R2 Score: 0.13952393996607182\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1500, random_state = 0, oob_score=True, n_jobs=4, max_depth=40)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: n_estimators = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### min_samples_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.09527661064360354\n",
      "Mean Squared Error: 0.01811730448852929\n",
      "Root Mean Squared Error: 0.134600536731951\n",
      "R2 Score: 0.8386797063777922\n",
      "Mean Absolute Error: 0.22740058271518235\n",
      "Mean Squared Error: 0.09696536396012541\n",
      "Root Mean Squared Error: 0.311392620272423\n",
      "R2 Score: 0.14004196422738535\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=5)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse train error but almost same test error. Continue to see what happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.12118794406662461\n",
      "Mean Squared Error: 0.02855060799705045\n",
      "Root Mean Squared Error: 0.1689692516319181\n",
      "R2 Score: 0.7457793752877078\n",
      "Mean Absolute Error: 0.227114120172975\n",
      "Mean Squared Error: 0.09676171547926513\n",
      "Root Mean Squared Error: 0.31106545208245984\n",
      "R2 Score: 0.14184806426595908\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=10)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worse training error but better test error. Continue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.16195603222982016\n",
      "Mean Squared Error: 0.04867164701531787\n",
      "Root Mean Squared Error: 0.2206165157356037\n",
      "R2 Score: 0.5666174075421244\n",
      "Mean Absolute Error: 0.2266817705903992\n",
      "Mean Squared Error: 0.09647297678354527\n",
      "Root Mean Squared Error: 0.3106009928888594\n",
      "R2 Score: 0.14440880504474796\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same findings... continue!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1860797326392722\n",
      "Mean Squared Error: 0.06372164641524446\n",
      "Root Mean Squared Error: 0.25243146874992517\n",
      "R2 Score: 0.43260904422586083\n",
      "Mean Absolute Error: 0.22676672542749535\n",
      "Mean Squared Error: 0.09658991437222163\n",
      "Root Mean Squared Error: 0.31078917994714944\n",
      "R2 Score: 0.1433717190693118\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=50)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting to overfit... back to 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_split = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17460785051712543\n",
      "Mean Squared Error: 0.05622702540566839\n",
      "Root Mean Squared Error: 0.23712238486838055\n",
      "R2 Score: 0.4993427276287898\n",
      "Mean Absolute Error: 0.22668867234523482\n",
      "Mean Squared Error: 0.09652016389936675\n",
      "Root Mean Squared Error: 0.31067694458933826\n",
      "R2 Score: 0.14399031603198753\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=35)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: min_samples_split = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing min_samples_leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1718009534312613\n",
      "Mean Squared Error: 0.05731074997071511\n",
      "Root Mean Squared Error: 0.23939663734212122\n",
      "R2 Score: 0.4896930159319076\n",
      "Mean Absolute Error: 0.22638378548403246\n",
      "Mean Squared Error: 0.09639114067035282\n",
      "Root Mean Squared Error: 0.3104692266076508\n",
      "R2 Score: 0.14513458608946384\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training error is worse but test error is better -> current best model is overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min_samples_leaf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.18060021955496142\n",
      "Mean Squared Error: 0.06302657076789636\n",
      "Root Mean Squared Error: 0.2510509326170615\n",
      "R2 Score: 0.4387981441325733\n",
      "Mean Absolute Error: 0.2263302915452586\n",
      "Mean Squared Error: 0.09633156694515613\n",
      "Root Mean Squared Error: 0.31037327034581463\n",
      "R2 Score: 0.14566292839244188\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=10)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: min_samples_leaf = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing max_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 'sqrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.18899399596000802\n",
      "Mean Squared Error: 0.06825012869690746\n",
      "Root Mean Squared Error: 0.2612472558648367\n",
      "R2 Score: 0.3922864845535116\n",
      "Mean Absolute Error: 0.22759975734587135\n",
      "Mean Squared Error: 0.09739004081877224\n",
      "Root Mean Squared Error: 0.31207377464114516\n",
      "R2 Score: 0.13627562682313255\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features='sqrt')\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best results yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 'log2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.19238528946058592\n",
      "Mean Squared Error: 0.0705244544068896\n",
      "Root Mean Squared Error: 0.26556440726665465\n",
      "R2 Score: 0.3720354095903928\n",
      "Mean Absolute Error: 0.2280465832203221\n",
      "Mean Squared Error: 0.09773819789014873\n",
      "Root Mean Squared Error: 0.3126310891292623\n",
      "R2 Score: 0.13318792149193415\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features='log2')\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as good as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17598807419587292\n",
      "Mean Squared Error: 0.059871253383688205\n",
      "Root Mean Squared Error: 0.24468603021768162\n",
      "R2 Score: 0.4668937544488868\n",
      "Mean Absolute Error: 0.2260039619244125\n",
      "Mean Squared Error: 0.09617133185862317\n",
      "Root Mean Squared Error: 0.31011503004308444\n",
      "R2 Score: 0.14708400747314754\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best one so far!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17327649241228937\n",
      "Mean Squared Error: 0.058188298199374065\n",
      "Root Mean Squared Error: 0.2412225076550156\n",
      "R2 Score: 0.48187914174303237\n",
      "Mean Absolute Error: 0.22615719120000355\n",
      "Mean Squared Error: 0.09618881724054015\n",
      "Root Mean Squared Error: 0.3101432205297097\n",
      "R2 Score: 0.14692893462987688\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.75)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17399876150778526\n",
      "Mean Squared Error: 0.05860421266992674\n",
      "Root Mean Squared Error: 0.2420830697713633\n",
      "R2 Score: 0.47817575172970217\n",
      "Mean Absolute Error: 0.22600042006505155\n",
      "Mean Squared Error: 0.09620045733576427\n",
      "Root Mean Squared Error: 0.3101619856393821\n",
      "R2 Score: 0.14682570195981492\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=(2/3))\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inconclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features = 1/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17961158774353347\n",
      "Mean Squared Error: 0.06210900691840913\n",
      "Root Mean Squared Error: 0.24921678699158514\n",
      "R2 Score: 0.4469683258342786\n",
      "Mean Absolute Error: 0.22622488356963383\n",
      "Mean Squared Error: 0.09633826315073138\n",
      "Root Mean Squared Error: 0.31038405750091513\n",
      "R2 Score: 0.14560354166342415\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=(1/3))\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: max_features = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing max_leaf_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.2269880460845918\n",
      "Mean Squared Error: 0.09541509822578721\n",
      "Root Mean Squared Error: 0.308893344418081\n",
      "R2 Score: 0.15040387649712128\n",
      "Mean Absolute Error: 0.2327939085937391\n",
      "Mean Squared Error: 0.10092311148187985\n",
      "Root Mean Squared Error: 0.3176839805244826\n",
      "R2 Score: 0.10494183521336453\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=50)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.22216063390048135\n",
      "Mean Squared Error: 0.09081029569131203\n",
      "Root Mean Squared Error: 0.3013474667079716\n",
      "R2 Score: 0.19140600776914074\n",
      "Mean Absolute Error: 0.23099824823059478\n",
      "Mean Squared Error: 0.09959585542644278\n",
      "Root Mean Squared Error: 0.3155881104009509\n",
      "R2 Score: 0.11671288895653775\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=100)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better but still NOPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.19976689937887224\n",
      "Mean Squared Error: 0.0727097341334275\n",
      "Root Mean Squared Error: 0.26964742560133503\n",
      "R2 Score: 0.35257721881179477\n",
      "Mean Absolute Error: 0.22737542108195785\n",
      "Mean Squared Error: 0.09695059929862015\n",
      "Root Mean Squared Error: 0.31136891190133315\n",
      "R2 Score: 0.14017290778071578\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=500)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.18291679179208678\n",
      "Mean Squared Error: 0.06273639042120896\n",
      "Root Mean Squared Error: 0.2504723346423891\n",
      "R2 Score: 0.44138197103467364\n",
      "Mean Absolute Error: 0.22628649842416418\n",
      "Mean Squared Error: 0.09628971296226578\n",
      "Root Mean Squared Error: 0.3103058377830907\n",
      "R2 Score: 0.1460341193769925\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=1000)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting better but still nope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17598423893879164\n",
      "Mean Squared Error: 0.059822156275163955\n",
      "Root Mean Squared Error: 0.24458568289081017\n",
      "R2 Score: 0.46733092544019783\n",
      "Mean Absolute Error: 0.22599937293715203\n",
      "Mean Squared Error: 0.0961326180925619\n",
      "Root Mean Squared Error: 0.31005260536328655\n",
      "R2 Score: 0.14742734877420327\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=5000)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better than no max_leaf_nodes specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_leaf_nodes = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17598423893879164\n",
      "Mean Squared Error: 0.059822156275163955\n",
      "Root Mean Squared Error: 0.24458568289081017\n",
      "R2 Score: 0.46733092544019783\n",
      "Mean Absolute Error: 0.22599937293715203\n",
      "Mean Squared Error: 0.0961326180925619\n",
      "Root Mean Squared Error: 0.31005260536328655\n",
      "R2 Score: 0.14742734877420327\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=10000)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: max_leaf_nodes = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using gr_genres and am_format dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historical fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8847</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        biography   children   comics   crime   fantasy   fiction   graphic  \\\n",
       "0               0          0        0       0         0         1         0   \n",
       "1               1          0        1       0         0         1         1   \n",
       "2               0          1        0       0         0         0         0   \n",
       "3               1          0        0       0         0         1         0   \n",
       "4               0          0        0       0         1         1         0   \n",
       "...           ...        ...      ...     ...       ...       ...       ...   \n",
       "37228           0          0        0       1         0         0         0   \n",
       "37229           0          0        0       1         0         0         0   \n",
       "37230           0          0        0       1         0         1         0   \n",
       "37231           0          0        0       1         0         0         0   \n",
       "37232           1          0        0       1         1         1         0   \n",
       "\n",
       "        historical fiction   history   mystery  ...  gr_reviews_count  \\\n",
       "0                        0         0         0  ...              8847   \n",
       "1                        1         0         0  ...                85   \n",
       "2                        0         0         0  ...                36   \n",
       "3                        1         1         0  ...                75   \n",
       "4                        0         0         0  ...                65   \n",
       "...                    ...       ...       ...  ...               ...   \n",
       "37228                    0         0         0  ...                 8   \n",
       "37229                    0         0         0  ...                 4   \n",
       "37230                    0         0         0  ...                 5   \n",
       "37231                    0         0         0  ...                 4   \n",
       "37232                    1         1         0  ...                70   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_ratings_count  \\\n",
       "0                    42320               17834              1453   \n",
       "1                      158                  75                50   \n",
       "2                       49                  18                45   \n",
       "3                      130                  61                17   \n",
       "4                      257                 117               107   \n",
       "...                    ...                 ...               ...   \n",
       "37228                  219                  94                13   \n",
       "37229                  125                  52                12   \n",
       "37230                  362                 184                14   \n",
       "37231                  152                  76                15   \n",
       "37232                  137                  72                41   \n",
       "\n",
       "       am_reviews_count  am_rank  am_verifiedTrue_count  am_countText_before  \\\n",
       "0                  1453  1810945                   1130                69909   \n",
       "1                    50  9799161                     43                 4888   \n",
       "2                    45   321557                     30                 3085   \n",
       "3                    17  1542999                     13                  788   \n",
       "4                   107  2884610                     69                 5667   \n",
       "...                 ...      ...                    ...                  ...   \n",
       "37228                13   443719                      4                 2599   \n",
       "37229                12  3470182                      6                 1489   \n",
       "37230                14  3412599                      4                 1456   \n",
       "37231                15  2606128                      9                  968   \n",
       "37232                41  2880300                     26                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  \n",
       "0                   31772         0.41  \n",
       "1                    2240         0.40  \n",
       "2                    1326         0.25  \n",
       "3                     399         0.49  \n",
       "4                    2574         0.15  \n",
       "...                   ...          ...  \n",
       "37228                1216        -0.11  \n",
       "37229                 668         0.20  \n",
       "37230                 683        -0.07  \n",
       "37231                 450        -0.45  \n",
       "37232                2184         0.56  \n",
       "\n",
       "[37233 rows x 38 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Amazon Video</th>\n",
       "      <th>Audible Audiobook</th>\n",
       "      <th>Audio CD</th>\n",
       "      <th>Audio CD Library Binding</th>\n",
       "      <th>Audio Cassette</th>\n",
       "      <th>Bargain Book</th>\n",
       "      <th>Bath Book</th>\n",
       "      <th>Blu-ray</th>\n",
       "      <th>Board book</th>\n",
       "      <th>...</th>\n",
       "      <th>Spiral-bound</th>\n",
       "      <th>Staple Bound</th>\n",
       "      <th>Textbook Binding</th>\n",
       "      <th>Toy</th>\n",
       "      <th>Turtleback</th>\n",
       "      <th>Unbound</th>\n",
       "      <th>Unknown Binding</th>\n",
       "      <th>VHS Tape</th>\n",
       "      <th>Vinyl</th>\n",
       "      <th>Vinyl Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Accessory    Amazon Video    Audible Audiobook    Audio CD  \\\n",
       "0                0               0                    0           0   \n",
       "1                0               0                    0           0   \n",
       "2                0               0                    0           0   \n",
       "3                0               0                    0           0   \n",
       "4                0               0                    0           0   \n",
       "...            ...             ...                  ...         ...   \n",
       "37228            0               0                    0           0   \n",
       "37229            0               0                    0           0   \n",
       "37230            0               0                    0           0   \n",
       "37231            0               0                    0           0   \n",
       "37232            0               0                    0           0   \n",
       "\n",
       "         Audio CD Library Binding    Audio Cassette    Bargain Book  \\\n",
       "0                               0                 0               0   \n",
       "1                               0                 1               0   \n",
       "2                               0                 0               0   \n",
       "3                               0                 0               0   \n",
       "4                               0                 0               0   \n",
       "...                           ...               ...             ...   \n",
       "37228                           0                 0               0   \n",
       "37229                           0                 0               0   \n",
       "37230                           0                 0               0   \n",
       "37231                           0                 0               0   \n",
       "37232                           0                 0               0   \n",
       "\n",
       "         Bath Book    Blu-ray    Board book  ...   Spiral-bound  \\\n",
       "0                0          0             0  ...              0   \n",
       "1                0          0             0  ...              0   \n",
       "2                0          0             0  ...              0   \n",
       "3                0          0             0  ...              0   \n",
       "4                0          0             0  ...              0   \n",
       "...            ...        ...           ...  ...            ...   \n",
       "37228            0          0             0  ...              0   \n",
       "37229            0          0             0  ...              0   \n",
       "37230            0          0             0  ...              0   \n",
       "37231            0          0             0  ...              0   \n",
       "37232            0          0             0  ...              0   \n",
       "\n",
       "        Staple Bound   Textbook Binding   Toy   Turtleback   Unbound  \\\n",
       "0                  0                  0     0            0         0   \n",
       "1                  0                  0     0            0         0   \n",
       "2                  0                  0     0            0         0   \n",
       "3                  0                  0     0            0         0   \n",
       "4                  0                  0     0            0         0   \n",
       "...              ...                ...   ...          ...       ...   \n",
       "37228              0                  0     0            0         0   \n",
       "37229              0                  0     0            0         0   \n",
       "37230              0                  0     0            0         0   \n",
       "37231              0                  0     0            0         0   \n",
       "37232              0                  0     0            0         0   \n",
       "\n",
       "        Unknown Binding   VHS Tape   Vinyl   Vinyl Bound  \n",
       "0                     0          0       0             0  \n",
       "1                     0          0       0             0  \n",
       "2                     0          0       0             0  \n",
       "3                     0          0       0             0  \n",
       "4                     0          0       0             0  \n",
       "...                 ...        ...     ...           ...  \n",
       "37228                 0          0       0             0  \n",
       "37229                 0          0       0             0  \n",
       "37230                 0          0       0             0  \n",
       "37231                 0          0       0             0  \n",
       "37232                 0          0       0             0  \n",
       "\n",
       "[37233 rows x 115 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.get_dummies(am_gr_metadata['am_format'].str.get_dummies(sep=','))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historical fiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>Spiral-bound</th>\n",
       "      <th>Staple Bound</th>\n",
       "      <th>Textbook Binding</th>\n",
       "      <th>Toy</th>\n",
       "      <th>Turtleback</th>\n",
       "      <th>Unbound</th>\n",
       "      <th>Unknown Binding</th>\n",
       "      <th>VHS Tape</th>\n",
       "      <th>Vinyl</th>\n",
       "      <th>Vinyl Bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 153 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        biography   children   comics   crime   fantasy   fiction   graphic  \\\n",
       "0               0          0        0       0         0         1         0   \n",
       "1               1          0        1       0         0         1         1   \n",
       "2               0          1        0       0         0         0         0   \n",
       "3               1          0        0       0         0         1         0   \n",
       "4               0          0        0       0         1         1         0   \n",
       "...           ...        ...      ...     ...       ...       ...       ...   \n",
       "37228           0          0        0       1         0         0         0   \n",
       "37229           0          0        0       1         0         0         0   \n",
       "37230           0          0        0       1         0         1         0   \n",
       "37231           0          0        0       1         0         0         0   \n",
       "37232           1          0        0       1         1         1         0   \n",
       "\n",
       "        historical fiction   history   mystery  ...   Spiral-bound  \\\n",
       "0                        0         0         0  ...              0   \n",
       "1                        1         0         0  ...              0   \n",
       "2                        0         0         0  ...              0   \n",
       "3                        1         1         0  ...              0   \n",
       "4                        0         0         0  ...              0   \n",
       "...                    ...       ...       ...  ...            ...   \n",
       "37228                    0         0         0  ...              0   \n",
       "37229                    0         0         0  ...              0   \n",
       "37230                    0         0         0  ...              0   \n",
       "37231                    0         0         0  ...              0   \n",
       "37232                    1         1         0  ...              0   \n",
       "\n",
       "        Staple Bound   Textbook Binding   Toy   Turtleback   Unbound  \\\n",
       "0                  0                  0     0            0         0   \n",
       "1                  0                  0     0            0         0   \n",
       "2                  0                  0     0            0         0   \n",
       "3                  0                  0     0            0         0   \n",
       "4                  0                  0     0            0         0   \n",
       "...              ...                ...   ...          ...       ...   \n",
       "37228              0                  0     0            0         0   \n",
       "37229              0                  0     0            0         0   \n",
       "37230              0                  0     0            0         0   \n",
       "37231              0                  0     0            0         0   \n",
       "37232              0                  0     0            0         0   \n",
       "\n",
       "        Unknown Binding   VHS Tape   Vinyl   Vinyl Bound  \n",
       "0                     0          0       0             0  \n",
       "1                     0          0       0             0  \n",
       "2                     0          0       0             0  \n",
       "3                     0          0       0             0  \n",
       "4                     0          0       0             0  \n",
       "...                 ...        ...     ...           ...  \n",
       "37228                 0          0       0             0  \n",
       "37229                 0          0       0             0  \n",
       "37230                 0          0       0             0  \n",
       "37231                 0          0       0             0  \n",
       "37232                 0          0       0             0  \n",
       "\n",
       "[37233 rows x 153 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, df2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.17523464619784684\n",
      "Mean Squared Error: 0.05937160867325297\n",
      "Root Mean Squared Error: 0.24366289966519927\n",
      "R2 Score: 0.4713426961468766\n",
      "Mean Absolute Error: 0.2254487360514314\n",
      "Mean Squared Error: 0.0956595884830423\n",
      "Root Mean Squared Error: 0.30928884312733024\n",
      "R2 Score: 0.15162251287457262\n"
     ]
    }
   ],
   "source": [
    "y = np.array(df['rating_diff'])\n",
    "x = df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 0, oob_score=True, n_jobs=4, max_depth=40, min_samples_split=25,\n",
    "                          min_samples_leaf=5, max_features=0.5, max_leaf_nodes=5000)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "print('R2 Score:', rf.score(x_train, y_train))\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print('R2 Score:', rf.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final verdict: Could be better? Inconclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best models tested: <br/>\n",
    "Ties between 1, 2. Models 1,2,3 are only slightly better than models 4 & 5. Trade-offs?\n",
    "1. Only numeric variables w/o null, gr_genres dummies, 1000 trees, .25 test <br/>\n",
    "Train: MAE 0.0834, MSE 0.0130, RMSE 0.1138, R2 0.8846 <br/>\n",
    "Test: MAE 0.2275, MSE 0.0970, RMSE 0.3114, R2 0.1399 <br/>\n",
    "2. All numeric variables, am_format dummies, delete null rows (NOTE: MIGHT BE AN ISSUE IF # ROWS > SOME %), 1000 trees, .25 test <br/>\n",
    "Train: MAE 0.0843, MSE: 0.0132, RMSE 0.1148, R2 0.8820 <br/>\n",
    "Test: MAE 0.2278, MSE: 0.0968, RMSE 0.3111, R2 0.1450 <br/>\n",
    "3. All numeric variables, gr_genres dummies, delete null rows (NOTE: MIGHT BE AN ISSUE IF # NULL ROWS > SOME %), 1000 trees, .25 test <br/>\n",
    "Train: MAE 0.0846, MSE 0.0132, RMSE 0.1151, R2 0.8814 <br/>\n",
    "Test: MAE 0.2291, MSE 0.0974, RMSE 0.3122, R2: 0.1394 <br/>\n",
    "4. All numeric variables, delete null rows (NOTE: MIGHT BE AN ISSUE IF # NULL ROWS > SOME %), 1000 trees, .25 test <br/>\n",
    "Train: MAE 0.0847, MSE 0.0133, RMSE 0.1152, R2 0.8811 <br/>\n",
    "Test: MAE 0.2316, MSE 0.0994, RMSE 0.3152, R2 0.1189 <br/>\n",
    "5. Only numeric variables w/o null, 1000 trees, .25 test <br/>\n",
    "Train: MAE 0.0864, MSE 0.0137, RMSE 0.1171, R2 0.8779  <br/>\n",
    "Test: MAE 0.2344, MSE 0.1015, RMSE 0.3187, R2 0.0994 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameter tuning: <br/>\n",
    "Training on model #1 in best models tested <br/>\n",
    "Train: MAE 0.1760, MSE 0.0598, RMSE 0.2446, R2 0.46733 <br/>\n",
    "Test: MAE 0.2260, MSE 0.0961, RMSE 0.3101, R2 0.1474 <br/>\n",
    "1. n_estimators = 1000\n",
    "2. test size = .25\n",
    "3. max_depth = 40-45\n",
    "4. min_samples_split = 25\n",
    "5. min_samples_leaf = 5\n",
    "6. max_features = .5\n",
    "7. max_leaf_nodes = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
