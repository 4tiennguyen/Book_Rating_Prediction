{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_num_pages</th>\n",
       "      <th>gr_format</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_genres</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>poetry, fiction, non-fiction</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>8.87</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>history, historical fiction, biography, non-fi...</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover,  Audi...</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>8.56</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>poetry, children</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>9.49</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>children, fiction, young-adult, history, histo...</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children, fiction, poetry, fantasy, paranormal</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>8.73</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>41.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>7.49</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>156.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>Kindle Edition,  Hardcover</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>6.96</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>48.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>mystery, thriller, crime, fiction</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>6.65</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>187.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>mystery, thriller, crime, non-fiction</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>7.11</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>60.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>mystery, thriller, crime, fiction, history, hi...</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>7.10</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  gr_pub_yr  gr_pub_mo  gr_pub_day  gr_num_pages  gr_format  \\\n",
       "0      000100039X     2010.0        1.0         1.0         127.0  Paperback   \n",
       "1      0001053655     1997.0        NaN         NaN         268.0  Hardcover   \n",
       "2      0001061240     1959.0       12.0         1.0         324.0  Hardcover   \n",
       "3      000161102X        NaN        NaN         NaN         190.0        NaN   \n",
       "4      0001711296        NaN        NaN         NaN          63.0        NaN   \n",
       "...           ...        ...        ...         ...           ...        ...   \n",
       "37228  0312953240     1995.0        7.0        15.0         570.0  Paperback   \n",
       "37229  0312955138     1995.0        9.0        15.0         320.0  Paperback   \n",
       "37230  0312955154     1995.0       10.0        15.0           NaN  Paperback   \n",
       "37231  0312956878     1995.0       10.0        15.0         608.0  Paperback   \n",
       "37232  0312956959     1996.0        1.0        28.0         308.0  Paperback   \n",
       "\n",
       "       gr_countDes_before  gr_countDes_after  \\\n",
       "0                   106.0               66.0   \n",
       "1                     NaN                NaN   \n",
       "2                     NaN                NaN   \n",
       "3                    47.0               25.0   \n",
       "4                     NaN                NaN   \n",
       "...                   ...                ...   \n",
       "37228                41.0               20.0   \n",
       "37229               156.0               82.0   \n",
       "37230                48.0               33.0   \n",
       "37231               187.0              103.0   \n",
       "37232                60.0               39.0   \n",
       "\n",
       "                                               gr_genres  gr_countText_before  \\\n",
       "0                           poetry, fiction, non-fiction                42320   \n",
       "1      history, historical fiction, biography, non-fi...                  158   \n",
       "2                                       poetry, children                   49   \n",
       "3      children, fiction, young-adult, history, histo...                  130   \n",
       "4         children, fiction, poetry, fantasy, paranormal                  257   \n",
       "...                                                  ...                  ...   \n",
       "37228              mystery, thriller, crime, non-fiction                  219   \n",
       "37229              mystery, thriller, crime, non-fiction                  125   \n",
       "37230                  mystery, thriller, crime, fiction                  362   \n",
       "37231              mystery, thriller, crime, non-fiction                  152   \n",
       "37232  mystery, thriller, crime, fiction, history, hi...                  137   \n",
       "\n",
       "       gr_countText_after  am_rank  am_verifiedTrue_count  \\\n",
       "0                   17834  1810945                   1130   \n",
       "1                      75  9799161                     43   \n",
       "2                      18   321557                     30   \n",
       "3                      61  1542999                     13   \n",
       "4                     117  2884610                     69   \n",
       "...                   ...      ...                    ...   \n",
       "37228                  94   443719                      4   \n",
       "37229                  52  3470182                      6   \n",
       "37230                 184  3412599                      4   \n",
       "37231                  76  2606128                      9   \n",
       "37232                  72  2880300                     26   \n",
       "\n",
       "                                               am_format  am_countText_before  \\\n",
       "0                                                    NaN                69909   \n",
       "1       Kindle Edition,  Paperback,  Hardcover,  Audi...                 4888   \n",
       "2                                              Hardcover                 3085   \n",
       "3                                                    NaN                  788   \n",
       "4       Library Binding,  VHS Tape,  Paperback,  Hard...                 5667   \n",
       "...                                                  ...                  ...   \n",
       "37228                  Mass Market Paperback,  Hardcover                 2599   \n",
       "37229                         Kindle Edition,  Hardcover                 1489   \n",
       "37230                         Kindle Edition,  Paperback                 1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                  968   \n",
       "37232             Kindle Edition,  Paperback,  Hardcover                 4356   \n",
       "\n",
       "       am_countText_after  rating_diff  ratings_count  text_reviews_count  \n",
       "0                   31772         8.87         221541               10300  \n",
       "1                    2240         8.56            726                 135  \n",
       "2                    1326         9.49            266                  81  \n",
       "3                     399         8.21           2946                  92  \n",
       "4                    2574         8.73            845                 172  \n",
       "...                   ...          ...            ...                 ...  \n",
       "37228                1216         7.49            100                  21  \n",
       "37229                 668         6.96             41                  16  \n",
       "37230                 683         6.65             70                  19  \n",
       "37231                 450         7.11             74                  19  \n",
       "37232                2184         7.10            422                 111  \n",
       "\n",
       "[37233 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = pd.read_csv('official_goodreads_metadata.csv')\n",
    "am = pd.read_csv('official_amazon_metadata.csv')\n",
    "am_gr = pd.merge(gr[['asin', 'average_rating', 'total_ratings_count', 'total_reviews_count', 'total_text_reviews_count',\n",
    "                    'publication_year', 'publication_month', 'publication_day', 'num_pages', 'format', 'gr_countDes_before',\n",
    "                    'gr_countDes_after', 'cleaned_genres', 'gr_countText_before', 'gr_countText_after']],\n",
    "                 am[['asin', 'average', 'rating_count', 'text_reviews_count', 'rank', 'verifiedTrue_count', 'Format',\n",
    "                    'am_countText_before', 'am_countText_after']], how='inner', on='asin')\n",
    "am_gr = am_gr.rename(columns={'average_rating':'gr_rating', 'total_ratings_count':'gr_ratings_count', \n",
    "                              'total_reviews_count':'gr_reviews_count', 'total_text_reviews_count':'gr_text_reviews_count',\n",
    "                              'publication_year':'gr_pub_yr', 'publication_month':'gr_pub_mo', 'publication_day':'gr_pub_day',\n",
    "                              'num_pages':'gr_num_pages', 'format':'gr_format', 'cleaned_genres':'gr_genres', \n",
    "                              'average':'am_rating', 'rating_count':'am_ratings_count', \n",
    "                              'text_reviews_count':'am_text_reviews_count', 'rank':'am_rank',\n",
    "                              'verifiedTrue_count':'am_verifiedTrue_count', 'Format':'am_format'})\n",
    "am_gr['rating_diff'] = am_gr['gr_rating'] + am_gr['am_rating']\n",
    "am_gr['ratings_count'] = am_gr['gr_ratings_count'] + am_gr['am_ratings_count']\n",
    "am_gr['text_reviews_count'] = am_gr['gr_text_reviews_count'] + am_gr['am_text_reviews_count']\n",
    "am_gr = am_gr.drop('gr_ratings_count', axis=1)\n",
    "am_gr = am_gr.drop('gr_reviews_count', axis=1)\n",
    "am_gr = am_gr.drop('gr_text_reviews_count', axis=1)\n",
    "am_gr = am_gr.drop('am_ratings_count', axis=1)\n",
    "am_gr = am_gr.drop('am_text_reviews_count', axis=1)\n",
    "am_gr = am_gr.drop('gr_rating', axis=1)\n",
    "am_gr = am_gr.drop('am_rating', axis=1)\n",
    "am_gr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_num_pages             1630\n",
       "gr_format                1535\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_genres                 199\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_format                  49\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "rating_diff                 0\n",
       "ratings_count               0\n",
       "text_reviews_count          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.46597280553565734\n",
      "Mean Squared Error: 0.350117638300743\n",
      "Root Mean Squared Error: 0.5917073924675464\n",
      "R2 Score: 0.189531639293663\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.46716936575965107\n",
      "Mean Squared Error: 0.3500436705664461\n",
      "Root Mean Squared Error: 0.5916448855237795\n",
      "R2 Score: 0.1937314414637782\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr[['gr_countText_before', 'gr_countText_after', 'am_rank', 'am_verifiedTrue_count', 'am_countText_before',\n",
    "            'am_countText_after', 'ratings_count', 'text_reviews_count']]\n",
    "Y = am_gr['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All numeric features w/ null rows removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_all = am_gr[['asin', 'gr_pub_yr', 'gr_pub_mo', 'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                           'gr_countText_before', 'gr_countText_after', 'am_rank', 'am_verifiedTrue_count', \n",
    "                           'am_countText_before', 'am_countText_after', 'rating_diff', 'ratings_count', 'text_reviews_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_no_null = am_gr_numeric_all.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.44606932631183954\n",
      "Mean Squared Error: 0.33912570244385687\n",
      "Root Mean Squared Error: 0.5823450029354221\n",
      "R2 Score: 0.22260560738612634\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.4486636641510659\n",
      "Mean Squared Error: 0.34382880771943863\n",
      "Root Mean Squared Error: 0.5863691735753498\n",
      "R2 Score: 0.19466942436560475\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr_numeric_no_null.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = am_gr_numeric_no_null['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Better than the last one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All numeric features w/ null values replaced by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_mean = am_gr_numeric_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "rating_diff                 0\n",
       "ratings_count               0\n",
       "text_reviews_count          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_numeric_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Fill null values with mean\n",
    "am_gr_numeric_mean['gr_pub_yr'].fillna(am_gr_numeric_mean['gr_pub_yr'].mean(), inplace=True)\n",
    "am_gr_numeric_mean['gr_pub_mo'].fillna(am_gr_numeric_mean['gr_pub_mo'].mean(), inplace=True)\n",
    "am_gr_numeric_mean['gr_pub_day'].fillna(am_gr_numeric_mean['gr_pub_day'].mean(), inplace=True)\n",
    "am_gr_numeric_mean['gr_countDes_before'].fillna(am_gr_numeric_mean['gr_countDes_before'].mean(), inplace=True)\n",
    "# If gr_countDes_after value is null, copy the value from gr_countDes_before\n",
    "am_gr_numeric_mean['gr_countDes_after'] = np.where(am_gr_numeric_mean['gr_countDes_after'].isnull(), am_gr_numeric_mean['gr_countDes_before'], am_gr_numeric_mean['gr_countDes_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "rating_diff              0\n",
       "ratings_count            0\n",
       "text_reviews_count       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr_numeric_mean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.4493589220380372\n",
      "Mean Squared Error: 0.34156749401888326\n",
      "Root Mean Squared Error: 0.5844377588921538\n",
      "R2 Score: 0.20932390526904676\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.4531094607519216\n",
      "Mean Squared Error: 0.3433562312665237\n",
      "Root Mean Squared Error: 0.5859660666510679\n",
      "R2 Score: 0.20913486823027772\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr_numeric_mean.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = am_gr_numeric_mean['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All numeric features w/ null values replaced by median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr_numeric_median = am_gr_numeric_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Fill null values with mean\n",
    "am_gr_numeric_median['gr_pub_yr'].fillna(am_gr_numeric_median['gr_pub_yr'].median(), inplace=True)\n",
    "am_gr_numeric_median['gr_pub_mo'].fillna(am_gr_numeric_median['gr_pub_mo'].median(), inplace=True)\n",
    "am_gr_numeric_median['gr_pub_day'].fillna(am_gr_numeric_median['gr_pub_day'].median(), inplace=True)\n",
    "am_gr_numeric_median['gr_countDes_before'].fillna(am_gr_numeric_median['gr_countDes_before'].median(), inplace=True)\n",
    "# If gr_countDes_after value is null, copy the value from gr_countDes_before\n",
    "am_gr_numeric_median['gr_countDes_after'] = np.where(am_gr_numeric_median['gr_countDes_after'].isnull(), am_gr_numeric_median['gr_countDes_before'], am_gr_numeric_median['gr_countDes_after'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.4509739704441613\n",
      "Mean Squared Error: 0.33648974338652476\n",
      "Root Mean Squared Error: 0.5800773598292944\n",
      "R2 Score: 0.22107811522846665\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.45380769536499094\n",
      "Mean Squared Error: 0.33763615405180664\n",
      "Root Mean Squared Error: 0.5810646728650836\n",
      "R2 Score: 0.22231013405686073\n"
     ]
    }
   ],
   "source": [
    "X =  am_gr_numeric_median.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = am_gr_numeric_median['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Not as good as replacing it with the mean, about the same as removing null rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gr_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audible audio</th>\n",
       "      <th>audio</th>\n",
       "      <th>audio cassette</th>\n",
       "      <th>audio cd</th>\n",
       "      <th>audio cd (unabridged)</th>\n",
       "      <th>audiobook</th>\n",
       "      <th>b</th>\n",
       "      <th>big book</th>\n",
       "      <th>board book</th>\n",
       "      <th>boxed set - hardcover</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>8.87</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>8.56</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>9.49</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>8.73</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>7.49</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>6.96</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>6.65</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>7.11</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>7.10</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       audible audio  audio  audio cassette  audio cd  audio cd (unabridged)  \\\n",
       "0                  0      0               0         0                      0   \n",
       "1                  0      0               0         0                      0   \n",
       "2                  0      0               0         0                      0   \n",
       "3                  0      0               0         0                      0   \n",
       "4                  0      0               0         0                      0   \n",
       "...              ...    ...             ...       ...                    ...   \n",
       "37228              0      0               0         0                      0   \n",
       "37229              0      0               0         0                      0   \n",
       "37230              0      0               0         0                      0   \n",
       "37231              0      0               0         0                      0   \n",
       "37232              0      0               0         0                      0   \n",
       "\n",
       "       audiobook  b  big book  board book  boxed set - hardcover  ...  \\\n",
       "0              0  0         0           0                      0  ...   \n",
       "1              0  0         0           0                      0  ...   \n",
       "2              0  0         0           0                      0  ...   \n",
       "3              0  0         0           0                      0  ...   \n",
       "4              0  0         0           0                      0  ...   \n",
       "...          ... ..       ...         ...                    ...  ...   \n",
       "37228          0  0         0           0                      0  ...   \n",
       "37229          0  0         0           0                      0  ...   \n",
       "37230          0  0         0           0                      0  ...   \n",
       "37231          0  0         0           0                      0  ...   \n",
       "37232          0  0         0           0                      0  ...   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0              66.000000                42320               17834  1810945   \n",
       "1             160.689085                  158                  75  9799161   \n",
       "2             160.689085                   49                  18   321557   \n",
       "3              25.000000                  130                  61  1542999   \n",
       "4             160.689085                  257                 117  2884610   \n",
       "...                  ...                  ...                 ...      ...   \n",
       "37228          20.000000                  219                  94   443719   \n",
       "37229          82.000000                  125                  52  3470182   \n",
       "37230          33.000000                  362                 184  3412599   \n",
       "37231         103.000000                  152                  76  2606128   \n",
       "37232          39.000000                  137                  72  2880300   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before  am_countText_after  \\\n",
       "0                       1130                69909               31772   \n",
       "1                         43                 4888                2240   \n",
       "2                         30                 3085                1326   \n",
       "3                         13                  788                 399   \n",
       "4                         69                 5667                2574   \n",
       "...                      ...                  ...                 ...   \n",
       "37228                      4                 2599                1216   \n",
       "37229                      6                 1489                 668   \n",
       "37230                      4                 1456                 683   \n",
       "37231                      9                  968                 450   \n",
       "37232                     26                 4356                2184   \n",
       "\n",
       "       rating_diff  ratings_count  text_reviews_count  \n",
       "0             8.87         221541               10300  \n",
       "1             8.56            726                 135  \n",
       "2             9.49            266                  81  \n",
       "3             8.21           2946                  92  \n",
       "4             8.73            845                 172  \n",
       "...            ...            ...                 ...  \n",
       "37228         7.49            100                  21  \n",
       "37229         6.96             41                  16  \n",
       "37230         6.65             70                  19  \n",
       "37231         7.11             74                  19  \n",
       "37232         7.10            422                 111  \n",
       "\n",
       "[37233 rows x 54 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['gr_format'].str.strip().str.lower())\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.4492504706689631\n",
      "Mean Squared Error: 0.33844072502177197\n",
      "Root Mean Squared Error: 0.5817565857141387\n",
      "R2 Score: 0.21656189349407706\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.45379163423756436\n",
      "Mean Squared Error: 0.3429676822564108\n",
      "Root Mean Squared Error: 0.5856344271441107\n",
      "R2 Score: 0.2100298275643444\n"
     ]
    }
   ],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than model w/ just numeric nulls replaced by mean, but not worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding gr_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['gr_genres'] = am_gr['gr_genres'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biography</th>\n",
       "      <th>children</th>\n",
       "      <th>comics</th>\n",
       "      <th>crime</th>\n",
       "      <th>fantasy</th>\n",
       "      <th>fiction</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historicalfiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>8.87</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>8.56</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>9.49</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>8.73</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>7.49</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>6.96</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>6.65</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>7.11</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>7.10</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       biography  children  comics  crime  fantasy  fiction  graphic  \\\n",
       "0              0         0       0      0        0        1        0   \n",
       "1              1         0       1      0        0        1        1   \n",
       "2              0         1       0      0        0        0        0   \n",
       "3              1         1       0      0        0        1        0   \n",
       "4              0         1       0      0        1        1        0   \n",
       "...          ...       ...     ...    ...      ...      ...      ...   \n",
       "37228          0         0       0      1        0        0        0   \n",
       "37229          0         0       0      1        0        0        0   \n",
       "37230          0         0       0      1        0        1        0   \n",
       "37231          0         0       0      1        0        0        0   \n",
       "37232          1         0       0      1        1        1        0   \n",
       "\n",
       "       historicalfiction  history  mystery  ...  gr_countDes_after  \\\n",
       "0                      0        0        0  ...          66.000000   \n",
       "1                      1        1        0  ...         160.689085   \n",
       "2                      0        0        0  ...         160.689085   \n",
       "3                      1        1        0  ...          25.000000   \n",
       "4                      0        0        0  ...         160.689085   \n",
       "...                  ...      ...      ...  ...                ...   \n",
       "37228                  0        0        1  ...          20.000000   \n",
       "37229                  0        0        1  ...          82.000000   \n",
       "37230                  0        0        1  ...          33.000000   \n",
       "37231                  0        0        1  ...         103.000000   \n",
       "37232                  1        1        1  ...          39.000000   \n",
       "\n",
       "       gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0                    42320               17834  1810945   \n",
       "1                      158                  75  9799161   \n",
       "2                       49                  18   321557   \n",
       "3                      130                  61  1542999   \n",
       "4                      257                 117  2884610   \n",
       "...                    ...                 ...      ...   \n",
       "37228                  219                  94   443719   \n",
       "37229                  125                  52  3470182   \n",
       "37230                  362                 184  3412599   \n",
       "37231                  152                  76  2606128   \n",
       "37232                  137                  72  2880300   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before am_countText_after  \\\n",
       "0                       1130                69909              31772   \n",
       "1                         43                 4888               2240   \n",
       "2                         30                 3085               1326   \n",
       "3                         13                  788                399   \n",
       "4                         69                 5667               2574   \n",
       "...                      ...                  ...                ...   \n",
       "37228                      4                 2599               1216   \n",
       "37229                      6                 1489                668   \n",
       "37230                      4                 1456                683   \n",
       "37231                      9                  968                450   \n",
       "37232                     26                 4356               2184   \n",
       "\n",
       "       rating_diff  ratings_count  text_reviews_count  \n",
       "0             8.87         221541               10300  \n",
       "1             8.56            726                 135  \n",
       "2             9.49            266                  81  \n",
       "3             8.21           2946                  92  \n",
       "4             8.73            845                 172  \n",
       "...            ...            ...                 ...  \n",
       "37228         7.49            100                  21  \n",
       "37229         6.96             41                  16  \n",
       "37230         6.65             70                  19  \n",
       "37231         7.11             74                  19  \n",
       "37232         7.10            422                 111  \n",
       "\n",
       "[37233 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['gr_genres'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['biography', 'children', 'comics', 'crime', 'fantasy', 'fiction',\n",
       "       'graphic', 'historicalfiction', 'history', 'mystery', 'non-fiction',\n",
       "       'paranormal', 'poetry', 'romance', 'thriller', 'young-adult', 'asin',\n",
       "       'gr_pub_yr', 'gr_pub_mo', 'gr_pub_day', 'gr_countDes_before',\n",
       "       'gr_countDes_after', 'gr_countText_before', 'gr_countText_after',\n",
       "       'am_rank', 'am_verifiedTrue_count', 'am_countText_before',\n",
       "       'am_countText_after', 'rating_diff', 'ratings_count',\n",
       "       'text_reviews_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.4327131302459282\n",
      "Mean Squared Error: 0.32234701509865354\n",
      "Root Mean Squared Error: 0.5677561229072334\n",
      "R2 Score: 0.25381635105976275\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.44360506168099145\n",
      "Mean Squared Error: 0.3317168209759363\n",
      "Root Mean Squared Error: 0.5759486270284324\n",
      "R2 Score: 0.235944353292577\n"
     ]
    }
   ],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better still but worth?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding am_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['am_format'] = am_gr['am_format'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessory</th>\n",
       "      <th>AmazonVideo</th>\n",
       "      <th>AudibleAudiobook</th>\n",
       "      <th>AudioCD</th>\n",
       "      <th>AudioCDLibraryBinding</th>\n",
       "      <th>AudioCassette</th>\n",
       "      <th>BargainBook</th>\n",
       "      <th>BathBook</th>\n",
       "      <th>Blu-ray</th>\n",
       "      <th>Boardbook</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>8.87</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>8.56</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>9.49</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>8.73</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>7.49</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>6.96</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>6.65</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>7.11</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>7.10</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accessory  AmazonVideo  AudibleAudiobook  AudioCD  \\\n",
       "0              0            0                 0        0   \n",
       "1              0            0                 0        0   \n",
       "2              0            0                 0        0   \n",
       "3              0            0                 0        0   \n",
       "4              0            0                 0        0   \n",
       "...          ...          ...               ...      ...   \n",
       "37228          0            0                 0        0   \n",
       "37229          0            0                 0        0   \n",
       "37230          0            0                 0        0   \n",
       "37231          0            0                 0        0   \n",
       "37232          0            0                 0        0   \n",
       "\n",
       "       AudioCDLibraryBinding  AudioCassette  BargainBook  BathBook  Blu-ray  \\\n",
       "0                          0              0            0         0        0   \n",
       "1                          0              1            0         0        0   \n",
       "2                          0              0            0         0        0   \n",
       "3                          0              0            0         0        0   \n",
       "4                          0              0            0         0        0   \n",
       "...                      ...            ...          ...       ...      ...   \n",
       "37228                      0              0            0         0        0   \n",
       "37229                      0              0            0         0        0   \n",
       "37230                      0              0            0         0        0   \n",
       "37231                      0              0            0         0        0   \n",
       "37232                      0              0            0         0        0   \n",
       "\n",
       "       Boardbook  ...  gr_countDes_after  gr_countText_before  \\\n",
       "0              0  ...          66.000000                42320   \n",
       "1              0  ...         160.689085                  158   \n",
       "2              0  ...         160.689085                   49   \n",
       "3              0  ...          25.000000                  130   \n",
       "4              0  ...         160.689085                  257   \n",
       "...          ...  ...                ...                  ...   \n",
       "37228          0  ...          20.000000                  219   \n",
       "37229          0  ...          82.000000                  125   \n",
       "37230          0  ...          33.000000                  362   \n",
       "37231          0  ...         103.000000                  152   \n",
       "37232          0  ...          39.000000                  137   \n",
       "\n",
       "       gr_countText_after  am_rank  am_verifiedTrue_count  \\\n",
       "0                   17834  1810945                   1130   \n",
       "1                      75  9799161                     43   \n",
       "2                      18   321557                     30   \n",
       "3                      61  1542999                     13   \n",
       "4                     117  2884610                     69   \n",
       "...                   ...      ...                    ...   \n",
       "37228                  94   443719                      4   \n",
       "37229                  52  3470182                      6   \n",
       "37230                 184  3412599                      4   \n",
       "37231                  76  2606128                      9   \n",
       "37232                  72  2880300                     26   \n",
       "\n",
       "       am_countText_before  am_countText_after  rating_diff  ratings_count  \\\n",
       "0                    69909               31772         8.87         221541   \n",
       "1                     4888                2240         8.56            726   \n",
       "2                     3085                1326         9.49            266   \n",
       "3                      788                 399         8.21           2946   \n",
       "4                     5667                2574         8.73            845   \n",
       "...                    ...                 ...          ...            ...   \n",
       "37228                 2599                1216         7.49            100   \n",
       "37229                 1489                 668         6.96             41   \n",
       "37230                 1456                 683         6.65             70   \n",
       "37231                  968                 450         7.11             74   \n",
       "37232                 4356                2184         7.10            422   \n",
       "\n",
       "       text_reviews_count  \n",
       "0                   10300  \n",
       "1                     135  \n",
       "2                      81  \n",
       "3                      92  \n",
       "4                     172  \n",
       "...                   ...  \n",
       "37228                  21  \n",
       "37229                  16  \n",
       "37230                  19  \n",
       "37231                  19  \n",
       "37232                 111  \n",
       "\n",
       "[37233 rows x 85 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['am_format'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Accessory', 'AmazonVideo', 'AudibleAudiobook', 'AudioCD',\n",
       "       'AudioCDLibraryBinding', 'AudioCassette', 'BargainBook', 'BathBook',\n",
       "       'Blu-ray', 'Boardbook', 'BondedLeather', 'CD-ROM', 'Calendar',\n",
       "       'CardBook', 'Cards', 'Comic', 'DVD', 'DVD-ROM', 'DVDAudio', 'Diary',\n",
       "       'Digital', 'Diskette', 'Flexibound', 'Hardcover', 'Hardcover-spiral',\n",
       "       'HardcoverComic', 'Home', 'ImitationLeather', 'Journal',\n",
       "       'KindleEdition', 'KindleEditionwithAudio/Video', 'Kitchen',\n",
       "       'LeatherBound', 'LibraryBinding', 'LooseLeaf', 'MP3CD',\n",
       "       'MP3CDLibraryBinding', 'MP3Music', 'Map', 'MassMarketPaperback',\n",
       "       'Misc.', 'Misc.Supplies', 'OfficeProduct', 'Pamphlet', 'Paperback',\n",
       "       'PerfectPaperback', 'PlasticComb', 'Pop-Up',\n",
       "       'PreloadedDigitalAudioPlayer', 'PrintedAccessCode',\n",
       "       'PrintonDemand(Paperback)', 'RagBook', 'Ring-bound', 'Roughcut',\n",
       "       'School&LibraryBinding', 'School&amp;LibraryBinding', 'Sheetmusic',\n",
       "       'SingleIssueMagazine', 'Spiral-bound', 'StapleBound', 'Stationery',\n",
       "       'TextbookBinding', 'Toy', 'Turtleback', 'UMDforPSP', 'Unbound',\n",
       "       'UnknownBinding', 'VHSTape', 'Vinyl', 'VinylBound', 'asin', 'gr_pub_yr',\n",
       "       'gr_pub_mo', 'gr_pub_day', 'gr_countDes_before', 'gr_countDes_after',\n",
       "       'gr_countText_before', 'gr_countText_after', 'am_rank',\n",
       "       'am_verifiedTrue_count', 'am_countText_before', 'am_countText_after',\n",
       "       'rating_diff', 'ratings_count', 'text_reviews_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
      "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
      "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.43944975473518766\n",
      "Mean Squared Error: 0.323579709887535\n",
      "Root Mean Squared Error: 0.568840671794427\n",
      "R2 Score: 0.2509628526480723\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.45168166384670394\n",
      "Mean Squared Error: 0.341043164566802\n",
      "Root Mean Squared Error: 0.583989010655853\n",
      "R2 Score: 0.21446264047870833\n"
     ]
    }
   ],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,14,14),max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "print(model)\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "print('R2 Score:', r2_score(y_train, y_pred))\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not worth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['gr_genres'] = am_gr['gr_genres'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accessory</th>\n",
       "      <th>AmazonVideo</th>\n",
       "      <th>AudibleAudiobook</th>\n",
       "      <th>AudioCD</th>\n",
       "      <th>AudioCDLibraryBinding</th>\n",
       "      <th>AudioCassette</th>\n",
       "      <th>BargainBook</th>\n",
       "      <th>BathBook</th>\n",
       "      <th>Blu-ray</th>\n",
       "      <th>Boardbook</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>rating_diff</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "      <td>8.87</td>\n",
       "      <td>221541</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "      <td>8.56</td>\n",
       "      <td>726</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>9.49</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "      <td>8.21</td>\n",
       "      <td>2946</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>8.73</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "      <td>7.49</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "      <td>6.96</td>\n",
       "      <td>41</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>6.65</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>7.11</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "      <td>7.10</td>\n",
       "      <td>422</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Accessory  AmazonVideo  AudibleAudiobook  AudioCD  \\\n",
       "0              0            0                 0        0   \n",
       "1              0            0                 0        0   \n",
       "2              0            0                 0        0   \n",
       "3              0            0                 0        0   \n",
       "4              0            0                 0        0   \n",
       "...          ...          ...               ...      ...   \n",
       "37228          0            0                 0        0   \n",
       "37229          0            0                 0        0   \n",
       "37230          0            0                 0        0   \n",
       "37231          0            0                 0        0   \n",
       "37232          0            0                 0        0   \n",
       "\n",
       "       AudioCDLibraryBinding  AudioCassette  BargainBook  BathBook  Blu-ray  \\\n",
       "0                          0              0            0         0        0   \n",
       "1                          0              1            0         0        0   \n",
       "2                          0              0            0         0        0   \n",
       "3                          0              0            0         0        0   \n",
       "4                          0              0            0         0        0   \n",
       "...                      ...            ...          ...       ...      ...   \n",
       "37228                      0              0            0         0        0   \n",
       "37229                      0              0            0         0        0   \n",
       "37230                      0              0            0         0        0   \n",
       "37231                      0              0            0         0        0   \n",
       "37232                      0              0            0         0        0   \n",
       "\n",
       "       Boardbook  ...  gr_countDes_after  gr_countText_before  \\\n",
       "0              0  ...          66.000000                42320   \n",
       "1              0  ...         160.689085                  158   \n",
       "2              0  ...         160.689085                   49   \n",
       "3              0  ...          25.000000                  130   \n",
       "4              0  ...         160.689085                  257   \n",
       "...          ...  ...                ...                  ...   \n",
       "37228          0  ...          20.000000                  219   \n",
       "37229          0  ...          82.000000                  125   \n",
       "37230          0  ...          33.000000                  362   \n",
       "37231          0  ...         103.000000                  152   \n",
       "37232          0  ...          39.000000                  137   \n",
       "\n",
       "       gr_countText_after  am_rank  am_verifiedTrue_count  \\\n",
       "0                   17834  1810945                   1130   \n",
       "1                      75  9799161                     43   \n",
       "2                      18   321557                     30   \n",
       "3                      61  1542999                     13   \n",
       "4                     117  2884610                     69   \n",
       "...                   ...      ...                    ...   \n",
       "37228                  94   443719                      4   \n",
       "37229                  52  3470182                      6   \n",
       "37230                 184  3412599                      4   \n",
       "37231                  76  2606128                      9   \n",
       "37232                  72  2880300                     26   \n",
       "\n",
       "       am_countText_before  am_countText_after  rating_diff  ratings_count  \\\n",
       "0                    69909               31772         8.87         221541   \n",
       "1                     4888                2240         8.56            726   \n",
       "2                     3085                1326         9.49            266   \n",
       "3                      788                 399         8.21           2946   \n",
       "4                     5667                2574         8.73            845   \n",
       "...                    ...                 ...          ...            ...   \n",
       "37228                 2599                1216         7.49            100   \n",
       "37229                 1489                 668         6.96             41   \n",
       "37230                 1456                 683         6.65             70   \n",
       "37231                  968                 450         7.11             74   \n",
       "37232                 4356                2184         7.10            422   \n",
       "\n",
       "       text_reviews_count  \n",
       "0                   10300  \n",
       "1                     135  \n",
       "2                      81  \n",
       "3                      92  \n",
       "4                     172  \n",
       "...                   ...  \n",
       "37228                  21  \n",
       "37229                  16  \n",
       "37230                  19  \n",
       "37231                  19  \n",
       "37232                 111  \n",
       "\n",
       "[37233 rows x 85 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(am_gr['am_format'].str.get_dummies(sep=','))\n",
    "df = pd.concat([df, am_gr['asin']], axis=1)\n",
    "df = pd.merge(df, am_gr_numeric_mean, how='right', on='asin')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =  df.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "Y = df['rating_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_gscv(x, y):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from matplotlib import pyplot\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_dataset = scaler.fit_transform(x)\n",
    "    mlpr = MLPRegressor(max_iter=10000)\n",
    "\n",
    "    param_list = {\"hidden_layer_sizes\": [(1,),(25,),(50,),(100,)], \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"], \n",
    "                  \"solver\": [\"lbfgs\", \"sgd\", \"adam\"], \"alpha\": [0.00005,0.0005], \n",
    "                  'learning_rate': ['constant', 'invscaling', 'adaptive'], 'early_stopping': [True]}\n",
    "    gridCV = GridSearchCV(estimator=mlpr, param_grid=param_list)\n",
    "    gridCV.fit(x, y)\n",
    "\n",
    "    # print(\"rand.cv_results_ {}\".format(rand.cv_results_))\n",
    "    print(\"---------------\")\n",
    "    print(-gridCV.best_score_)\n",
    "    print(gridCV.best_params_)\n",
    "    print(gridCV.best_estimator_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_base.py:195: RuntimeWarning: overflow encountered in square\n",
      "  return ((y_true - y_pred) ** 2).mean() / 2\n",
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-d5c5e8c862ec>\u001b[0m in \u001b[0;36mnn_gscv\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     14\u001b[0m                   'learning_rate': ['constant', 'invscaling', 'adaptive'], 'early_stopping': [True]}\n\u001b[0;32m     15\u001b[0m     \u001b[0mgridCV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mgridCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# print(\"rand.cv_results_ {}\".format(rand.cv_results_))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    620\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mMLP\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    621\u001b[0m         \"\"\"\n\u001b[1;32m--> 622\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_STOCHASTIC_SOLVERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m             self._fit_stochastic(X, y, activations, deltas, coef_grads,\n\u001b[1;32m--> 370\u001b[1;33m                                  intercept_grads, layer_units, incremental)\n\u001b[0m\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;31m# Run the LBFGS solver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit_stochastic\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units, incremental)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;31m# update no_improvement_count based on training loss or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m                 \u001b[1;31m# validation score according to early_stopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_no_improvement_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m                 \u001b[1;31m# for learning rate that needs to be updated at iteration end\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py\u001b[0m in \u001b[0;36m_update_no_improvement_count\u001b[1;34m(self, early_stopping, X_val, y_val)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[1;31m# compute validation score, use that for stopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_scores_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;31m# XXX: Remove the check in 0.23\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_reg_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'continuous-multioutput'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m             warnings.warn(\"The default value of multioutput (not exposed in \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "%time nn_gscv(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
    "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "             hidden_layer_sizes=(14, 14, 14), learning_rate='constant',\n",
    "             learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
    "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "             validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "TRAIN DATA:\n",
    "Mean Absolute Error: 0.4327131302459282\n",
    "Mean Squared Error: 0.32234701509865354\n",
    "Root Mean Squared Error: 0.5677561229072334\n",
    "R2 Score: 0.25381635105976275\n",
    "TEST DATA:\n",
    "Mean Absolute Error: 0.44360506168099145\n",
    "Mean Squared Error: 0.3317168209759363\n",
    "Root Mean Squared Error: 0.5759486270284324\n",
    "R2 Score: 0.235944353292577'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
