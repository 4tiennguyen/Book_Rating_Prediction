{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>publication_day</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>format</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>average</th>\n",
       "      <th>rating_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>rank</th>\n",
       "      <th>verifiedTrue_count</th>\n",
       "      <th>Format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>4.23</td>\n",
       "      <td>220088</td>\n",
       "      <td>8847</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>tahsil vibrants masterpiece prophet one belove...</td>\n",
       "      <td>...</td>\n",
       "      <td>42320</td>\n",
       "      <td>17834</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1453</td>\n",
       "      <td>1453</td>\n",
       "      <td>1810945</td>\n",
       "      <td>1130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69909</td>\n",
       "      <td>31772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001053655</td>\n",
       "      <td>4.08</td>\n",
       "      <td>676</td>\n",
       "      <td>85</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>158</td>\n",
       "      <td>75</td>\n",
       "      <td>4.48</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>9799161</td>\n",
       "      <td>43</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover,  Audi...</td>\n",
       "      <td>4888</td>\n",
       "      <td>2240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>4.62</td>\n",
       "      <td>221</td>\n",
       "      <td>36</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>4.87</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>000161102X</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2929</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snobby girl fashionable board school ridicule ...</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>61</td>\n",
       "      <td>4.35</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>1542999</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>788</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>4.29</td>\n",
       "      <td>738</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>4.44</td>\n",
       "      <td>107</td>\n",
       "      <td>107</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312953240</td>\n",
       "      <td>3.80</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>recount search trial serial killer target offr...</td>\n",
       "      <td>...</td>\n",
       "      <td>219</td>\n",
       "      <td>94</td>\n",
       "      <td>3.69</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>443719</td>\n",
       "      <td>4</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>2599</td>\n",
       "      <td>1216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312955138</td>\n",
       "      <td>3.38</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>jill coit voluptuous darkskinned beauty sultry...</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>52</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>3470182</td>\n",
       "      <td>6</td>\n",
       "      <td>Kindle Edition,  Hardcover</td>\n",
       "      <td>1489</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>3.36</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>paleontologist cameron alone discover yearly m...</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3.29</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>3.78</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>killer without redemption broad daylight backw...</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>3.33</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312956959</td>\n",
       "      <td>3.27</td>\n",
       "      <td>381</td>\n",
       "      <td>70</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>though vaudeville die hold still dazzle audien...</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>72</td>\n",
       "      <td>3.83</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>2880300</td>\n",
       "      <td>26</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>4356</td>\n",
       "      <td>2184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  average_rating  total_ratings_count  \\\n",
       "0      000100039X            4.23               220088   \n",
       "1      0001053655            4.08                  676   \n",
       "2      0001061240            4.62                  221   \n",
       "3      000161102X            3.86                 2929   \n",
       "4      0001711296            4.29                  738   \n",
       "...           ...             ...                  ...   \n",
       "37228  0312953240            3.80                   87   \n",
       "37229  0312955138            3.38                   29   \n",
       "37230  0312955154            3.36                   56   \n",
       "37231  0312956878            3.78                   59   \n",
       "37232  0312956959            3.27                  381   \n",
       "\n",
       "       total_text_reviews_count  publication_year  publication_month  \\\n",
       "0                          8847            2010.0                1.0   \n",
       "1                            85            1997.0                NaN   \n",
       "2                            36            1959.0               12.0   \n",
       "3                            75               NaN                NaN   \n",
       "4                            65               NaN                NaN   \n",
       "...                         ...               ...                ...   \n",
       "37228                         8            1995.0                7.0   \n",
       "37229                         4            1995.0                9.0   \n",
       "37230                         5            1995.0               10.0   \n",
       "37231                         4            1995.0               10.0   \n",
       "37232                        70            1996.0                1.0   \n",
       "\n",
       "       publication_day  num_pages     format  \\\n",
       "0                  1.0      127.0  Paperback   \n",
       "1                  NaN      268.0  Hardcover   \n",
       "2                  1.0      324.0  Hardcover   \n",
       "3                  NaN      190.0        NaN   \n",
       "4                  NaN       63.0        NaN   \n",
       "...                ...        ...        ...   \n",
       "37228             15.0      570.0  Paperback   \n",
       "37229             15.0      320.0  Paperback   \n",
       "37230             15.0        NaN  Paperback   \n",
       "37231             15.0      608.0  Paperback   \n",
       "37232             28.0      308.0  Paperback   \n",
       "\n",
       "                                     cleaned_description  ...  \\\n",
       "0      tahsil vibrants masterpiece prophet one belove...  ...   \n",
       "1                                                    NaN  ...   \n",
       "2                                                    NaN  ...   \n",
       "3      snobby girl fashionable board school ridicule ...  ...   \n",
       "4                                                    NaN  ...   \n",
       "...                                                  ...  ...   \n",
       "37228  recount search trial serial killer target offr...  ...   \n",
       "37229  jill coit voluptuous darkskinned beauty sultry...  ...   \n",
       "37230  paleontologist cameron alone discover yearly m...  ...   \n",
       "37231  killer without redemption broad daylight backw...  ...   \n",
       "37232  though vaudeville die hold still dazzle audien...  ...   \n",
       "\n",
       "       gr_countText_before  gr_countText_after average  rating_count  \\\n",
       "0                    42320               17834    4.64          1453   \n",
       "1                      158                  75    4.48            50   \n",
       "2                       49                  18    4.87            45   \n",
       "3                      130                  61    4.35            17   \n",
       "4                      257                 117    4.44           107   \n",
       "...                    ...                 ...     ...           ...   \n",
       "37228                  219                  94    3.69            13   \n",
       "37229                  125                  52    3.58            12   \n",
       "37230                  362                 184    3.29            14   \n",
       "37231                  152                  76    3.33            15   \n",
       "37232                  137                  72    3.83            41   \n",
       "\n",
       "       text_reviews_count     rank  verifiedTrue_count  \\\n",
       "0                    1453  1810945                1130   \n",
       "1                      50  9799161                  43   \n",
       "2                      45   321557                  30   \n",
       "3                      17  1542999                  13   \n",
       "4                     107  2884610                  69   \n",
       "...                   ...      ...                 ...   \n",
       "37228                  13   443719                   4   \n",
       "37229                  12  3470182                   6   \n",
       "37230                  14  3412599                   4   \n",
       "37231                  15  2606128                   9   \n",
       "37232                  41  2880300                  26   \n",
       "\n",
       "                                                  Format  am_countText_before  \\\n",
       "0                                                    NaN                69909   \n",
       "1       Kindle Edition,  Paperback,  Hardcover,  Audi...                 4888   \n",
       "2                                              Hardcover                 3085   \n",
       "3                                                    NaN                  788   \n",
       "4       Library Binding,  VHS Tape,  Paperback,  Hard...                 5667   \n",
       "...                                                  ...                  ...   \n",
       "37228                  Mass Market Paperback,  Hardcover                 2599   \n",
       "37229                         Kindle Edition,  Hardcover                 1489   \n",
       "37230                         Kindle Edition,  Paperback                 1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                  968   \n",
       "37232             Kindle Edition,  Paperback,  Hardcover                 4356   \n",
       "\n",
       "       am_countText_after  \n",
       "0                   31772  \n",
       "1                    2240  \n",
       "2                    1326  \n",
       "3                     399  \n",
       "4                    2574  \n",
       "...                   ...  \n",
       "37228                1216  \n",
       "37229                 668  \n",
       "37230                 683  \n",
       "37231                 450  \n",
       "37232                2184  \n",
       "\n",
       "[37233 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr = pd.read_csv('official_goodreads_metadata.csv')\n",
    "am = pd.read_csv('official_amazon_metadata.csv')\n",
    "am_gr = pd.merge(gr[['asin', 'average_rating', 'total_ratings_count', 'total_text_reviews_count', 'publication_year', \n",
    "                     'publication_month', 'publication_day', 'num_pages', 'format', 'cleaned_description', 'gr_countDes_before', \n",
    "                     'gr_countDes_after', 'cleaned_genres', 'gr_countText_before', 'gr_countText_after']], \n",
    "                 am[['asin', 'average', 'rating_count', 'text_reviews_count', 'rank', 'verifiedTrue_count', 'Format',\n",
    "                     'am_countText_before', 'am_countText_after']], how='inner', on='asin')\n",
    "am_gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr = am_gr.rename(columns={'average_rating':'gr_average', 'total_ratings_count':'gr_ratings_count',\n",
    "                              'total_text_reviews_count':'gr_reviews_count', 'publication_year':'gr_pub_yr', \n",
    "                              'publication_month':'gr_pub_mo', 'publication_day':'gr_pub_day', 'num_pages':'gr_num_pages', \n",
    "                              'format':'gr_format', 'cleaned_description':'gr_description', 'cleaned_genres':'gr_genres',\n",
    "                              'average':'am_average', 'rating_count':'am_ratings_count', 'text_reviews_count':'am_reviews_count', \n",
    "                              'rank':'am_rank', 'verifiedTrue_count':'am_verifiedTrue_count', 'Format':'am_format'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names=[\"asin\", \"prop_topic_1\", \"prop_topic_2\", \"prop_topic_3\", \"prop_topic_4\", 'prop_topic_5', 'prop_topic_6', \n",
    "           'prop_topic_7', 'prop_topic_8', 'prop_topic_9', 'prop_topic_10']\n",
    "lda_gen = pd.read_csv('am_gr_LDA_step5_metadata.csv', names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prop_topic_1</th>\n",
       "      <th>prop_topic_2</th>\n",
       "      <th>prop_topic_3</th>\n",
       "      <th>prop_topic_4</th>\n",
       "      <th>prop_topic_5</th>\n",
       "      <th>prop_topic_6</th>\n",
       "      <th>prop_topic_7</th>\n",
       "      <th>prop_topic_8</th>\n",
       "      <th>prop_topic_9</th>\n",
       "      <th>prop_topic_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.944674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.960657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060253</td>\n",
       "      <td>0.887754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017332</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399840</td>\n",
       "      <td>0.131761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.412079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.026173</td>\n",
       "      <td>0.051585</td>\n",
       "      <td>0.828228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321645</td>\n",
       "      <td>0.071768</td>\n",
       "      <td>0.434701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.268765</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.037515</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.034230</td>\n",
       "      <td>0.143670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>0.019026</td>\n",
       "      <td>0.291277</td>\n",
       "      <td>0.142345</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.028764</td>\n",
       "      <td>0.049903</td>\n",
       "      <td>0.053601</td>\n",
       "      <td>0.100960</td>\n",
       "      <td>0.126584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>0.071949</td>\n",
       "      <td>0.105398</td>\n",
       "      <td>0.026594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.308752</td>\n",
       "      <td>0.134243</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>0.045840</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.143098</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.180277</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.406120</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.038480</td>\n",
       "      <td>0.053886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  prop_topic_1  prop_topic_2  prop_topic_3  prop_topic_4  \\\n",
       "0      0001713353      0.000000      0.000000      0.000000      0.000000   \n",
       "1      0001061240      0.000000      0.000000      0.000000      0.000000   \n",
       "2      0001711296      0.000000      0.000000      0.017237      0.000000   \n",
       "3      0002007649      0.032234      0.000000      0.000000      0.000000   \n",
       "4      0001716069      0.000000      0.000000      0.056557      0.026173   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "37228  0312943636      0.000000      0.321645      0.071768      0.434701   \n",
       "37229  0312953038      0.016848      0.268765      0.119893      0.299400   \n",
       "37230  0312955154      0.019026      0.291277      0.142345      0.122231   \n",
       "37231  0312956878      0.071949      0.105398      0.026594      0.000000   \n",
       "37232  0312947763      0.045840      0.011807      0.143098      0.035479   \n",
       "\n",
       "       prop_topic_5  prop_topic_6  prop_topic_7  prop_topic_8  prop_topic_9  \\\n",
       "0          0.035829      0.944674      0.000000      0.000000      0.010132   \n",
       "1          0.022678      0.960657      0.000000      0.000000      0.013664   \n",
       "2          0.060253      0.887754      0.000000      0.000000      0.017332   \n",
       "3          0.014494      0.000000      0.399840      0.131761      0.000000   \n",
       "4          0.051585      0.828228      0.000000      0.000000      0.023740   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "37228      0.000000      0.087001      0.000000      0.026738      0.000000   \n",
       "37229      0.037515      0.053613      0.000000      0.025559      0.034230   \n",
       "37230      0.065309      0.028764      0.049903      0.053601      0.100960   \n",
       "37231      0.255959      0.025761      0.308752      0.134243      0.059607   \n",
       "37232      0.180277      0.032258      0.406120      0.052756      0.038480   \n",
       "\n",
       "       prop_topic_10  \n",
       "0           0.000000  \n",
       "1           0.000000  \n",
       "2           0.000000  \n",
       "3           0.412079  \n",
       "4           0.000000  \n",
       "...              ...  \n",
       "37228       0.045392  \n",
       "37229       0.143670  \n",
       "37230       0.126584  \n",
       "37231       0.000000  \n",
       "37232       0.053886  \n",
       "\n",
       "[37233 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prop_topic_1</th>\n",
       "      <th>prop_topic_2</th>\n",
       "      <th>prop_topic_3</th>\n",
       "      <th>prop_topic_4</th>\n",
       "      <th>prop_topic_5</th>\n",
       "      <th>prop_topic_6</th>\n",
       "      <th>prop_topic_7</th>\n",
       "      <th>prop_topic_8</th>\n",
       "      <th>prop_topic_9</th>\n",
       "      <th>prop_topic_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>0.051038</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.718697</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.035051</td>\n",
       "      <td>0.062258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.783295</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.036005</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.014518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>0.032466</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.040258</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>0.721677</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.034492</td>\n",
       "      <td>0.030544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>0.295647</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.547939</td>\n",
       "      <td>0.009964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>0.037673</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.040430</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.673381</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>0.083404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.126679</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.298709</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.402321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.563066</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>0.182301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>0.051609</td>\n",
       "      <td>0.061779</td>\n",
       "      <td>0.083485</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.360959</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.025956</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>0.183515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.033629</td>\n",
       "      <td>0.236083</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.039309</td>\n",
       "      <td>0.186549</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.053624</td>\n",
       "      <td>0.038400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.034881</td>\n",
       "      <td>0.136717</td>\n",
       "      <td>0.432817</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.119538</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  prop_topic_1  prop_topic_2  prop_topic_3  prop_topic_4  \\\n",
       "0      0001713353      0.051038      0.018866      0.020753      0.038229   \n",
       "1      0001061240      0.024777      0.032617      0.019454      0.011808   \n",
       "2      0001711296      0.032466      0.014493      0.021298      0.040258   \n",
       "3      0002007649      0.295647      0.005536      0.006731      0.094017   \n",
       "4      0001716069      0.044247      0.037673      0.018377      0.040430   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "37228  0312943636      0.017039      0.126679      0.004580      0.011723   \n",
       "37229  0312953038      0.015675      0.563066      0.091599      0.027186   \n",
       "37230  0312955154      0.051609      0.061779      0.083485      0.024287   \n",
       "37231  0312956878      0.034083      0.055215      0.033629      0.236083   \n",
       "37232  0312947763      0.068718      0.034424      0.034881      0.136717   \n",
       "\n",
       "       prop_topic_5  prop_topic_6  prop_topic_7  prop_topic_8  prop_topic_9  \\\n",
       "0          0.016284      0.718697      0.024824      0.014001      0.035051   \n",
       "1          0.012195      0.783295      0.048780      0.036005      0.016551   \n",
       "2          0.037349      0.721677      0.053608      0.013817      0.034492   \n",
       "3          0.008016      0.008060      0.008680      0.015411      0.547939   \n",
       "4          0.023537      0.673381      0.027283      0.016822      0.034846   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "37228      0.298709      0.095567      0.025440      0.009659      0.008282   \n",
       "37229      0.032248      0.015267      0.042616      0.013715      0.016328   \n",
       "37230      0.360959      0.059199      0.036278      0.025956      0.112933   \n",
       "37231      0.285390      0.039309      0.186549      0.037719      0.053624   \n",
       "37232      0.432817      0.030505      0.110915      0.015285      0.119538   \n",
       "\n",
       "       prop_topic_10  \n",
       "0           0.062258  \n",
       "1           0.014518  \n",
       "2           0.030544  \n",
       "3           0.009964  \n",
       "4           0.083404  \n",
       "...              ...  \n",
       "37228       0.402321  \n",
       "37229       0.182301  \n",
       "37230       0.183515  \n",
       "37231       0.038400  \n",
       "37232       0.016200  \n",
       "\n",
       "[37233 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names=[\"asin\", \"prop_topic_1\", \"prop_topic_2\", \"prop_topic_3\", \"prop_topic_4\", 'prop_topic_5', 'prop_topic_6', \n",
    "           'prop_topic_7', 'prop_topic_8', 'prop_topic_9', 'prop_topic_10', 'delete']\n",
    "lda_mallet = pd.read_csv('am_gr_lda_metadata_wmallet_10topics.csv', names=col_names)\n",
    "lda_mallet = lda_mallet.drop('delete', axis=1)\n",
    "lda_mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_average</th>\n",
       "      <th>gr_ratings_count</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_num_pages</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_average</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>35788.000000</td>\n",
       "      <td>35221.000000</td>\n",
       "      <td>35021.000000</td>\n",
       "      <td>35603.000000</td>\n",
       "      <td>36206.000000</td>\n",
       "      <td>35485.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.873311</td>\n",
       "      <td>1.147746e+04</td>\n",
       "      <td>614.953992</td>\n",
       "      <td>2005.668772</td>\n",
       "      <td>6.367764</td>\n",
       "      <td>13.958339</td>\n",
       "      <td>322.277757</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>89.978442</td>\n",
       "      <td>3.233221e+03</td>\n",
       "      <td>1429.169957</td>\n",
       "      <td>4.261219</td>\n",
       "      <td>152.651680</td>\n",
       "      <td>152.615798</td>\n",
       "      <td>1.563020e+06</td>\n",
       "      <td>104.396879</td>\n",
       "      <td>1.371004e+04</td>\n",
       "      <td>6.490044e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>8.537788e+04</td>\n",
       "      <td>3121.161743</td>\n",
       "      <td>8.987800</td>\n",
       "      <td>3.339121</td>\n",
       "      <td>10.365574</td>\n",
       "      <td>201.544695</td>\n",
       "      <td>92.759441</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>1.502964e+04</td>\n",
       "      <td>6492.465045</td>\n",
       "      <td>0.422799</td>\n",
       "      <td>702.459338</td>\n",
       "      <td>702.255076</td>\n",
       "      <td>2.092905e+06</td>\n",
       "      <td>569.410575</td>\n",
       "      <td>4.245893e+04</td>\n",
       "      <td>1.970582e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.022940e+05</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.395000e+03</td>\n",
       "      <td>1.152000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>8.210000e+02</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.740000e+02</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.232760e+05</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.956000e+03</td>\n",
       "      <td>2.387000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>3.416000e+03</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2.058000e+03</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.986080e+06</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.170400e+04</td>\n",
       "      <td>5.585000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.718437e+06</td>\n",
       "      <td>152766.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9998.000000</td>\n",
       "      <td>2124.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1.001655e+06</td>\n",
       "      <td>443150.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>44956.000000</td>\n",
       "      <td>44947.000000</td>\n",
       "      <td>2.154444e+07</td>\n",
       "      <td>39851.000000</td>\n",
       "      <td>2.384912e+06</td>\n",
       "      <td>1.082212e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gr_average  gr_ratings_count  gr_reviews_count     gr_pub_yr  \\\n",
       "count  37233.000000      3.723300e+04      37233.000000  35788.000000   \n",
       "mean       3.873311      1.147746e+04        614.953992   2005.668772   \n",
       "std        0.306148      8.537788e+04       3121.161743      8.987800   \n",
       "min        2.320000      1.000000e+00          0.000000   1900.000000   \n",
       "25%        3.690000      2.270000e+02         27.000000   2002.000000   \n",
       "50%        3.890000      8.210000e+02         83.000000   2008.000000   \n",
       "75%        4.080000      3.416000e+03        292.000000   2012.000000   \n",
       "max        5.000000      4.718437e+06     152766.000000   2019.000000   \n",
       "\n",
       "          gr_pub_mo    gr_pub_day  gr_num_pages  gr_countDes_before  \\\n",
       "count  35221.000000  35021.000000  35603.000000        36206.000000   \n",
       "mean       6.367764     13.958339    322.277757          160.689085   \n",
       "std        3.339121     10.365574    201.544695           92.759441   \n",
       "min        1.000000      1.000000      0.000000            1.000000   \n",
       "25%        4.000000      4.000000    227.000000           99.000000   \n",
       "50%        6.000000     13.000000    307.000000          147.000000   \n",
       "75%        9.000000     24.000000    384.000000          205.000000   \n",
       "max       12.000000     31.000000   9998.000000         2124.000000   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  \\\n",
       "count       35485.000000         3.723300e+04        37233.000000   \n",
       "mean           89.978442         3.233221e+03         1429.169957   \n",
       "std            52.634720         1.502964e+04         6492.465045   \n",
       "min             1.000000         1.000000e+00            0.000000   \n",
       "25%            55.000000         1.480000e+02           68.000000   \n",
       "50%            81.000000         5.740000e+02          260.000000   \n",
       "75%           115.000000         2.058000e+03          928.000000   \n",
       "max          1250.000000         1.001655e+06       443150.000000   \n",
       "\n",
       "         am_average  am_ratings_count  am_reviews_count       am_rank  \\\n",
       "count  37233.000000      37233.000000      37233.000000  3.723300e+04   \n",
       "mean       4.261219        152.651680        152.615798  1.563020e+06   \n",
       "std        0.422799        702.459338        702.255076  2.092905e+06   \n",
       "min        1.080000          6.000000          6.000000  2.300000e+01   \n",
       "25%        4.040000         22.000000         22.000000  3.022940e+05   \n",
       "50%        4.330000         43.000000         43.000000  9.232760e+05   \n",
       "75%        4.570000        107.000000        107.000000  1.986080e+06   \n",
       "max        5.000000      44956.000000      44947.000000  2.154444e+07   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before  am_countText_after  \n",
       "count           37233.000000         3.723300e+04        3.723300e+04  \n",
       "mean              104.396879         1.371004e+04        6.490044e+03  \n",
       "std               569.410575         4.245893e+04        1.970582e+04  \n",
       "min                 0.000000         7.900000e+01        4.900000e+01  \n",
       "25%                11.000000         2.395000e+03        1.152000e+03  \n",
       "50%                24.000000         4.956000e+03        2.387000e+03  \n",
       "75%                66.000000         1.170400e+04        5.585000e+03  \n",
       "max             39851.000000         2.384912e+06        1.082212e+06  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>total_ratings_count</th>\n",
       "      <th>total_reviews_count</th>\n",
       "      <th>total_text_reviews_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>publication_month</th>\n",
       "      <th>...</th>\n",
       "      <th>publisher</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>format</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>cleaned_genres</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24788</td>\n",
       "      <td>0205739415</td>\n",
       "      <td>2.92</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Longman Publishing Group</td>\n",
       "      <td>544.0</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>\"Technical Communication Strategies for Today ...</td>\n",
       "      <td>technical communication strategy today offer s...</td>\n",
       "      <td>147.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>non-fiction</td>\n",
       "      <td>96</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26677</td>\n",
       "      <td>0300084323</td>\n",
       "      <td>4.35</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Yale University Press</td>\n",
       "      <td>816.0</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>The Holocaust has been the subject of countles...</td>\n",
       "      <td>holocaust subject countless book work art memo...</td>\n",
       "      <td>214.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>history, historical fiction, biography, fictio...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  average_rating  ratings_count  reviews_count  \\\n",
       "24788  0205739415            2.92              8             32   \n",
       "26677  0300084323            4.35             23             86   \n",
       "\n",
       "       text_reviews_count  total_ratings_count  total_reviews_count  \\\n",
       "24788                   0                   12                   46   \n",
       "26677                   0                   23                   86   \n",
       "\n",
       "       total_text_reviews_count  publication_year  publication_month  ...  \\\n",
       "24788                         0            2010.0                9.0  ...   \n",
       "26677                         0            2001.0                3.0  ...   \n",
       "\n",
       "                      publisher num_pages     format  \\\n",
       "24788  Longman Publishing Group     544.0  Paperback   \n",
       "26677     Yale University Press     816.0  Hardcover   \n",
       "\n",
       "                                             description  \\\n",
       "24788  \"Technical Communication Strategies for Today ...   \n",
       "26677  The Holocaust has been the subject of countles...   \n",
       "\n",
       "                                     cleaned_description gr_countDes_before  \\\n",
       "24788  technical communication strategy today offer s...              147.0   \n",
       "26677  holocaust subject countless book work art memo...              214.0   \n",
       "\n",
       "       gr_countDes_after                                     cleaned_genres  \\\n",
       "24788               92.0                                        non-fiction   \n",
       "26677              134.0  history, historical fiction, biography, fictio...   \n",
       "\n",
       "      gr_countText_before  gr_countText_after  \n",
       "24788                  96                  40  \n",
       "26677                   2                   2  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr[gr['total_text_reviews_count'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr.loc[am_gr['asin'] == '0205739415', 'gr_reviews_count'] = 32\n",
    "am_gr.loc[am_gr['asin'] == '0300084323', 'gr_reviews_count'] = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_average</th>\n",
       "      <th>gr_ratings_count</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_num_pages</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_average</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>35788.000000</td>\n",
       "      <td>35221.000000</td>\n",
       "      <td>35021.000000</td>\n",
       "      <td>35603.000000</td>\n",
       "      <td>36206.000000</td>\n",
       "      <td>35485.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.873311</td>\n",
       "      <td>1.147746e+04</td>\n",
       "      <td>614.957162</td>\n",
       "      <td>2005.668772</td>\n",
       "      <td>6.367764</td>\n",
       "      <td>13.958339</td>\n",
       "      <td>322.277757</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>89.978442</td>\n",
       "      <td>3.233221e+03</td>\n",
       "      <td>1429.169957</td>\n",
       "      <td>4.261219</td>\n",
       "      <td>152.651680</td>\n",
       "      <td>152.615798</td>\n",
       "      <td>1.563020e+06</td>\n",
       "      <td>104.396879</td>\n",
       "      <td>1.371004e+04</td>\n",
       "      <td>6.490044e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>8.537788e+04</td>\n",
       "      <td>3121.161155</td>\n",
       "      <td>8.987800</td>\n",
       "      <td>3.339121</td>\n",
       "      <td>10.365574</td>\n",
       "      <td>201.544695</td>\n",
       "      <td>92.759441</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>1.502964e+04</td>\n",
       "      <td>6492.465045</td>\n",
       "      <td>0.422799</td>\n",
       "      <td>702.459338</td>\n",
       "      <td>702.255076</td>\n",
       "      <td>2.092905e+06</td>\n",
       "      <td>569.410575</td>\n",
       "      <td>4.245893e+04</td>\n",
       "      <td>1.970582e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.022940e+05</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.395000e+03</td>\n",
       "      <td>1.152000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>8.210000e+02</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.740000e+02</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.232760e+05</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.956000e+03</td>\n",
       "      <td>2.387000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>3.416000e+03</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2.058000e+03</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.986080e+06</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.170400e+04</td>\n",
       "      <td>5.585000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.718437e+06</td>\n",
       "      <td>152766.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9998.000000</td>\n",
       "      <td>2124.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1.001655e+06</td>\n",
       "      <td>443150.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>44956.000000</td>\n",
       "      <td>44947.000000</td>\n",
       "      <td>2.154444e+07</td>\n",
       "      <td>39851.000000</td>\n",
       "      <td>2.384912e+06</td>\n",
       "      <td>1.082212e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gr_average  gr_ratings_count  gr_reviews_count     gr_pub_yr  \\\n",
       "count  37233.000000      3.723300e+04      37233.000000  35788.000000   \n",
       "mean       3.873311      1.147746e+04        614.957162   2005.668772   \n",
       "std        0.306148      8.537788e+04       3121.161155      8.987800   \n",
       "min        2.320000      1.000000e+00          1.000000   1900.000000   \n",
       "25%        3.690000      2.270000e+02         27.000000   2002.000000   \n",
       "50%        3.890000      8.210000e+02         83.000000   2008.000000   \n",
       "75%        4.080000      3.416000e+03        292.000000   2012.000000   \n",
       "max        5.000000      4.718437e+06     152766.000000   2019.000000   \n",
       "\n",
       "          gr_pub_mo    gr_pub_day  gr_num_pages  gr_countDes_before  \\\n",
       "count  35221.000000  35021.000000  35603.000000        36206.000000   \n",
       "mean       6.367764     13.958339    322.277757          160.689085   \n",
       "std        3.339121     10.365574    201.544695           92.759441   \n",
       "min        1.000000      1.000000      0.000000            1.000000   \n",
       "25%        4.000000      4.000000    227.000000           99.000000   \n",
       "50%        6.000000     13.000000    307.000000          147.000000   \n",
       "75%        9.000000     24.000000    384.000000          205.000000   \n",
       "max       12.000000     31.000000   9998.000000         2124.000000   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  \\\n",
       "count       35485.000000         3.723300e+04        37233.000000   \n",
       "mean           89.978442         3.233221e+03         1429.169957   \n",
       "std            52.634720         1.502964e+04         6492.465045   \n",
       "min             1.000000         1.000000e+00            0.000000   \n",
       "25%            55.000000         1.480000e+02           68.000000   \n",
       "50%            81.000000         5.740000e+02          260.000000   \n",
       "75%           115.000000         2.058000e+03          928.000000   \n",
       "max          1250.000000         1.001655e+06       443150.000000   \n",
       "\n",
       "         am_average  am_ratings_count  am_reviews_count       am_rank  \\\n",
       "count  37233.000000      37233.000000      37233.000000  3.723300e+04   \n",
       "mean       4.261219        152.651680        152.615798  1.563020e+06   \n",
       "std        0.422799        702.459338        702.255076  2.092905e+06   \n",
       "min        1.080000          6.000000          6.000000  2.300000e+01   \n",
       "25%        4.040000         22.000000         22.000000  3.022940e+05   \n",
       "50%        4.330000         43.000000         43.000000  9.232760e+05   \n",
       "75%        4.570000        107.000000        107.000000  1.986080e+06   \n",
       "max        5.000000      44956.000000      44947.000000  2.154444e+07   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before  am_countText_after  \n",
       "count           37233.000000         3.723300e+04        3.723300e+04  \n",
       "mean              104.396879         1.371004e+04        6.490044e+03  \n",
       "std               569.410575         4.245893e+04        1.970582e+04  \n",
       "min                 0.000000         7.900000e+01        4.900000e+01  \n",
       "25%                11.000000         2.395000e+03        1.152000e+03  \n",
       "50%                24.000000         4.956000e+03        2.387000e+03  \n",
       "75%                66.000000         1.170400e+04        5.585000e+03  \n",
       "max             39851.000000         2.384912e+06        1.082212e+06  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['gr_num_pages'] = am_gr['gr_num_pages'].replace(0, np.mean(am_gr['gr_num_pages']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gr_average</th>\n",
       "      <th>gr_ratings_count</th>\n",
       "      <th>gr_reviews_count</th>\n",
       "      <th>gr_pub_yr</th>\n",
       "      <th>gr_pub_mo</th>\n",
       "      <th>gr_pub_day</th>\n",
       "      <th>gr_num_pages</th>\n",
       "      <th>gr_countDes_before</th>\n",
       "      <th>gr_countDes_after</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_average</th>\n",
       "      <th>am_ratings_count</th>\n",
       "      <th>am_reviews_count</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>35788.000000</td>\n",
       "      <td>35221.000000</td>\n",
       "      <td>35021.000000</td>\n",
       "      <td>35603.000000</td>\n",
       "      <td>36206.000000</td>\n",
       "      <td>35485.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>37233.000000</td>\n",
       "      <td>3.723300e+04</td>\n",
       "      <td>3.723300e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.873311</td>\n",
       "      <td>1.147746e+04</td>\n",
       "      <td>614.957162</td>\n",
       "      <td>2005.668772</td>\n",
       "      <td>6.367764</td>\n",
       "      <td>13.958339</td>\n",
       "      <td>323.246320</td>\n",
       "      <td>160.689085</td>\n",
       "      <td>89.978442</td>\n",
       "      <td>3.233221e+03</td>\n",
       "      <td>1429.169957</td>\n",
       "      <td>4.261219</td>\n",
       "      <td>152.651680</td>\n",
       "      <td>152.615798</td>\n",
       "      <td>1.563020e+06</td>\n",
       "      <td>104.396879</td>\n",
       "      <td>1.371004e+04</td>\n",
       "      <td>6.490044e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.306148</td>\n",
       "      <td>8.537788e+04</td>\n",
       "      <td>3121.161155</td>\n",
       "      <td>8.987800</td>\n",
       "      <td>3.339121</td>\n",
       "      <td>10.365574</td>\n",
       "      <td>200.766459</td>\n",
       "      <td>92.759441</td>\n",
       "      <td>52.634720</td>\n",
       "      <td>1.502964e+04</td>\n",
       "      <td>6492.465045</td>\n",
       "      <td>0.422799</td>\n",
       "      <td>702.459338</td>\n",
       "      <td>702.255076</td>\n",
       "      <td>2.092905e+06</td>\n",
       "      <td>569.410575</td>\n",
       "      <td>4.245893e+04</td>\n",
       "      <td>1.970582e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.900000e+01</td>\n",
       "      <td>4.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2002.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.480000e+02</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>3.022940e+05</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.395000e+03</td>\n",
       "      <td>1.152000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>3.890000</td>\n",
       "      <td>8.210000e+02</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>5.740000e+02</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>4.330000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>9.232760e+05</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.956000e+03</td>\n",
       "      <td>2.387000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.080000</td>\n",
       "      <td>3.416000e+03</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>2012.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>205.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>2.058000e+03</td>\n",
       "      <td>928.000000</td>\n",
       "      <td>4.570000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>1.986080e+06</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1.170400e+04</td>\n",
       "      <td>5.585000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.718437e+06</td>\n",
       "      <td>152766.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>9998.000000</td>\n",
       "      <td>2124.000000</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>1.001655e+06</td>\n",
       "      <td>443150.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>44956.000000</td>\n",
       "      <td>44947.000000</td>\n",
       "      <td>2.154444e+07</td>\n",
       "      <td>39851.000000</td>\n",
       "      <td>2.384912e+06</td>\n",
       "      <td>1.082212e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         gr_average  gr_ratings_count  gr_reviews_count     gr_pub_yr  \\\n",
       "count  37233.000000      3.723300e+04      37233.000000  35788.000000   \n",
       "mean       3.873311      1.147746e+04        614.957162   2005.668772   \n",
       "std        0.306148      8.537788e+04       3121.161155      8.987800   \n",
       "min        2.320000      1.000000e+00          1.000000   1900.000000   \n",
       "25%        3.690000      2.270000e+02         27.000000   2002.000000   \n",
       "50%        3.890000      8.210000e+02         83.000000   2008.000000   \n",
       "75%        4.080000      3.416000e+03        292.000000   2012.000000   \n",
       "max        5.000000      4.718437e+06     152766.000000   2019.000000   \n",
       "\n",
       "          gr_pub_mo    gr_pub_day  gr_num_pages  gr_countDes_before  \\\n",
       "count  35221.000000  35021.000000  35603.000000        36206.000000   \n",
       "mean       6.367764     13.958339    323.246320          160.689085   \n",
       "std        3.339121     10.365574    200.766459           92.759441   \n",
       "min        1.000000      1.000000      1.000000            1.000000   \n",
       "25%        4.000000      4.000000    229.000000           99.000000   \n",
       "50%        6.000000     13.000000    308.000000          147.000000   \n",
       "75%        9.000000     24.000000    384.000000          205.000000   \n",
       "max       12.000000     31.000000   9998.000000         2124.000000   \n",
       "\n",
       "       gr_countDes_after  gr_countText_before  gr_countText_after  \\\n",
       "count       35485.000000         3.723300e+04        37233.000000   \n",
       "mean           89.978442         3.233221e+03         1429.169957   \n",
       "std            52.634720         1.502964e+04         6492.465045   \n",
       "min             1.000000         1.000000e+00            0.000000   \n",
       "25%            55.000000         1.480000e+02           68.000000   \n",
       "50%            81.000000         5.740000e+02          260.000000   \n",
       "75%           115.000000         2.058000e+03          928.000000   \n",
       "max          1250.000000         1.001655e+06       443150.000000   \n",
       "\n",
       "         am_average  am_ratings_count  am_reviews_count       am_rank  \\\n",
       "count  37233.000000      37233.000000      37233.000000  3.723300e+04   \n",
       "mean       4.261219        152.651680        152.615798  1.563020e+06   \n",
       "std        0.422799        702.459338        702.255076  2.092905e+06   \n",
       "min        1.080000          6.000000          6.000000  2.300000e+01   \n",
       "25%        4.040000         22.000000         22.000000  3.022940e+05   \n",
       "50%        4.330000         43.000000         43.000000  9.232760e+05   \n",
       "75%        4.570000        107.000000        107.000000  1.986080e+06   \n",
       "max        5.000000      44956.000000      44947.000000  2.154444e+07   \n",
       "\n",
       "       am_verifiedTrue_count  am_countText_before  am_countText_after  \n",
       "count           37233.000000         3.723300e+04        3.723300e+04  \n",
       "mean              104.396879         1.371004e+04        6.490044e+03  \n",
       "std               569.410575         4.245893e+04        1.970582e+04  \n",
       "min                 0.000000         7.900000e+01        4.900000e+01  \n",
       "25%                11.000000         2.395000e+03        1.152000e+03  \n",
       "50%                24.000000         4.956000e+03        2.387000e+03  \n",
       "75%                66.000000         1.170400e+04        5.585000e+03  \n",
       "max             39851.000000         2.384912e+06        1.082212e+06  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr['ratings_count'] = am_gr['gr_ratings_count'] + am_gr['am_ratings_count']\n",
    "am_gr['reviews_count'] = am_gr['gr_reviews_count'] + am_gr['am_reviews_count']\n",
    "am_gr['rating_diff'] = am_gr['am_average'] - am_gr['gr_average']\n",
    "am_gr = am_gr.drop(['gr_ratings_count', 'am_ratings_count', 'gr_reviews_count', 'am_reviews_count', 'am_average', 'gr_average'],\n",
    "                   axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_num_pages             1630\n",
       "gr_format                1535\n",
       "gr_description           1748\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_genres                 199\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_format                  49\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "ratings_count               0\n",
       "reviews_count               0\n",
       "rating_diff                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "am_gr.to_csv('official_am_gr_metadata.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prop_topic_1</th>\n",
       "      <th>prop_topic_2</th>\n",
       "      <th>prop_topic_3</th>\n",
       "      <th>prop_topic_4</th>\n",
       "      <th>prop_topic_5</th>\n",
       "      <th>prop_topic_6</th>\n",
       "      <th>prop_topic_7</th>\n",
       "      <th>prop_topic_8</th>\n",
       "      <th>prop_topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.944674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>...</td>\n",
       "      <td>600</td>\n",
       "      <td>268</td>\n",
       "      <td>1461315</td>\n",
       "      <td>36</td>\n",
       "      <td>Paperback,  Hardcover</td>\n",
       "      <td>2362</td>\n",
       "      <td>1037</td>\n",
       "      <td>691</td>\n",
       "      <td>109</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022678</td>\n",
       "      <td>0.960657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060253</td>\n",
       "      <td>0.887754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017332</td>\n",
       "      <td>...</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399840</td>\n",
       "      <td>0.131761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>356</td>\n",
       "      <td>166</td>\n",
       "      <td>9799524</td>\n",
       "      <td>3</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>5668</td>\n",
       "      <td>2810</td>\n",
       "      <td>375</td>\n",
       "      <td>60</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.026173</td>\n",
       "      <td>0.051585</td>\n",
       "      <td>0.828228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>...</td>\n",
       "      <td>1090</td>\n",
       "      <td>509</td>\n",
       "      <td>3841172</td>\n",
       "      <td>44</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>3081</td>\n",
       "      <td>1457</td>\n",
       "      <td>1618</td>\n",
       "      <td>161</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321645</td>\n",
       "      <td>0.071768</td>\n",
       "      <td>0.434701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7453</td>\n",
       "      <td>3353</td>\n",
       "      <td>2583900</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition</td>\n",
       "      <td>5228</td>\n",
       "      <td>2508</td>\n",
       "      <td>1819</td>\n",
       "      <td>158</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.268765</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.037515</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.034230</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>210</td>\n",
       "      <td>553268</td>\n",
       "      <td>12</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition,  Pape...</td>\n",
       "      <td>3184</td>\n",
       "      <td>1420</td>\n",
       "      <td>1155</td>\n",
       "      <td>86</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>0.019026</td>\n",
       "      <td>0.291277</td>\n",
       "      <td>0.142345</td>\n",
       "      <td>0.122231</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.028764</td>\n",
       "      <td>0.049903</td>\n",
       "      <td>0.053601</td>\n",
       "      <td>0.100960</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>0.071949</td>\n",
       "      <td>0.105398</td>\n",
       "      <td>0.026594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.308752</td>\n",
       "      <td>0.134243</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>0.045840</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.143098</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.180277</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.406120</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.038480</td>\n",
       "      <td>...</td>\n",
       "      <td>431</td>\n",
       "      <td>184</td>\n",
       "      <td>3083783</td>\n",
       "      <td>13</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition,  Pape...</td>\n",
       "      <td>3811</td>\n",
       "      <td>1804</td>\n",
       "      <td>128</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  prop_topic_1  prop_topic_2  prop_topic_3  prop_topic_4  \\\n",
       "0      0001713353      0.000000      0.000000      0.000000      0.000000   \n",
       "1      0001061240      0.000000      0.000000      0.000000      0.000000   \n",
       "2      0001711296      0.000000      0.000000      0.017237      0.000000   \n",
       "3      0002007649      0.032234      0.000000      0.000000      0.000000   \n",
       "4      0001716069      0.000000      0.000000      0.056557      0.026173   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "37228  0312943636      0.000000      0.321645      0.071768      0.434701   \n",
       "37229  0312953038      0.016848      0.268765      0.119893      0.299400   \n",
       "37230  0312955154      0.019026      0.291277      0.142345      0.122231   \n",
       "37231  0312956878      0.071949      0.105398      0.026594      0.000000   \n",
       "37232  0312947763      0.045840      0.011807      0.143098      0.035479   \n",
       "\n",
       "       prop_topic_5  prop_topic_6  prop_topic_7  prop_topic_8  prop_topic_9  \\\n",
       "0          0.035829      0.944674      0.000000      0.000000      0.010132   \n",
       "1          0.022678      0.960657      0.000000      0.000000      0.013664   \n",
       "2          0.060253      0.887754      0.000000      0.000000      0.017332   \n",
       "3          0.014494      0.000000      0.399840      0.131761      0.000000   \n",
       "4          0.051585      0.828228      0.000000      0.000000      0.023740   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "37228      0.000000      0.087001      0.000000      0.026738      0.000000   \n",
       "37229      0.037515      0.053613      0.000000      0.025559      0.034230   \n",
       "37230      0.065309      0.028764      0.049903      0.053601      0.100960   \n",
       "37231      0.255959      0.025761      0.308752      0.134243      0.059607   \n",
       "37232      0.180277      0.032258      0.406120      0.052756      0.038480   \n",
       "\n",
       "       ...  gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0      ...                  600                 268  1461315   \n",
       "1      ...                   49                  18   321557   \n",
       "2      ...                  257                 117  2884610   \n",
       "3      ...                  356                 166  9799524   \n",
       "4      ...                 1090                 509  3841172   \n",
       "...    ...                  ...                 ...      ...   \n",
       "37228  ...                 7453                3353  2583900   \n",
       "37229  ...                  451                 210   553268   \n",
       "37230  ...                  362                 184  3412599   \n",
       "37231  ...                  152                  76  2606128   \n",
       "37232  ...                  431                 184  3083783   \n",
       "\n",
       "       am_verifiedTrue_count  \\\n",
       "0                         36   \n",
       "1                         30   \n",
       "2                         69   \n",
       "3                          3   \n",
       "4                         44   \n",
       "...                      ...   \n",
       "37228                      9   \n",
       "37229                     12   \n",
       "37230                      4   \n",
       "37231                      9   \n",
       "37232                     13   \n",
       "\n",
       "                                               am_format am_countText_before  \\\n",
       "0                                  Paperback,  Hardcover                2362   \n",
       "1                                              Hardcover                3085   \n",
       "2       Library Binding,  VHS Tape,  Paperback,  Hard...                5667   \n",
       "3                 Kindle Edition,  Paperback,  Hardcover                5668   \n",
       "4                 Kindle Edition,  Paperback,  Hardcover                3081   \n",
       "...                                                  ...                 ...   \n",
       "37228             Mass Market Paperback,  Kindle Edition                5228   \n",
       "37229   Mass Market Paperback,  Kindle Edition,  Pape...                3184   \n",
       "37230                         Kindle Edition,  Paperback                1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                 968   \n",
       "37232   Mass Market Paperback,  Kindle Edition,  Pape...                3811   \n",
       "\n",
       "      am_countText_after  ratings_count  reviews_count rating_diff  \n",
       "0                   1037            691            109        0.56  \n",
       "1                   1326            266             81        0.25  \n",
       "2                   2574            845            172        0.15  \n",
       "3                   2810            375             60       -0.20  \n",
       "4                   1457           1618            161        0.79  \n",
       "...                  ...            ...            ...         ...  \n",
       "37228               2508           1819            158        0.44  \n",
       "37229               1420           1155             86        0.25  \n",
       "37230                683             70             19       -0.07  \n",
       "37231                450             74             19       -0.45  \n",
       "37232               1804            128             49       -0.64  \n",
       "\n",
       "[37233 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_gen = pd.merge(lda_gen, am_gr, on='asin', how='inner')\n",
    "lda_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prop_topic_1</th>\n",
       "      <th>prop_topic_2</th>\n",
       "      <th>prop_topic_3</th>\n",
       "      <th>prop_topic_4</th>\n",
       "      <th>prop_topic_5</th>\n",
       "      <th>prop_topic_6</th>\n",
       "      <th>prop_topic_7</th>\n",
       "      <th>prop_topic_8</th>\n",
       "      <th>prop_topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>gr_countText_before</th>\n",
       "      <th>gr_countText_after</th>\n",
       "      <th>am_rank</th>\n",
       "      <th>am_verifiedTrue_count</th>\n",
       "      <th>am_format</th>\n",
       "      <th>am_countText_before</th>\n",
       "      <th>am_countText_after</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>rating_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>0.051038</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.718697</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.035051</td>\n",
       "      <td>...</td>\n",
       "      <td>600</td>\n",
       "      <td>268</td>\n",
       "      <td>1461315</td>\n",
       "      <td>36</td>\n",
       "      <td>Paperback,  Hardcover</td>\n",
       "      <td>2362</td>\n",
       "      <td>1037</td>\n",
       "      <td>691</td>\n",
       "      <td>109</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0001061240</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.032617</td>\n",
       "      <td>0.019454</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.783295</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.036005</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>18</td>\n",
       "      <td>321557</td>\n",
       "      <td>30</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>3085</td>\n",
       "      <td>1326</td>\n",
       "      <td>266</td>\n",
       "      <td>81</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001711296</td>\n",
       "      <td>0.032466</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.040258</td>\n",
       "      <td>0.037349</td>\n",
       "      <td>0.721677</td>\n",
       "      <td>0.053608</td>\n",
       "      <td>0.013817</td>\n",
       "      <td>0.034492</td>\n",
       "      <td>...</td>\n",
       "      <td>257</td>\n",
       "      <td>117</td>\n",
       "      <td>2884610</td>\n",
       "      <td>69</td>\n",
       "      <td>Library Binding,  VHS Tape,  Paperback,  Hard...</td>\n",
       "      <td>5667</td>\n",
       "      <td>2574</td>\n",
       "      <td>845</td>\n",
       "      <td>172</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>0.295647</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.547939</td>\n",
       "      <td>...</td>\n",
       "      <td>356</td>\n",
       "      <td>166</td>\n",
       "      <td>9799524</td>\n",
       "      <td>3</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>5668</td>\n",
       "      <td>2810</td>\n",
       "      <td>375</td>\n",
       "      <td>60</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>0.037673</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.040430</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.673381</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>...</td>\n",
       "      <td>1090</td>\n",
       "      <td>509</td>\n",
       "      <td>3841172</td>\n",
       "      <td>44</td>\n",
       "      <td>Kindle Edition,  Paperback,  Hardcover</td>\n",
       "      <td>3081</td>\n",
       "      <td>1457</td>\n",
       "      <td>1618</td>\n",
       "      <td>161</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37228</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.126679</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.298709</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>...</td>\n",
       "      <td>7453</td>\n",
       "      <td>3353</td>\n",
       "      <td>2583900</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition</td>\n",
       "      <td>5228</td>\n",
       "      <td>2508</td>\n",
       "      <td>1819</td>\n",
       "      <td>158</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37229</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.563066</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>...</td>\n",
       "      <td>451</td>\n",
       "      <td>210</td>\n",
       "      <td>553268</td>\n",
       "      <td>12</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition,  Pape...</td>\n",
       "      <td>3184</td>\n",
       "      <td>1420</td>\n",
       "      <td>1155</td>\n",
       "      <td>86</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37230</td>\n",
       "      <td>0312955154</td>\n",
       "      <td>0.051609</td>\n",
       "      <td>0.061779</td>\n",
       "      <td>0.083485</td>\n",
       "      <td>0.024287</td>\n",
       "      <td>0.360959</td>\n",
       "      <td>0.059199</td>\n",
       "      <td>0.036278</td>\n",
       "      <td>0.025956</td>\n",
       "      <td>0.112933</td>\n",
       "      <td>...</td>\n",
       "      <td>362</td>\n",
       "      <td>184</td>\n",
       "      <td>3412599</td>\n",
       "      <td>4</td>\n",
       "      <td>Kindle Edition,  Paperback</td>\n",
       "      <td>1456</td>\n",
       "      <td>683</td>\n",
       "      <td>70</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37231</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.033629</td>\n",
       "      <td>0.236083</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.039309</td>\n",
       "      <td>0.186549</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.053624</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>76</td>\n",
       "      <td>2606128</td>\n",
       "      <td>9</td>\n",
       "      <td>Mass Market Paperback,  Hardcover</td>\n",
       "      <td>968</td>\n",
       "      <td>450</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37232</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.034881</td>\n",
       "      <td>0.136717</td>\n",
       "      <td>0.432817</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.119538</td>\n",
       "      <td>...</td>\n",
       "      <td>431</td>\n",
       "      <td>184</td>\n",
       "      <td>3083783</td>\n",
       "      <td>13</td>\n",
       "      <td>Mass Market Paperback,  Kindle Edition,  Pape...</td>\n",
       "      <td>3811</td>\n",
       "      <td>1804</td>\n",
       "      <td>128</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37233 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  prop_topic_1  prop_topic_2  prop_topic_3  prop_topic_4  \\\n",
       "0      0001713353      0.051038      0.018866      0.020753      0.038229   \n",
       "1      0001061240      0.024777      0.032617      0.019454      0.011808   \n",
       "2      0001711296      0.032466      0.014493      0.021298      0.040258   \n",
       "3      0002007649      0.295647      0.005536      0.006731      0.094017   \n",
       "4      0001716069      0.044247      0.037673      0.018377      0.040430   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "37228  0312943636      0.017039      0.126679      0.004580      0.011723   \n",
       "37229  0312953038      0.015675      0.563066      0.091599      0.027186   \n",
       "37230  0312955154      0.051609      0.061779      0.083485      0.024287   \n",
       "37231  0312956878      0.034083      0.055215      0.033629      0.236083   \n",
       "37232  0312947763      0.068718      0.034424      0.034881      0.136717   \n",
       "\n",
       "       prop_topic_5  prop_topic_6  prop_topic_7  prop_topic_8  prop_topic_9  \\\n",
       "0          0.016284      0.718697      0.024824      0.014001      0.035051   \n",
       "1          0.012195      0.783295      0.048780      0.036005      0.016551   \n",
       "2          0.037349      0.721677      0.053608      0.013817      0.034492   \n",
       "3          0.008016      0.008060      0.008680      0.015411      0.547939   \n",
       "4          0.023537      0.673381      0.027283      0.016822      0.034846   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "37228      0.298709      0.095567      0.025440      0.009659      0.008282   \n",
       "37229      0.032248      0.015267      0.042616      0.013715      0.016328   \n",
       "37230      0.360959      0.059199      0.036278      0.025956      0.112933   \n",
       "37231      0.285390      0.039309      0.186549      0.037719      0.053624   \n",
       "37232      0.432817      0.030505      0.110915      0.015285      0.119538   \n",
       "\n",
       "       ...  gr_countText_before  gr_countText_after  am_rank  \\\n",
       "0      ...                  600                 268  1461315   \n",
       "1      ...                   49                  18   321557   \n",
       "2      ...                  257                 117  2884610   \n",
       "3      ...                  356                 166  9799524   \n",
       "4      ...                 1090                 509  3841172   \n",
       "...    ...                  ...                 ...      ...   \n",
       "37228  ...                 7453                3353  2583900   \n",
       "37229  ...                  451                 210   553268   \n",
       "37230  ...                  362                 184  3412599   \n",
       "37231  ...                  152                  76  2606128   \n",
       "37232  ...                  431                 184  3083783   \n",
       "\n",
       "       am_verifiedTrue_count  \\\n",
       "0                         36   \n",
       "1                         30   \n",
       "2                         69   \n",
       "3                          3   \n",
       "4                         44   \n",
       "...                      ...   \n",
       "37228                      9   \n",
       "37229                     12   \n",
       "37230                      4   \n",
       "37231                      9   \n",
       "37232                     13   \n",
       "\n",
       "                                               am_format am_countText_before  \\\n",
       "0                                  Paperback,  Hardcover                2362   \n",
       "1                                              Hardcover                3085   \n",
       "2       Library Binding,  VHS Tape,  Paperback,  Hard...                5667   \n",
       "3                 Kindle Edition,  Paperback,  Hardcover                5668   \n",
       "4                 Kindle Edition,  Paperback,  Hardcover                3081   \n",
       "...                                                  ...                 ...   \n",
       "37228             Mass Market Paperback,  Kindle Edition                5228   \n",
       "37229   Mass Market Paperback,  Kindle Edition,  Pape...                3184   \n",
       "37230                         Kindle Edition,  Paperback                1456   \n",
       "37231                  Mass Market Paperback,  Hardcover                 968   \n",
       "37232   Mass Market Paperback,  Kindle Edition,  Pape...                3811   \n",
       "\n",
       "      am_countText_after  ratings_count  reviews_count rating_diff  \n",
       "0                   1037            691            109        0.56  \n",
       "1                   1326            266             81        0.25  \n",
       "2                   2574            845            172        0.15  \n",
       "3                   2810            375             60       -0.20  \n",
       "4                   1457           1618            161        0.79  \n",
       "...                  ...            ...            ...         ...  \n",
       "37228               2508           1819            158        0.44  \n",
       "37229               1420           1155             86        0.25  \n",
       "37230                683             70             19       -0.07  \n",
       "37231                450             74             19       -0.45  \n",
       "37232               1804            128             49       -0.64  \n",
       "\n",
       "[37233 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_mallet = pd.merge(lda_mallet, am_gr, on='asin', how='inner')\n",
    "lda_mallet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "prop_topic_1                0\n",
       "prop_topic_2                0\n",
       "prop_topic_3                0\n",
       "prop_topic_4                0\n",
       "prop_topic_5                0\n",
       "prop_topic_6                0\n",
       "prop_topic_7                0\n",
       "prop_topic_8                0\n",
       "prop_topic_9                0\n",
       "prop_topic_10               0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_num_pages             1630\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "ratings_count               0\n",
       "reviews_count               0\n",
       "rating_diff                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gen = lda_gen.drop(['gr_format', 'gr_description', 'gr_genres', 'am_format'], axis=1) \n",
    "rf_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gen = rf_gen.dropna()\n",
    "rf_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prop_topic_1</th>\n",
       "      <th>prop_topic_2</th>\n",
       "      <th>prop_topic_3</th>\n",
       "      <th>prop_topic_4</th>\n",
       "      <th>prop_topic_5</th>\n",
       "      <th>prop_topic_6</th>\n",
       "      <th>prop_topic_7</th>\n",
       "      <th>prop_topic_8</th>\n",
       "      <th>prop_topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historicalfiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>non-fiction</th>\n",
       "      <th>paranormal</th>\n",
       "      <th>poetry</th>\n",
       "      <th>romance</th>\n",
       "      <th>thriller</th>\n",
       "      <th>young-adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035829</td>\n",
       "      <td>0.944674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010132</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399840</td>\n",
       "      <td>0.131761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056557</td>\n",
       "      <td>0.026173</td>\n",
       "      <td>0.051585</td>\n",
       "      <td>0.828228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001841572</td>\n",
       "      <td>0.078685</td>\n",
       "      <td>0.092011</td>\n",
       "      <td>0.078267</td>\n",
       "      <td>0.095343</td>\n",
       "      <td>0.039925</td>\n",
       "      <td>0.026173</td>\n",
       "      <td>0.467022</td>\n",
       "      <td>0.051698</td>\n",
       "      <td>0.055911</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001983008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>0.958966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33403</td>\n",
       "      <td>0312952813</td>\n",
       "      <td>0.015762</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>0.801447</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33404</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321645</td>\n",
       "      <td>0.071768</td>\n",
       "      <td>0.434701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33405</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.268765</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.299400</td>\n",
       "      <td>0.037515</td>\n",
       "      <td>0.053613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.034230</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33406</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>0.071949</td>\n",
       "      <td>0.105398</td>\n",
       "      <td>0.026594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255959</td>\n",
       "      <td>0.025761</td>\n",
       "      <td>0.308752</td>\n",
       "      <td>0.134243</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33407</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>0.045840</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>0.143098</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>0.180277</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.406120</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.038480</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33408 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  prop_topic_1  prop_topic_2  prop_topic_3  prop_topic_4  \\\n",
       "0      0001713353      0.000000      0.000000      0.000000      0.000000   \n",
       "1      0002007649      0.032234      0.000000      0.000000      0.000000   \n",
       "2      0001716069      0.000000      0.000000      0.056557      0.026173   \n",
       "3      0001841572      0.078685      0.092011      0.078267      0.095343   \n",
       "4      0001983008      0.000000      0.000000      0.000000      0.000000   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "33403  0312952813      0.015762      0.043639      0.801447      0.018681   \n",
       "33404  0312943636      0.000000      0.321645      0.071768      0.434701   \n",
       "33405  0312953038      0.016848      0.268765      0.119893      0.299400   \n",
       "33406  0312956878      0.071949      0.105398      0.026594      0.000000   \n",
       "33407  0312947763      0.045840      0.011807      0.143098      0.035479   \n",
       "\n",
       "       prop_topic_5  prop_topic_6  prop_topic_7  prop_topic_8  prop_topic_9  \\\n",
       "0          0.035829      0.944674      0.000000      0.000000      0.010132   \n",
       "1          0.014494      0.000000      0.399840      0.131761      0.000000   \n",
       "2          0.051585      0.828228      0.000000      0.000000      0.023740   \n",
       "3          0.039925      0.026173      0.467022      0.051698      0.055911   \n",
       "4          0.025957      0.958966      0.000000      0.000000      0.000000   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "33403      0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "33404      0.000000      0.087001      0.000000      0.026738      0.000000   \n",
       "33405      0.037515      0.053613      0.000000      0.025559      0.034230   \n",
       "33406      0.255959      0.025761      0.308752      0.134243      0.059607   \n",
       "33407      0.180277      0.032258      0.406120      0.052756      0.038480   \n",
       "\n",
       "       ...  graphic  historicalfiction  history  mystery  non-fiction  \\\n",
       "0      ...        0                  0        0        0            0   \n",
       "1      ...        0                  0        0        0            1   \n",
       "2      ...        0                  0        0        0            0   \n",
       "3      ...        0                  1        1        0            0   \n",
       "4      ...        0                  0        0        0            0   \n",
       "...    ...      ...                ...      ...      ...          ...   \n",
       "33403  ...        0                  0        0        1            0   \n",
       "33404  ...        0                  0        0        1            0   \n",
       "33405  ...        0                  1        1        0            0   \n",
       "33406  ...        0                  0        0        1            1   \n",
       "33407  ...        0                  1        1        1            1   \n",
       "\n",
       "       paranormal  poetry  romance  thriller  young-adult  \n",
       "0               0       0        0         0            0  \n",
       "1               0       0        0         0            0  \n",
       "2               0       1        0         0            1  \n",
       "3               1       0        0         0            1  \n",
       "4               1       0        0         0            0  \n",
       "...           ...     ...      ...       ...          ...  \n",
       "33403           0       0        0         1            0  \n",
       "33404           1       0        1         1            0  \n",
       "33405           0       0        1         0            0  \n",
       "33406           0       0        0         1            0  \n",
       "33407           0       0        0         1            0  \n",
       "\n",
       "[33408 rows x 42 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "am_gr['gr_genres'] = am_gr['gr_genres'].str.replace(' ','')\n",
    "genres = pd.get_dummies(am_gr['gr_genres'].str.get_dummies(sep=','))\n",
    "genres.astype('int8')\n",
    "genres = pd.concat([genres, am_gr['asin']], axis=1)\n",
    "rf_gen = pd.merge(rf_gen, genres, how='left', on='asin')\n",
    "rf_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "biography                0\n",
       "children                 0\n",
       "comics                   0\n",
       "crime                    0\n",
       "fantasy                  0\n",
       "fiction                  0\n",
       "graphic                  0\n",
       "historicalfiction        0\n",
       "history                  0\n",
       "mystery                  0\n",
       "non-fiction              0\n",
       "paranormal               0\n",
       "poetry                   0\n",
       "romance                  0\n",
       "thriller                 0\n",
       "young-adult              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.16530917986301608\n",
      "Mean Squared Error: 0.05277315335410391\n",
      "Root Mean Squared Error: 0.22972408091905364\n",
      "R2 Adjusted Score: 0.5261799291598515\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21930362757579333\n",
      "Mean Squared Error: 0.09128298751807547\n",
      "Root Mean Squared Error: 0.30213074573448406\n",
      "R2 Adjusted Score: 0.18587044914032336\n"
     ]
    }
   ],
   "source": [
    "y = np.array(rf_gen['rating_diff'])\n",
    "x = rf_gen.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "features = list(x.columns)\n",
    "\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1155, min_samples_split = 35, min_samples_leaf = 3, max_leaf_nodes = 7000,\n",
    "                           max_features = 'auto', max_depth = 30, bootstrap = True, n_jobs=4)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "r2 = rf.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "r2 = rf.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Much better MSE than model w/o LDA!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "prop_topic_1                0\n",
       "prop_topic_2                0\n",
       "prop_topic_3                0\n",
       "prop_topic_4                0\n",
       "prop_topic_5                0\n",
       "prop_topic_6                0\n",
       "prop_topic_7                0\n",
       "prop_topic_8                0\n",
       "prop_topic_9                0\n",
       "prop_topic_10               0\n",
       "gr_pub_yr                1445\n",
       "gr_pub_mo                2012\n",
       "gr_pub_day               2212\n",
       "gr_num_pages             1630\n",
       "gr_countDes_before       1027\n",
       "gr_countDes_after        1748\n",
       "gr_countText_before         0\n",
       "gr_countText_after          0\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_countText_before         0\n",
       "am_countText_after          0\n",
       "ratings_count               0\n",
       "reviews_count               0\n",
       "rating_diff                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mallet = lda_mallet.drop(['gr_format', 'gr_description', 'gr_genres', 'am_format'], axis=1) \n",
    "rf_mallet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mallet = rf_mallet.dropna()\n",
    "rf_mallet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>prop_topic_1</th>\n",
       "      <th>prop_topic_2</th>\n",
       "      <th>prop_topic_3</th>\n",
       "      <th>prop_topic_4</th>\n",
       "      <th>prop_topic_5</th>\n",
       "      <th>prop_topic_6</th>\n",
       "      <th>prop_topic_7</th>\n",
       "      <th>prop_topic_8</th>\n",
       "      <th>prop_topic_9</th>\n",
       "      <th>...</th>\n",
       "      <th>graphic</th>\n",
       "      <th>historicalfiction</th>\n",
       "      <th>history</th>\n",
       "      <th>mystery</th>\n",
       "      <th>non-fiction</th>\n",
       "      <th>paranormal</th>\n",
       "      <th>poetry</th>\n",
       "      <th>romance</th>\n",
       "      <th>thriller</th>\n",
       "      <th>young-adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0001713353</td>\n",
       "      <td>0.051038</td>\n",
       "      <td>0.018866</td>\n",
       "      <td>0.020753</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.718697</td>\n",
       "      <td>0.024824</td>\n",
       "      <td>0.014001</td>\n",
       "      <td>0.035051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002007649</td>\n",
       "      <td>0.295647</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.008016</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>0.547939</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0001716069</td>\n",
       "      <td>0.044247</td>\n",
       "      <td>0.037673</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.040430</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.673381</td>\n",
       "      <td>0.027283</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.034846</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001841572</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>0.028265</td>\n",
       "      <td>0.269094</td>\n",
       "      <td>0.021974</td>\n",
       "      <td>0.182350</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.152401</td>\n",
       "      <td>0.096137</td>\n",
       "      <td>0.030746</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001983008</td>\n",
       "      <td>0.042353</td>\n",
       "      <td>0.039266</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.049726</td>\n",
       "      <td>0.693073</td>\n",
       "      <td>0.034465</td>\n",
       "      <td>0.020062</td>\n",
       "      <td>0.033608</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33403</td>\n",
       "      <td>0312952813</td>\n",
       "      <td>0.034485</td>\n",
       "      <td>0.005480</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.024283</td>\n",
       "      <td>0.749818</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>0.065930</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.016728</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33404</td>\n",
       "      <td>0312943636</td>\n",
       "      <td>0.017039</td>\n",
       "      <td>0.126679</td>\n",
       "      <td>0.004580</td>\n",
       "      <td>0.011723</td>\n",
       "      <td>0.298709</td>\n",
       "      <td>0.095567</td>\n",
       "      <td>0.025440</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33405</td>\n",
       "      <td>0312953038</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.563066</td>\n",
       "      <td>0.091599</td>\n",
       "      <td>0.027186</td>\n",
       "      <td>0.032248</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.042616</td>\n",
       "      <td>0.013715</td>\n",
       "      <td>0.016328</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33406</td>\n",
       "      <td>0312956878</td>\n",
       "      <td>0.034083</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.033629</td>\n",
       "      <td>0.236083</td>\n",
       "      <td>0.285390</td>\n",
       "      <td>0.039309</td>\n",
       "      <td>0.186549</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.053624</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33407</td>\n",
       "      <td>0312947763</td>\n",
       "      <td>0.068718</td>\n",
       "      <td>0.034424</td>\n",
       "      <td>0.034881</td>\n",
       "      <td>0.136717</td>\n",
       "      <td>0.432817</td>\n",
       "      <td>0.030505</td>\n",
       "      <td>0.110915</td>\n",
       "      <td>0.015285</td>\n",
       "      <td>0.119538</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33408 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin  prop_topic_1  prop_topic_2  prop_topic_3  prop_topic_4  \\\n",
       "0      0001713353      0.051038      0.018866      0.020753      0.038229   \n",
       "1      0002007649      0.295647      0.005536      0.006731      0.094017   \n",
       "2      0001716069      0.044247      0.037673      0.018377      0.040430   \n",
       "3      0001841572      0.016215      0.028265      0.269094      0.021974   \n",
       "4      0001983008      0.042353      0.039266      0.028807      0.024691   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "33403  0312952813      0.034485      0.005480      0.005409      0.024283   \n",
       "33404  0312943636      0.017039      0.126679      0.004580      0.011723   \n",
       "33405  0312953038      0.015675      0.563066      0.091599      0.027186   \n",
       "33406  0312956878      0.034083      0.055215      0.033629      0.236083   \n",
       "33407  0312947763      0.068718      0.034424      0.034881      0.136717   \n",
       "\n",
       "       prop_topic_5  prop_topic_6  prop_topic_7  prop_topic_8  prop_topic_9  \\\n",
       "0          0.016284      0.718697      0.024824      0.014001      0.035051   \n",
       "1          0.008016      0.008060      0.008680      0.015411      0.547939   \n",
       "2          0.023537      0.673381      0.027283      0.016822      0.034846   \n",
       "3          0.182350      0.063530      0.152401      0.096137      0.030746   \n",
       "4          0.049726      0.693073      0.034465      0.020062      0.033608   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "33403      0.749818      0.024479      0.065930      0.002698      0.016728   \n",
       "33404      0.298709      0.095567      0.025440      0.009659      0.008282   \n",
       "33405      0.032248      0.015267      0.042616      0.013715      0.016328   \n",
       "33406      0.285390      0.039309      0.186549      0.037719      0.053624   \n",
       "33407      0.432817      0.030505      0.110915      0.015285      0.119538   \n",
       "\n",
       "       ...  graphic  historicalfiction  history  mystery  non-fiction  \\\n",
       "0      ...        0                  0        0        0            0   \n",
       "1      ...        0                  0        0        0            1   \n",
       "2      ...        0                  0        0        0            0   \n",
       "3      ...        0                  1        1        0            0   \n",
       "4      ...        0                  0        0        0            0   \n",
       "...    ...      ...                ...      ...      ...          ...   \n",
       "33403  ...        0                  0        0        1            0   \n",
       "33404  ...        0                  0        0        1            0   \n",
       "33405  ...        0                  1        1        0            0   \n",
       "33406  ...        0                  0        0        1            1   \n",
       "33407  ...        0                  1        1        1            1   \n",
       "\n",
       "       paranormal  poetry  romance  thriller  young-adult  \n",
       "0               0       0        0         0            0  \n",
       "1               0       0        0         0            0  \n",
       "2               0       1        0         0            1  \n",
       "3               1       0        0         0            1  \n",
       "4               1       0        0         0            0  \n",
       "...           ...     ...      ...       ...          ...  \n",
       "33403           0       0        0         1            0  \n",
       "33404           1       0        1         1            0  \n",
       "33405           0       0        1         0            0  \n",
       "33406           0       0        0         1            0  \n",
       "33407           0       0        0         1            0  \n",
       "\n",
       "[33408 rows x 42 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mallet = pd.merge(rf_mallet, genres, how='left', on='asin')\n",
    "rf_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "biography                0\n",
       "children                 0\n",
       "comics                   0\n",
       "crime                    0\n",
       "fantasy                  0\n",
       "fiction                  0\n",
       "graphic                  0\n",
       "historicalfiction        0\n",
       "history                  0\n",
       "mystery                  0\n",
       "non-fiction              0\n",
       "paranormal               0\n",
       "poetry                   0\n",
       "romance                  0\n",
       "thriller                 0\n",
       "young-adult              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mallet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.16291721299058654\n",
      "Mean Squared Error: 0.051398209261767115\n",
      "Root Mean Squared Error: 0.2267117316368236\n",
      "R2 Adjusted Score: 0.5385247686440662\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21787551434312485\n",
      "Mean Squared Error: 0.0903255259705928\n",
      "Root Mean Squared Error: 0.3005420535808472\n",
      "R2 Adjusted Score: 0.19440980308580103\n"
     ]
    }
   ],
   "source": [
    "y = np.array(rf_mallet['rating_diff'])\n",
    "x = rf_mallet.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "x = np.array(x)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)\n",
    "\n",
    "# Train the model on training data\n",
    "rf = RandomForestRegressor(n_estimators = 1155, min_samples_split = 35, min_samples_leaf = 3, max_leaf_nodes = 7000,\n",
    "                           max_features = 'auto', max_depth = 30, bootstrap = True, n_jobs=4)\n",
    "rf.fit(x_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the train data\n",
    "predictions = rf.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, predictions)))\n",
    "r2 = rf.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, predictions))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, predictions))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "r2 = rf.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Better than the model w/o LDA & w/ LDA gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gen = lda_gen.drop(['gr_pub_mo', 'gr_pub_day', 'gr_format', 'gr_description', 'gr_countDes_before', 'gr_countDes_after', \n",
    "                        'gr_genres', 'gr_countText_before', 'gr_countText_after', 'am_format', 'am_countText_after', \n",
    "                        'reviews_count'], axis=1) \n",
    "xgb_gen = pd.merge(xgb_gen, genres, how='left', on='asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.19853487651300472\n",
      "Mean Squared Error: 0.07296480818180238\n",
      "Root Mean Squared Error: 0.27011998848993457\n",
      "R2 Adjusted Score: 0.35226563478056927\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21906072046731387\n",
      "Mean Squared Error: 0.08958092678023954\n",
      "Root Mean Squared Error: 0.29930072966873894\n",
      "R2 Adjusted Score: 0.19267045663831028\n"
     ]
    }
   ],
   "source": [
    "y = np.array(xgb_gen['rating_diff'])\n",
    "x = xgb_gen.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=0)\n",
    "\n",
    "# fit model no training data\n",
    "model = xgb.XGBRegressor(eta=0.1, min_child_weight=10, tree_method='approx')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = model.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = model.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: A little than model w/o LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                        0\n",
       "prop_topic_1                0\n",
       "prop_topic_2                0\n",
       "prop_topic_3                0\n",
       "prop_topic_4                0\n",
       "prop_topic_5                0\n",
       "prop_topic_6                0\n",
       "prop_topic_7                0\n",
       "prop_topic_8                0\n",
       "prop_topic_9                0\n",
       "prop_topic_10               0\n",
       "gr_pub_yr                1445\n",
       "gr_num_pages             1630\n",
       "am_rank                     0\n",
       "am_verifiedTrue_count       0\n",
       "am_countText_before         0\n",
       "ratings_count               0\n",
       "rating_diff                 0\n",
       "biography                   0\n",
       "children                    0\n",
       "comics                      0\n",
       "crime                       0\n",
       "fantasy                     0\n",
       "fiction                     0\n",
       "graphic                     0\n",
       "historicalfiction           0\n",
       "history                     0\n",
       "mystery                     0\n",
       "non-fiction                 0\n",
       "paranormal                  0\n",
       "poetry                      0\n",
       "romance                     0\n",
       "thriller                    0\n",
       "young-adult                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mallet = lda_mallet.drop(['gr_pub_mo', 'gr_pub_day', 'gr_format', 'gr_description', 'gr_countDes_before', \n",
    "                              'gr_countDes_after', 'gr_genres', 'gr_countText_before', 'gr_countText_after', 'am_format', \n",
    "                              'am_countText_after', 'reviews_count'], axis=1) \n",
    "xgb_mallet = pd.merge(xgb_mallet, genres, how='left', on='asin')\n",
    "xgb_mallet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.19486709062959384\n",
      "Mean Squared Error: 0.07076167341963924\n",
      "Root Mean Squared Error: 0.2660106641088647\n",
      "R2 Adjusted Score: 0.3718236399644781\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21702461432662787\n",
      "Mean Squared Error: 0.08788603953607708\n",
      "Root Mean Squared Error: 0.2964557969345128\n",
      "R2 Adjusted Score: 0.2079452767820672\n"
     ]
    }
   ],
   "source": [
    "y = np.array(xgb_mallet['rating_diff'])\n",
    "x = xgb_mallet.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=0)\n",
    "\n",
    "# fit model no training data\n",
    "model = xgb.XGBRegressor(eta=0.1, min_child_weight=10, tree_method='approx')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = model.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = model.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Better than model w/o LDA & w/ LDA gen. Not as good as RF w/ LDA mallet except for R2 Adjusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB mallet w/ null removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "biography                0\n",
       "children                 0\n",
       "comics                   0\n",
       "crime                    0\n",
       "fantasy                  0\n",
       "fiction                  0\n",
       "graphic                  0\n",
       "historicalfiction        0\n",
       "history                  0\n",
       "mystery                  0\n",
       "non-fiction              0\n",
       "paranormal               0\n",
       "poetry                   0\n",
       "romance                  0\n",
       "thriller                 0\n",
       "young-adult              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mallet_2 = lda_mallet.drop(['gr_format', 'gr_description', 'gr_genres', 'am_format'], axis=1) \n",
    "xgb_mallet_2 = xgb_mallet_2.dropna()\n",
    "xgb_mallet_2 = pd.merge(xgb_mallet_2, genres, how='left', on='asin')\n",
    "xgb_mallet_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.1883286662159504\n",
      "Mean Squared Error: 0.0652517491776496\n",
      "Root Mean Squared Error: 0.25544421930756156\n",
      "R2 Adjusted Score: 0.4141417282696216\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21798319724970056\n",
      "Mean Squared Error: 0.09007134901267383\n",
      "Root Mean Squared Error: 0.30011889146248993\n",
      "R2 Adjusted Score: 0.19667674217506426\n"
     ]
    }
   ],
   "source": [
    "y = np.array(xgb_mallet_2['rating_diff'])\n",
    "x = xgb_mallet_2.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=0)\n",
    "\n",
    "# fit model no training data\n",
    "model = xgb.XGBRegressor(eta=0.1, min_child_weight=10, tree_method='approx')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = model.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = model.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Not as good as the model w/o removing null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_gen = lda_gen.drop(['gr_format', 'gr_description', 'gr_genres', 'am_format'], axis=1) \n",
    "nn_gen = nn_gen.dropna()\n",
    "nn_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "biography                0\n",
       "children                 0\n",
       "comics                   0\n",
       "crime                    0\n",
       "fantasy                  0\n",
       "fiction                  0\n",
       "graphic                  0\n",
       "historicalfiction        0\n",
       "history                  0\n",
       "mystery                  0\n",
       "non-fiction              0\n",
       "paranormal               0\n",
       "poetry                   0\n",
       "romance                  0\n",
       "thriller                 0\n",
       "young-adult              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_gen = pd.merge(nn_gen, genres, how='left', on='asin')\n",
    "nn_gen.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.22320938663686138\n",
      "Mean Squared Error: 0.0923981836802762\n",
      "Root Mean Squared Error: 0.30397069543012895\n",
      "R2 Adjusted Score: 0.17040936244366067\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.2274558781686148\n",
      "Mean Squared Error: 0.09693540705385784\n",
      "Root Mean Squared Error: 0.31134451505343375\n",
      "R2 Adjusted Score: 0.13545796919135444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(nn_gen['rating_diff'])\n",
    "x = nn_gen.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,), solver='lbfgs', alpha=0.002, max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = model.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = model.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Improvement from the model w/o LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "asin                     0\n",
       "prop_topic_1             0\n",
       "prop_topic_2             0\n",
       "prop_topic_3             0\n",
       "prop_topic_4             0\n",
       "prop_topic_5             0\n",
       "prop_topic_6             0\n",
       "prop_topic_7             0\n",
       "prop_topic_8             0\n",
       "prop_topic_9             0\n",
       "prop_topic_10            0\n",
       "gr_pub_yr                0\n",
       "gr_pub_mo                0\n",
       "gr_pub_day               0\n",
       "gr_num_pages             0\n",
       "gr_countDes_before       0\n",
       "gr_countDes_after        0\n",
       "gr_countText_before      0\n",
       "gr_countText_after       0\n",
       "am_rank                  0\n",
       "am_verifiedTrue_count    0\n",
       "am_countText_before      0\n",
       "am_countText_after       0\n",
       "ratings_count            0\n",
       "reviews_count            0\n",
       "rating_diff              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_mallet = lda_mallet.drop(['gr_format', 'gr_description', 'gr_genres', 'am_format'], axis=1) \n",
    "nn_mallet = nn_mallet.dropna()\n",
    "nn_mallet.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.2236077076649016\n",
      "Mean Squared Error: 0.09271409951675427\n",
      "Root Mean Squared Error: 0.3044899005168386\n",
      "R2 Adjusted Score: 0.16810502770078406\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.22530780624884159\n",
      "Mean Squared Error: 0.09526099443588573\n",
      "Root Mean Squared Error: 0.30864379863507013\n",
      "R2 Adjusted Score: 0.15202411460073195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "y = np.array(nn_mallet['rating_diff'])\n",
    "x = nn_mallet.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=0)\n",
    "# normalize features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "# fit model no training data\n",
    "model = MLPRegressor(hidden_layer_sizes=(14,), solver='lbfgs', alpha=0.002, max_iter=500)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# make predictions for train data\n",
    "y_pred = model.predict(x_train)\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = model.score(x_train, y_train)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(x_test)\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = model.score(x_test, y_test)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verdict: Likewise, better than the model w/o LDA & model w/ just LDA gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models test performance from best to least in order are: Xgboost > RF > NN. <br/>\n",
    "But the train/test prediction difference of the models from smallest to biggest in order are: NN > Xgboost > RF. <br/>\n",
    "Best models overall: Xgboost & NN <br/>\n",
    "Test out some weighted average ensembles and compare with individual models. Start w/ <br/>\n",
    "1. Equal weights for all 3\n",
    "2. Equal weights for just Xgboost & NN\n",
    "3. Higher weights for Xgboost & NN (equal or one higher than the other) than RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal weights for all 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tu Lam\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.1892909082231817\n",
      "Mean Squared Error: 0.06735065130875274\n",
      "Root Mean Squared Error: 0.25952004028350634\n",
      "R2 Adjusted Score: 0.39568341280493025\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.2173961323400811\n",
      "Mean Squared Error: 0.08976584803896867\n",
      "Root Mean Squared Error: 0.2996094925715283\n",
      "R2 Adjusted Score: 0.2009397453782431\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestRegressor(n_estimators = 1155, min_samples_split = 35, min_samples_leaf = 3, max_leaf_nodes = 7000,\n",
    "                               max_features = 'auto', max_depth = 30, bootstrap = True, n_jobs=4)\n",
    "model2 = xgb.XGBRegressor(eta=0.1, min_child_weight=10, tree_method='approx')\n",
    "model3= MLPRegressor(hidden_layer_sizes=(14,), solver='lbfgs', alpha=0.002, max_iter=500)\n",
    "\n",
    "y = np.array(nn_mallet['rating_diff'])\n",
    "x = nn_mallet.drop('asin', axis=1).drop('rating_diff', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.25, random_state=0)\n",
    "\n",
    "model1.fit(x_train, y_train)\n",
    "model2.fit(x_train, y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_nn = scaler.transform(x_train)\n",
    "x_test_nn = scaler.transform(x_test)\n",
    "\n",
    "model3.fit(x_train_nn, y_train)\n",
    "\n",
    "# make predictions for train data\n",
    "model1_pred = np.array(model1.predict(x_train))\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = (model1_pred + model2_pred + model3_pred)/3\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model1_pred = np.array(model1.predict(x_test))\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = (model1_pred + model2_pred + model3_pred)/3\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal weights w/ just XGB & NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.2035647868963323\n",
      "Mean Squared Error: 0.07682296379823761\n",
      "Root Mean Squared Error: 0.2771695578490495\n",
      "R2 Adjusted Score: 0.3106912791691443\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21853293960487824\n",
      "Mean Squared Error: 0.09032138765636519\n",
      "Root Mean Squared Error: 0.30053516875128805\n",
      "R2 Adjusted Score: 0.19599455031991064\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = (model2_pred + model3_pred)/2\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = (model2_pred + model3_pred)/2\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher but equal weights for XGB & NN than RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.19490386182604677\n",
      "Mean Squared Error: 0.07100842861685408\n",
      "Root Mean Squared Error: 0.2664740674378167\n",
      "R2 Adjusted Score: 0.36286330703612224\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21773139032792438\n",
      "Mean Squared Error: 0.08991301773764433\n",
      "Root Mean Squared Error: 0.2998549945184244\n",
      "R2 Adjusted Score: 0.19962969863479418\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model1_pred = np.array(model1.predict(x_train))\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = (model1_pred + (2*model2_pred) + (2*model3_pred))/5\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model1_pred = np.array(model1.predict(x_test))\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = (model1_pred + (2*model2_pred) + (2*model3_pred))/5\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB > RF > NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.18420263435860001\n",
      "Mean Squared Error: 0.06354196572582262\n",
      "Root Mean Squared Error: 0.25207531756564866\n",
      "R2 Adjusted Score: 0.4298575719028732\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21719317274096386\n",
      "Mean Squared Error: 0.08947013982886359\n",
      "Root Mean Squared Error: 0.2991155960976686\n",
      "R2 Adjusted Score: 0.20357202349762016\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model1_pred = np.array(model1.predict(x_train))\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = ((2*model1_pred) + (3*model2_pred) + model3_pred)/6\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model1_pred = np.array(model1.predict(x_test))\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = ((2*model1_pred) + (3*model2_pred) + model3_pred)/6\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB > NN > RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.19359473728290522\n",
      "Mean Squared Error: 0.06987182398221092\n",
      "Root Mean Squared Error: 0.26433279021379646\n",
      "R2 Adjusted Score: 0.37306170928540217\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21756600866549955\n",
      "Mean Squared Error: 0.08971510810900224\n",
      "Root Mean Squared Error: 0.29952480382933605\n",
      "R2 Adjusted Score: 0.201391412267647\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model1_pred = np.array(model1.predict(x_train))\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = (model1_pred + (3*model2_pred) + (2*model3_pred))/6\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model1_pred = np.array(model1.predict(x_test))\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = (model1_pred + (3*model2_pred) + (2*model3_pred))/6\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN > XGB > RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.19922812338038473\n",
      "Mean Squared Error: 0.07416958259968126\n",
      "Root Mean Squared Error: 0.27234093081959104\n",
      "R2 Adjusted Score: 0.33449924894048855\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21830729707633187\n",
      "Mean Squared Error: 0.09033187450583674\n",
      "Root Mean Squared Error: 0.3005526152037888\n",
      "R2 Adjusted Score: 0.19590120051269588\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model1_pred = np.array(model1.predict(x_train))\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = (model1_pred + (2*model2_pred) + (3*model3_pred))/6\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model1_pred = np.array(model1.predict(x_test))\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = (model1_pred + (2*model2_pred) + (3*model3_pred))/6\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB > NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.2499729920766883\n",
      "Mean Squared Error: 0.10607618531281983\n",
      "Root Mean Squared Error: 0.32569339157069155\n",
      "R2 Adjusted Score: 0.04821115987360469\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.2704075872007369\n",
      "Mean Squared Error: 0.1298744215367733\n",
      "Root Mean Squared Error: 0.36038093947484695\n",
      "R2 Adjusted Score: -0.15609099238917823\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = ((2*model2_pred) + model3_pred)/2\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = ((2*model2_pred) + model3_pred)/2\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN > XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.26077908346119133\n",
      "Mean Squared Error: 0.11798163285208894\n",
      "Root Mean Squared Error: 0.34348454528856015\n",
      "R2 Adjusted Score: -0.0586127428824188\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.269961762609331\n",
      "Mean Squared Error: 0.1307430109495287\n",
      "Root Mean Squared Error: 0.3615840302744698\n",
      "R2 Adjusted Score: -0.16382283353456328\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = (model2_pred + (2*model3_pred))/2\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = (model2_pred + (2*model3_pred))/2\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "### NOTE: RANKED FROM WORST TO BEST TEST PERFORMANCE\n",
    "\n",
    "ENSEMBLE - XGB > NN:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.2499729920766883\n",
    "    Mean Squared Error: 0.10607618531281983\n",
    "    Root Mean Squared Error: 0.32569339157069155\n",
    "    R2 Adjusted Score: 0.04821115987360469\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.2704075872007369\n",
    "    Mean Squared Error: 0.1298744215367733\n",
    "    Root Mean Squared Error: 0.36038093947484695\n",
    "    R2 Adjusted Score: -0.15609099238917823\n",
    "\n",
    "ENSEMBLE - NN > XGB:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.26077908346119133\n",
    "    Mean Squared Error: 0.11798163285208894\n",
    "    Root Mean Squared Error: 0.34348454528856015\n",
    "    R2 Adjusted Score: -0.0586127428824188\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.269961762609331\n",
    "    Mean Squared Error: 0.1307430109495287\n",
    "    Root Mean Squared Error: 0.3615840302744698\n",
    "    R2 Adjusted Score: -0.16382283353456328\n",
    "\n",
    "NN MALLET\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.22242721938169951\n",
    "    Mean Squared Error: 0.09188023591544606\n",
    "    Root Mean Squared Error: 0.3031175282220513\n",
    "    R2 Adjusted Score: 0.17558702818536265\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.2240292780327175\n",
    "    Mean Squared Error: 0.09415299768668209\n",
    "    Root Mean Squared Error: 0.30684360460449894\n",
    "    R2 Adjusted Score: 0.1618870656436987\n",
    "\n",
    "ENSEMBLE - EQUAL WEIGHTS FOR JUST XGB & NN:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.2035647868963323\n",
    "    Mean Squared Error: 0.07682296379823761\n",
    "    Root Mean Squared Error: 0.2771695578490495\n",
    "    R2 Adjusted Score: 0.3106912791691443\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21853293960487824\n",
    "    Mean Squared Error: 0.09032138765636519\n",
    "    Root Mean Squared Error: 0.30053516875128805\n",
    "    R2 Adjusted Score: 0.19599455031991064\n",
    "\n",
    "ENSEMBLE - NN > XGB > RF:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.19922812338038473\n",
    "    Mean Squared Error: 0.07416958259968126\n",
    "    Root Mean Squared Error: 0.27234093081959104\n",
    "    R2 Adjusted Score: 0.33449924894048855\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21830729707633187\n",
    "    Mean Squared Error: 0.09033187450583674\n",
    "    Root Mean Squared Error: 0.3005526152037888\n",
    "    R2 Adjusted Score: 0.19590120051269588\n",
    "\n",
    "RF MALLET\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.1629107330152026\n",
    "    Mean Squared Error: 0.05143697030068982\n",
    "    Root Mean Squared Error: 0.22679720082198945\n",
    "    R2 Adjusted Score: 0.5381767553638106\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21773554131645412\n",
    "    Mean Squared Error: 0.09025789502980511\n",
    "    Root Mean Squared Error: 0.30042951757409775\n",
    "    R2 Adjusted Score: 0.19501298609881101  \n",
    "    \n",
    "ENSEMBLE - HIGHER BUT EQUAL WEIGHTS FOR XGB & NN THAN RF:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.19490386182604677\n",
    "    Mean Squared Error: 0.07100842861685408\n",
    "    Root Mean Squared Error: 0.2664740674378167\n",
    "    R2 Adjusted Score: 0.36286330703612224\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21773139032792438\n",
    "    Mean Squared Error: 0.08991301773764433\n",
    "    Root Mean Squared Error: 0.2998549945184244\n",
    "    R2 Adjusted Score: 0.19962969863479418\n",
    "  \n",
    "XGB MALLET NO NULLS\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.1883286662159504\n",
    "    Mean Squared Error: 0.0652517491776496\n",
    "    Root Mean Squared Error: 0.25544421930756156\n",
    "    R2 Adjusted Score: 0.4141417282696216\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21798319724970056\n",
    "    Mean Squared Error: 0.09007134901267383\n",
    "    Root Mean Squared Error: 0.30011889146248993\n",
    "    R2 Adjusted Score: 0.19667674217506426\n",
    "\n",
    "ENSEMBLE - XGB > NN > RF:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.19359473728290522\n",
    "    Mean Squared Error: 0.06987182398221092\n",
    "    Root Mean Squared Error: 0.26433279021379646\n",
    "    R2 Adjusted Score: 0.37306170928540217\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21756600866549955\n",
    "    Mean Squared Error: 0.08971510810900224\n",
    "    Root Mean Squared Error: 0.29952480382933605\n",
    "    R2 Adjusted Score: 0.201391412267647\n",
    "\n",
    "ENSEMBLE - EQUAL WEIGHTS FOR ALL 3:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.1892909082231817\n",
    "    Mean Squared Error: 0.06735065130875274\n",
    "    Root Mean Squared Error: 0.25952004028350634\n",
    "    R2 Adjusted Score: 0.39568341280493025\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.2173961323400811\n",
    "    Mean Squared Error: 0.08976584803896867\n",
    "    Root Mean Squared Error: 0.2996094925715283\n",
    "    R2 Adjusted Score: 0.2009397453782431\n",
    "    \n",
    "ENSEMBLE - XGB > RF > NN:\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.18420263435860001\n",
    "    Mean Squared Error: 0.06354196572582262\n",
    "    Root Mean Squared Error: 0.25207531756564866\n",
    "    R2 Adjusted Score: 0.4298575719028732\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21719317274096386\n",
    "    Mean Squared Error: 0.08947013982886359\n",
    "    Root Mean Squared Error: 0.2991155960976686\n",
    "    R2 Adjusted Score: 0.20357202349762016\n",
    "    \n",
    "XGB MALLET\n",
    "    TRAIN DATA:\n",
    "    Mean Absolute Error: 0.19486709062959384\n",
    "    Mean Squared Error: 0.07076167341963924\n",
    "    Root Mean Squared Error: 0.2660106641088647\n",
    "    R2 Adjusted Score: 0.3718236399644781\n",
    "    ----------------------------------\n",
    "    TEST DATA:\n",
    "    Mean Absolute Error: 0.21702461432662787\n",
    "    Mean Squared Error: 0.08788603953607708\n",
    "    Root Mean Squared Error: 0.2964557969345128\n",
    "    R2 Adjusted Score: 0.2079452767820672    \n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, it seems like the ensemble w/ XGB > RF > NN has best chances at beating XGB Mallet. Let's tweak the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATA:\n",
      "Mean Absolute Error: 0.18038588687997759\n",
      "Mean Squared Error: 0.06115359947434676\n",
      "Root Mean Squared Error: 0.2472925382504429\n",
      "R2 Adjusted Score: 0.451287644426555\n",
      "----------------------------------\n",
      "TEST DATA:\n",
      "Mean Absolute Error: 0.21716372915245075\n",
      "Mean Squared Error: 0.08947770025657142\n",
      "Root Mean Squared Error: 0.29912823380044123\n",
      "R2 Adjusted Score: 0.20350472354534155\n"
     ]
    }
   ],
   "source": [
    "# make predictions for train data\n",
    "model1_pred = np.array(model1.predict(x_train))\n",
    "model2_pred = np.array(model2.predict(x_train))\n",
    "model3_pred = np.array(model3.predict(x_train_nn))\n",
    "y_pred = ((43*model1_pred) + (45*model2_pred) + (12*model3_pred))/100\n",
    "print('TRAIN DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_train, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_train, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_train, y_pred)))\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "n = x_train.shape[0]\n",
    "p = x_train.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)\n",
    "\n",
    "print('----------------------------------')\n",
    "\n",
    "# make predictions for test data\n",
    "model1_pred = np.array(model1.predict(x_test))\n",
    "model2_pred = np.array(model2.predict(x_test))\n",
    "model3_pred = np.array(model3.predict(x_test_nn))\n",
    "y_pred = ((43*model1_pred) + (45*model2_pred) + (12*model3_pred))/100\n",
    "print('TEST DATA:')\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "n = x_test.shape[0]\n",
    "p = x_test.shape[1]\n",
    "adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "print('R2 Adjusted Score:', adjusted_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGB is still the best model. Ensemble did not help much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
